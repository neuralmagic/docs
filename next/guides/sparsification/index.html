<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-guides/sparsification/index" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.2.1">
<title data-rh="true">Sparsification: Compressing Neural Networks | Neural Magic Documentation</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://docs.neuralmagic.com/next/guides/sparsification/"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Sparsification: Compressing Neural Networks | Neural Magic Documentation"><meta data-rh="true" name="description" content="A comprehensive overview of sparsification techniques used to create smaller, faster, and more energy-efficient neural networks while maintaining accuracy."><meta data-rh="true" property="og:description" content="A comprehensive overview of sparsification techniques used to create smaller, faster, and more energy-efficient neural networks while maintaining accuracy."><meta data-rh="true" name="keywords" content="model compression,model acceleration,neural network optimization,efficiency,pruning,quantization,distillation"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://docs.neuralmagic.com/next/guides/sparsification/"><link data-rh="true" rel="alternate" href="https://docs.neuralmagic.com/next/guides/sparsification/" hreflang="en"><link data-rh="true" rel="alternate" href="https://docs.neuralmagic.com/next/guides/sparsification/" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://CIS4HPXHOK-dsn.algolia.net" crossorigin="anonymous"><link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-L2QW513YN1"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-L2QW513YN1",{anonymize_ip:!0})</script>


<link rel="search" type="application/opensearchdescription+xml" title="Neural Magic Documentation" href="/opensearch.xml"><link rel="stylesheet" href="/assets/css/styles.37291b94.css">
<script src="/assets/js/runtime~main.52fe846b.js" defer="defer"></script>
<script src="/assets/js/main.cd057446.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="Neural Magic Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo.svg" alt="Neural Magic Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Docs</b></a><div class="navbar__item dropdown dropdown--hoverable"><a aria-current="page" class="navbar__link active" aria-haspopup="true" aria-expanded="false" role="button" href="/next/">nightly</a><ul class="dropdown__menu"><li><a aria-current="page" class="dropdown__link dropdown__link--active" href="/next/guides/sparsification/">nightly</a></li><li><a class="dropdown__link" href="/guides/sparsification/">1.7.0</a></li></ul></div></div><div class="navbar__items navbar__items--right"><div class="navbarSearchContainer_Bca1"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20" aria-hidden="true"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">GitHub</a><ul class="dropdown__menu"><li><a href="https://github.com/neuralmagic/" target="_blank" rel="noopener noreferrer" class="dropdown__link">Neural Magic</a></li><li><a href="https://github.com/neuralmagic/docs" target="_blank" rel="noopener noreferrer" class="dropdown__link">Docs</a></li><li><a href="https://github.com/neuralmagic/nm-vllm" target="_blank" rel="noopener noreferrer" class="dropdown__link">nm-vllm</a></li><li><a href="https://github.com/neuralmagic/deepsparse" target="_blank" rel="noopener noreferrer" class="dropdown__link">DeepSparse</a></li><li><a href="https://github.com/neuralmagic/sparseml" target="_blank" rel="noopener noreferrer" class="dropdown__link">SparseML</a></li><li><a href="https://github.com/neuralmagic/sparsezoo" target="_blank" rel="noopener noreferrer" class="dropdown__link">SparseZoo</a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">Products</a><ul class="dropdown__menu"><li><a href="https://neuralmagic.com/nm-vllm" target="_blank" rel="noopener noreferrer" class="dropdown__link">nm-vllm</a></li><li><a href="https://neuralmagic.com/deepsparse" target="_blank" rel="noopener noreferrer" class="dropdown__link">DeepSparse</a></li><li><a href="https://neuralmagic.com/sparseml" target="_blank" rel="noopener noreferrer" class="dropdown__link">SparseML</a></li><li><a href="https://sparsezoo.neuralmagic.com/" target="_blank" rel="noopener noreferrer" class="dropdown__link">SparseZoo</a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">Resources</a><ul class="dropdown__menu"><li><a href="https://neuralmagic.com/blog/" target="_blank" rel="noopener noreferrer" class="dropdown__link">Blog</a></li><li><a href="http://neuralmagic.com/resources/technical-papers/" target="_blank" rel="noopener noreferrer" class="dropdown__link">Research Papers</a></li><li><a href="https://neuralmagic.com/support" target="_blank" rel="noopener noreferrer" class="dropdown__link">Support</a></li><li><a href="https://neuralmagic.com/community/#events" target="_blank" rel="noopener noreferrer" class="dropdown__link">Events</a></li><li><a href="https://www.youtube.com/channel/UCo8dO_WMGYbWCRnj_Dxr4EA" target="_blank" rel="noopener noreferrer" class="dropdown__link">Videos</a></li><li><a href="http://neuralmagic.com/community" target="_blank" rel="noopener noreferrer" class="dropdown__link">Developers</a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">Company</a><ul class="dropdown__menu"><li><a href="http://neuralmagic.com/about" target="_blank" rel="noopener noreferrer" class="dropdown__link">About Us</a></li><li><a href="http://neuralmagic.com/our-technology" target="_blank" rel="noopener noreferrer" class="dropdown__link">Our Technology</a></li><li><a href="https://apply.workable.com/neural-magic/" target="_blank" rel="noopener noreferrer" class="dropdown__link">Careers</a></li><li><a href="http://neuralmagic.com/contact" target="_blank" rel="noopener noreferrer" class="dropdown__link">Contact</a></li><li><a href="http://neuralmagic.com/legal" target="_blank" rel="noopener noreferrer" class="dropdown__link">Legal</a></li><li><a href="http://neuralmagic.com/" target="_blank" rel="noopener noreferrer" class="dropdown__link">neuralmagic.com</a></li></ul></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_BF9v"><div class="docsSideNavBackground_MOrL"></div><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_Rg9N"><aside class="theme-doc-sidebar-container docSidebarContainer_tLwi"><div class="sidebarViewport_wp6o"><div class="sidebar_mhZE"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_Y1UP"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/next/">Home</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/next/get-started/">Getting Started</a><button aria-label="Collapse sidebar category &#x27;Getting Started&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/next/get-started/install/">Install</a><button aria-label="Expand sidebar category &#x27;Install&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/next/get-started/deploy">Deploy</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/next/get-started/optimize">Optimize</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/next/get-started/finetune">Sparse Fine-Tuning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/next/get-started/transfer">Sparse Transfer</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/next/llms/">LLMs - Causal Language Modeling</a><button aria-label="Expand sidebar category &#x27;LLMs - Causal Language Modeling&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/next/computer-vision/">Computer Vision</a><button aria-label="Expand sidebar category &#x27;Computer Vision&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/next/nlp/">Natural Language Processing</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" href="/next/guides/">Guides</a><button aria-label="Collapse sidebar category &#x27;Guides&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/next/guides/sparsification/">Sparsification</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/next/guides/deepsparse-engine/">DeepSparse Features</a><button aria-label="Expand sidebar category &#x27;DeepSparse Features&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/next/guides/deploying-deepsparse/">Deployment Options</a><button aria-label="Expand sidebar category &#x27;Deployment Options&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/next/guides/onnx/">ONNX</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/next/products/">Products</a><button aria-label="Expand sidebar category &#x27;Products&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/next/details/">Details</a><button aria-label="Expand sidebar category &#x27;Details&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav></div></div></aside><main class="docMainContainer_Vlkt"><div class="container docItemWrapper_GJ0o"><div class="row"><div class="col docItemCol_VOVn"><div class="theme-doc-version-banner alert alert--warning margin-bottom--md" role="alert"><div>This is unreleased documentation for the <b>nightly</b> version.</div><div class="margin-top--md">For the latest released documentation, see the <b><a href="/guides/sparsification/">current version</a></b> (<!-- -->1.7.0<!-- -->).</div></div><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/next/guides/"><span itemprop="name">Guides</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Sparsification</span><meta itemprop="position" content="2"></li></ul></nav><span class="theme-doc-version-badge badge badge--secondary">Version: nightly</span><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>Sparsification: Compressing Neural Networks</h1>
<p>Sparsification encompasses a range of powerful techniques used to compress and optimize neural networks.
By strategically removing or reducing the significance of less important connections and information within a model, sparsification leads to retaining accuracy while resulting in:</p>
<ul>
<li><b>Smaller Model Sizes:</b> Reduced storage requirements and memory footprint, simplifying deployment.</li>
<li><b>Faster Inference:</b> Significant boosts in computational speed, especially on resource-constrained hardware, promoting real-time applications.</li>
<li><b>Reduced Energy Consumption:</b> Enable efficient execution for servers, edge environments, and mobile devices, lowering costs and broadening usage.</li>
</ul>
<p>This guide delves into the core concepts of sparsification, and in it, you&#x27;ll learn:</p>
<ul>
<li><b>The Purpose of Sparsification:</b> Discover the benefits and motivations behind optimizing neural networks.</li>
<li><b>Essential Techniques:</b> Explore the key methods used to achieve sparsification.</li>
<li><b>Application Strategies:</b> Understand how to implement sparsification at different stages of the model&#x27;s lifecycle.</li>
<li><b>Practical Recipes:</b> Get guidance on applying sparsification techniques to everyday use cases.</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="techniques">Techniques<a href="#techniques" class="hash-link" aria-label="Direct link to Techniques" title="Direct link to Techniques">​</a></h2>
<p>Sparsification techniques can be broadly categorized into several key methods, each with its unique approach to compressing and optimizing neural networks:</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="quantization">Quantization<a href="#quantization" class="hash-link" aria-label="Direct link to Quantization" title="Direct link to Quantization">​</a></h3>
<p>Quantization reduces the precision of weights and activations in a neural network, for example, from 32-bit floating-point numbers to 8-bit integers.
Quantization can be applied to weights, activations, or both and can be done statically (before deployment) or dynamically (at runtime).
It decreases model size and memory usage, often leading to faster inference, particularly with specialized hardware support for low-precision arithmetic.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="pruning">Pruning<a href="#pruning" class="hash-link" aria-label="Direct link to Pruning" title="Direct link to Pruning">​</a></h3>
<p>Pruning eliminates redundant or less important connections within a model.
Pruning can be done in either a structured or unstructured manner, where structured pruning changes the model&#x27;s shape, and unstructured pruning keeps the shape intact while introducing zeros in the weights (sparsity).
This results in a smaller model and faster inference due to reduced compute provided the engine/hardware supports sparse computation.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="knowledge-distillation">Knowledge Distillation<a href="#knowledge-distillation" class="hash-link" aria-label="Direct link to Knowledge Distillation" title="Direct link to Knowledge Distillation">​</a></h3>
<p>Distillation generally trains a smaller or more compressed &quot;student&quot; model to mimic the behavior of a larger, unoptimized &quot;teacher&quot; model.
It enables the creation of more compressed models that are easier to deploy and execute while leveraging the knowledge and performance of the larger model to maintain accuracy.
Distillation is further broken down into granularity levels, such as model-level, layer-level, and instance-level distillation.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="low-rank-approximation">Low Rank Approximation<a href="#low-rank-approximation" class="hash-link" aria-label="Direct link to Low Rank Approximation" title="Direct link to Low Rank Approximation">​</a></h3>
<p>Low-rank approximations (LoRA), also known as matrix factorization, matrix decomposition, or tensor decomposition, reduce the rank of the weight matrices in a neural network, effectively compressing the model.
This technique is based on the observation that the weight matrices of neural networks are often low-rank, meaning they can be approximated by a product of two smaller matrices.
It can be particularly effective for compressing a model&#x27;s large, fully connected layers.
It&#x27;s also known to be used in conjunction with other compression techniques, such as quantization (QLoRA), to enable faster fine-tuning.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="conditional-computation">Conditional Computation<a href="#conditional-computation" class="hash-link" aria-label="Direct link to Conditional Computation" title="Direct link to Conditional Computation">​</a></h3>
<p>Conditional computation selectively activates only parts of a model based on the input data, leading to dynamic sparsity.
This can be achieved through techniques such as gating, where a gating network decides which parts of the model to execute, or through adaptive computation, where the model learns to skip or reduce computation based on the input, such as Mixture of Experts (MoE) techniques.
Conditional computation can significantly speed up inference time, especially for models with large, redundant, or unnecessary computations.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="regularization">Regularization<a href="#regularization" class="hash-link" aria-label="Direct link to Regularization" title="Direct link to Regularization">​</a></h3>
<p>Regularization methods such as L1 and L2 can be used to encourage sparsity in a neural network&#x27;s weights.
Adding a regularization term to the loss function incentivizes the model to reduce overfitting and learn simpler representations, which can lead to sparser models.
Regularization can be used with other techniques, such as pruning, to further enhance the sparsity of a model.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="weight-sharing">Weight Sharing<a href="#weight-sharing" class="hash-link" aria-label="Direct link to Weight Sharing" title="Direct link to Weight Sharing">​</a></h3>
<p>Weight sharing involves sharing the weights of a neural network across different parts of the model, effectively reducing the number of unique weights and thereby reducing the model size.
This can be done by clustering similar weights and sharing the same weight value across multiple connections.
Weight sharing can be particularly effective for reducing a model&#x27;s memory footprint, especially when combined with other compression techniques.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="architecture-search">Architecture Search<a href="#architecture-search" class="hash-link" aria-label="Direct link to Architecture Search" title="Direct link to Architecture Search">​</a></h3>
<p>Techniques such as neural architecture search (NAS) can automatically discover more efficient and compact neural network architectures.
By searching over a large space of possible architectures, NAS can identify smaller, faster, and more accurate models than hand-designed architectures.
NAS can be used to optimize existing models or discover entirely new architectures tailored to specific tasks or constraints.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="compound-sparsification">Compound Sparsification<a href="#compound-sparsification" class="hash-link" aria-label="Direct link to Compound Sparsification" title="Direct link to Compound Sparsification">​</a></h3>
<p>Compound sparsification combines multiple techniques to achieve even more significant compression and optimization.
By leveraging the strengths of different methods, compound sparsification can create smaller, faster, and more energy-efficient models than those produced by individual techniques.
For example, pruning can be combined with quantization and distillation to create highly compressed models that retain high accuracy.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="application">Application<a href="#application" class="hash-link" aria-label="Direct link to Application" title="Direct link to Application">​</a></h2>
<p>Sparsification techniques can be applied at different stages of a model&#x27;s lifecycle with varying degrees of complexity and effectiveness:</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="post-training--one-shot">Post-Training / One-Shot<a href="#post-training--one-shot" class="hash-link" aria-label="Direct link to Post-Training / One-Shot" title="Direct link to Post-Training / One-Shot">​</a></h3>
<p>Sparsification can be applied post-training, where a pre-trained model is compressed using pruning, quantization, or distillation techniques.
Post-training is often the most straightforward approach to sparsification, as it does not require changes to the training process or hyperparameters.
However, post-training sparsification may have the same level of compression or performance as techniques applied during training.
It is particularly practical for quantization but less effective for pruning.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="training-aware">Training Aware<a href="#training-aware" class="hash-link" aria-label="Direct link to Training Aware" title="Direct link to Training Aware">​</a></h3>
<p>Sparsification can also be applied during training, where the model is trained with sparsification techniques such as pruning, quantization, and distillation.
This approach can lead to more effective compression and optimization as the model adapts to the sparsity constraints during training.
Training-aware sparsification can be more complex and computationally intensive than post-training sparsification, but it can often achieve better results regarding model size, speed, and accuracy.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="transfer-learning">Transfer Learning<a href="#transfer-learning" class="hash-link" aria-label="Direct link to Transfer Learning" title="Direct link to Transfer Learning">​</a></h3>
<p>Sparsification can be combined with transfer learning, where a sparsified, pre-trained model is fine-tuned on a new task or dataset.
This approach can leverage the knowledge and compression of the pre-trained model without the complexity of sparsification hyperparameters or training from scratch.
Transfer learning with sparsification can be particularly effective for quickly adapting compressed models to new tasks or domains with fewer resources and complexity while closely matching the performance of training-aware techniques.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="recipes">Recipes<a href="#recipes" class="hash-link" aria-label="Direct link to Recipes" title="Direct link to Recipes">​</a></h2>
<p>Sparsification recipes provide a structured and reusable way to define the steps and parameters for optimizing neural networks.
They encapsulate the specific sparsification techniques, hyperparameters, and necessary training adjustments into a single configuration file.
Sparsification recipes can be shared, reused, and adapted across different models, tasks, and domains, making experimenting with and deploying compressed models easier.</p>
<p>Recipes are core to the sparsification process through SparseML, a comprehensive framework for sparsification and model optimization.
Additionally, models generally available in the SparseZoo or our HuggingFace model hub include the recipes used to train them, making it easy to reproduce and adapt the training process.</p>
<p>Throughout the sparsification guides, you&#x27;ll find example recipes for different techniques and applications, providing a hands-on approach to implementing and experimenting with sparsification.</p>
<p>A general workflow for sparsification using SparseML is as follows:</p>
<ol>
<li>Define a sparsification recipe for the desired technique and application.</li>
<li>Integrate SparseML into your experimentation pipelines or utilize the pre-built pipelines in SparseML.</li>
<li>Apply the sparsification recipe to your model through one-shot, training-aware, or transfer learning methods.</li>
<li>Evaluate the compressed model on your desired metrics and tasks.</li>
</ol>
<hr>
<p>Dive into the guides in this section to learn more about the core sparsification techniques, applications, and recipes for compressing and optimizing neural networks.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-tags-row"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/next/tags/sparsification">sparsification</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/next/tags/model-optimization">model optimization</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/next/tags/model-compression-k">model compression k</a></li></ul></div></div><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://github.com/neuralmagic/docs/tree/main/docs/guides/sparsification/index.mdx" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/next/guides/"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Guides</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/next/guides/deepsparse-engine/"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">DeepSparse Features</div></a></nav></div></div><div class="col col--3"><div class="wrapper_Y1C6"><div class="section_EsUi"><h3 class="sectionTitle_pv0_">Content</h3><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#techniques" class="table-of-contents__link toc-highlight">Techniques</a><ul><li><a href="#quantization" class="table-of-contents__link toc-highlight">Quantization</a></li><li><a href="#pruning" class="table-of-contents__link toc-highlight">Pruning</a></li><li><a href="#knowledge-distillation" class="table-of-contents__link toc-highlight">Knowledge Distillation</a></li><li><a href="#low-rank-approximation" class="table-of-contents__link toc-highlight">Low Rank Approximation</a></li><li><a href="#conditional-computation" class="table-of-contents__link toc-highlight">Conditional Computation</a></li><li><a href="#regularization" class="table-of-contents__link toc-highlight">Regularization</a></li><li><a href="#weight-sharing" class="table-of-contents__link toc-highlight">Weight Sharing</a></li><li><a href="#architecture-search" class="table-of-contents__link toc-highlight">Architecture Search</a></li><li><a href="#compound-sparsification" class="table-of-contents__link toc-highlight">Compound Sparsification</a></li></ul></li><li><a href="#application" class="table-of-contents__link toc-highlight">Application</a><ul><li><a href="#post-training--one-shot" class="table-of-contents__link toc-highlight">Post-Training / One-Shot</a></li><li><a href="#training-aware" class="table-of-contents__link toc-highlight">Training Aware</a></li><li><a href="#transfer-learning" class="table-of-contents__link toc-highlight">Transfer Learning</a></li></ul></li><li><a href="#recipes" class="table-of-contents__link toc-highlight">Recipes</a></li></ul></div></div><div class="section_EsUi"><h3 class="sectionTitle_pv0_">Actions</h3><div class="sectionLinks_oh4b"><a href="https://github.com/neuralmagic/docs/tree/main/docs/guides/sparsification/index.mdx" target="_blank" class="link_RNAl"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 -960 960 960" class="icon_Oxux" fill="var(--ifm-toc-link-color)"><path d="M200-200h57l391-391-57-57-391 391v57Zm-80 80v-170l528-527q12-11 26.5-17t30.5-6q16 0 31 6t26 18l55 56q12 11 17.5 26t5.5 30q0 16-5.5 30.5T817-647L290-120H120Zm640-584-56-56 56 56Zm-141 85-28-29 57 57-29-28Z"></path></svg> Edit this page</a></div></div><div class="section_EsUi"><h3 class="sectionTitle_pv0_">Support</h3><div class="sectionLinks_oh4b"><li><a href="https://join.slack.com/t/discuss-neuralmagic/shared_invite/zt-2gbar46r6-2Tu~SS5iQdHgczAKlQ2jJA" target="_blank" class="link_RNAl"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 127 127" class="icon_Oxux"><path d="M27.2 80c0 7.3-5.9 13.2-13.2 13.2C6.7 93.2.8 87.3.8 80c0-7.3 5.9-13.2 13.2-13.2h13.2V80zm6.6 0c0-7.3 5.9-13.2 13.2-13.2 7.3 0 13.2 5.9 13.2 13.2v33c0 7.3-5.9 13.2-13.2 13.2-7.3 0-13.2-5.9-13.2-13.2V80z" fill="#E01E5A"></path><path d="M47 27c-7.3 0-13.2-5.9-13.2-13.2C33.8 6.5 39.7.6 47 .6c7.3 0 13.2 5.9 13.2 13.2V27H47zm0 6.7c7.3 0 13.2 5.9 13.2 13.2 0 7.3-5.9 13.2-13.2 13.2H13.9C6.6 60.1.7 54.2.7 46.9c0-7.3 5.9-13.2 13.2-13.2H47z" fill="#36C5F0"></path><path d="M99.9 46.9c0-7.3 5.9-13.2 13.2-13.2 7.3 0 13.2 5.9 13.2 13.2 0 7.3-5.9 13.2-13.2 13.2H99.9V46.9zm-6.6 0c0 7.3-5.9 13.2-13.2 13.2-7.3 0-13.2-5.9-13.2-13.2V13.8C66.9 6.5 72.8.6 80.1.6c7.3 0 13.2 5.9 13.2 13.2v33.1z" fill="#2EB67D"></path><path d="M80.1 99.8c7.3 0 13.2 5.9 13.2 13.2 0 7.3-5.9 13.2-13.2 13.2-7.3 0-13.2-5.9-13.2-13.2V99.8h13.2zm0-6.6c-7.3 0-13.2-5.9-13.2-13.2 0-7.3 5.9-13.2 13.2-13.2h33.1c7.3 0 13.2 5.9 13.2 13.2 0 7.3-5.9 13.2-13.2 13.2H80.1z" fill="#ECB22E"></path></svg> Community Slack</a><a href="https://support.neuralmagic.com" target="_blank" class="link_RNAl"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 -960 960 960" class="icon_Oxux" fill="var(--ifm-toc-link-color)"><path d="M440-120v-80h320v-284q0-117-81.5-198.5T480-764q-117 0-198.5 81.5T200-484v244h-40q-33 0-56.5-23.5T80-320v-80q0-21 10.5-39.5T120-469l3-53q8-68 39.5-126t79-101q47.5-43 109-67T480-840q68 0 129 24t109 66.5Q766-707 797-649t40 126l3 52q19 9 29.5 27t10.5 38v92q0 20-10.5 38T840-249v49q0 33-23.5 56.5T760-120H440Zm-80-280q-17 0-28.5-11.5T320-440q0-17 11.5-28.5T360-480q17 0 28.5 11.5T400-440q0 17-11.5 28.5T360-400Zm240 0q-17 0-28.5-11.5T560-440q0-17 11.5-28.5T600-480q17 0 28.5 11.5T640-440q0 17-11.5 28.5T600-400Zm-359-62q-7-106 64-182t177-76q89 0 156.5 56.5T720-519q-91-1-167.5-49T435-698q-16 80-67.5 142.5T241-462Z"></path></svg> Enterprise Support</a></li></div></div><div class="section_EsUi"><h3 class="sectionTitle_pv0_">Issues</h3><div class="sectionLinks_oh4b"><li><a href="https://github.com/neuralmagic/deepsparse/issues" target="_blank" rel="noopener noreferrer" class="link_RNAl"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1024 1024" fill="none" class="icon_Oxux"><path fill-rule="evenodd" clip-rule="evenodd" d="M8 0C3.58 0 0 3.58 0 8C0 11.54 2.29 14.53 5.47 15.59C5.87 15.66 6.02 15.42 6.02 15.21C6.02 15.02 6.01 14.39 6.01 13.72C4 14.09 3.48 13.23 3.32 12.78C3.23 12.55 2.84 11.84 2.5 11.65C2.22 11.5 1.82 11.13 2.49 11.12C3.12 11.11 3.57 11.7 3.72 11.94C4.44 13.15 5.59 12.81 6.05 12.6C6.12 12.08 6.33 11.73 6.56 11.53C4.78 11.33 2.92 10.64 2.92 7.58C2.92 6.71 3.23 5.99 3.74 5.43C3.66 5.23 3.38 4.41 3.82 3.31C3.82 3.31 4.49 3.1 6.02 4.13C6.66 3.95 7.34 3.86 8.02 3.86C8.7 3.86 9.38 3.95 10.02 4.13C11.55 3.09 12.22 3.31 12.22 3.31C12.66 4.41 12.38 5.23 12.3 5.43C12.81 5.99 13.12 6.7 13.12 7.58C13.12 10.65 11.25 11.33 9.47 11.53C9.76 11.78 10.01 12.26 10.01 13.01C10.01 14.08 10 14.94 10 15.21C10 15.42 10.15 15.67 10.55 15.59C13.71 14.53 16 11.53 16 8C16 3.58 12.42 0 8 0Z" transform="scale(64)" fill="#1B1F23"></path></svg>DeepSparse</a></li><li><a href="https://github.com/neuralmagic/sparseml/issues" target="_blank" rel="noopener noreferrer" class="link_RNAl"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1024 1024" fill="none" class="icon_Oxux"><path fill-rule="evenodd" clip-rule="evenodd" d="M8 0C3.58 0 0 3.58 0 8C0 11.54 2.29 14.53 5.47 15.59C5.87 15.66 6.02 15.42 6.02 15.21C6.02 15.02 6.01 14.39 6.01 13.72C4 14.09 3.48 13.23 3.32 12.78C3.23 12.55 2.84 11.84 2.5 11.65C2.22 11.5 1.82 11.13 2.49 11.12C3.12 11.11 3.57 11.7 3.72 11.94C4.44 13.15 5.59 12.81 6.05 12.6C6.12 12.08 6.33 11.73 6.56 11.53C4.78 11.33 2.92 10.64 2.92 7.58C2.92 6.71 3.23 5.99 3.74 5.43C3.66 5.23 3.38 4.41 3.82 3.31C3.82 3.31 4.49 3.1 6.02 4.13C6.66 3.95 7.34 3.86 8.02 3.86C8.7 3.86 9.38 3.95 10.02 4.13C11.55 3.09 12.22 3.31 12.22 3.31C12.66 4.41 12.38 5.23 12.3 5.43C12.81 5.99 13.12 6.7 13.12 7.58C13.12 10.65 11.25 11.33 9.47 11.53C9.76 11.78 10.01 12.26 10.01 13.01C10.01 14.08 10 14.94 10 15.21C10 15.42 10.15 15.67 10.55 15.59C13.71 14.53 16 11.53 16 8C16 3.58 12.42 0 8 0Z" transform="scale(64)" fill="#1B1F23"></path></svg>SparseML</a></li><li><a href="https://github.com/neuralmagic/sparsezoo/issues" target="_blank" rel="noopener noreferrer" class="link_RNAl"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1024 1024" fill="none" class="icon_Oxux"><path fill-rule="evenodd" clip-rule="evenodd" d="M8 0C3.58 0 0 3.58 0 8C0 11.54 2.29 14.53 5.47 15.59C5.87 15.66 6.02 15.42 6.02 15.21C6.02 15.02 6.01 14.39 6.01 13.72C4 14.09 3.48 13.23 3.32 12.78C3.23 12.55 2.84 11.84 2.5 11.65C2.22 11.5 1.82 11.13 2.49 11.12C3.12 11.11 3.57 11.7 3.72 11.94C4.44 13.15 5.59 12.81 6.05 12.6C6.12 12.08 6.33 11.73 6.56 11.53C4.78 11.33 2.92 10.64 2.92 7.58C2.92 6.71 3.23 5.99 3.74 5.43C3.66 5.23 3.38 4.41 3.82 3.31C3.82 3.31 4.49 3.1 6.02 4.13C6.66 3.95 7.34 3.86 8.02 3.86C8.7 3.86 9.38 3.95 10.02 4.13C11.55 3.09 12.22 3.31 12.22 3.31C12.66 4.41 12.38 5.23 12.3 5.43C12.81 5.99 13.12 6.7 13.12 7.58C13.12 10.65 11.25 11.33 9.47 11.53C9.76 11.78 10.01 12.26 10.01 13.01C10.01 14.08 10 14.94 10 15.21C10 15.42 10.15 15.67 10.55 15.59C13.71 14.53 16 11.53 16 8C16 3.58 12.42 0 8 0Z" transform="scale(64)" fill="#1B1F23"></path></svg>SparseZoo</a></li></div></div></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__links text--center"><div class="footer__links"><span class="footer__link-item">
            <a href="https://join.slack.com/t/discuss-neuralmagic/shared_invite/zt-2gbar46r6-2Tu~SS5iQdHgczAKlQ2jJA" target="_blank">
              <svg width="26" height="26" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M5.54 16.166c0 1.022-.823 1.857-1.83 1.857-1.008 0-1.831-.835-1.831-1.857s.823-1.857 1.83-1.857H5.54v1.857ZM7.223 16.166c0-1.388 1.117-2.521 2.485-2.521 1.368 0 2.485 1.133 2.485 2.521v6.313c0 1.387-1.117 2.521-2.485 2.521-1.368 0-2.485-1.134-2.485-2.521v-6.313h0ZM9.932 5.037c-1.071 0-1.947-.889-1.947-1.976s.876-1.976 1.947-1.976c1.072 0 1.948.889 1.948 1.976v1.976H9.932ZM9.708 6.673c1.368 0 2.486 1.133 2.486 2.52 0 1.389-1.118 2.522-2.486 2.522H3.485C2.117 11.715 1 10.582 1 9.194s1.117-2.521 2.485-2.521h6.223ZM20.45 9.834c0-1.087.876-1.976 1.948-1.976s1.948.889 1.948 1.976-.876 1.976-1.948 1.976h-1.947V9.834Z" fill="#052D52" stroke="#fff" stroke-width="1.25" stroke-miterlimit="10" stroke-linecap="round" stroke-linejoin="round"></path><path d="M18.777 9.834c0 1.388-1.117 2.521-2.485 2.521-1.368 0-2.485-1.133-2.485-2.521V3.521C13.807 2.134 14.924 1 16.292 1c1.368 0 2.485 1.134 2.485 2.521v6.313h0ZM16.292 20.722c1.072 0 1.947.888 1.947 1.975 0 1.088-.875 1.976-1.947 1.976s-1.948-.888-1.948-1.976v-1.975h1.948v0ZM16.292 19.025c-1.368 0-2.485-1.134-2.485-2.522 0-1.387 1.117-2.52 2.485-2.52h6.223c1.368 0 2.485 1.133 2.485 2.52 0 1.388-1.117 2.522-2.485 2.522h-6.223Z" stroke="#fff" stroke-width="1.25" stroke-miterlimit="10" stroke-linecap="round" stroke-linejoin="round"></path></svg>
            </a></span><span class="footer__link-separator">·</span><span class="footer__link-item">
            <a href="https://github.com/neuralmagic" target="_blank">
                <svg width="26" height="26" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M15.5 25a.496.496 0 0 1-.313-.111.509.509 0 0 1-.187-.395V20.73c0-.91-.115-1.555-.363-2.029a.51.51 0 0 1-.013-.446.5.5 0 0 1 .342-.282C17.93 17.281 20 15.086 20 12.636c0-1.214-.493-2.373-1.425-3.351a.51.51 0 0 1-.094-.565c.372-.811.293-1.916-.148-2.579-.583.23-1.34.713-1.832 1.304a.493.493 0 0 1-.554.149 8.576 8.576 0 0 0-5.893 0 .497.497 0 0 1-.554-.148c-.492-.59-1.249-1.073-1.833-1.304-.441.663-.52 1.768-.148 2.58.087.188.05.412-.094.563C6.493 10.263 6 11.423 6 12.635c0 2.335 1.863 4.438 4.636 5.232a.506.506 0 0 1 .364.488v.353c0 .633-.251.99-.462 1.18-.452.401-1.036.34-1.1.333h-.01c-.824 0-1.444-.464-2.043-.913-.301-.226-.606-.456-.961-.646.077.105.153.213.23.322.75 1.055 1.599 2.252 2.847 2.252h1c.276 0 .5.227.5.506v2.752a.509.509 0 0 1-.187.395.505.505 0 0 1-.421.099C4.95 23.766 1 18.785 1 13.142 1 6.447 6.383 1 13 1s12 5.447 12 12.142c0 5.642-3.95 10.624-9.392 11.846A.49.49 0 0 1 15.5 25Zm.258-6.193c.164.523.242 1.15.242 1.923v3.114c4.671-1.341 8-5.744 8-10.702 0-6.137-4.935-11.13-11-11.13S2 7.005 2 13.142c0 4.959 3.329 9.36 8 10.703v-1.597h-.5c-1.76 0-2.813-1.482-3.659-2.674-.479-.675-.975-1.373-1.341-1.373a.503.503 0 0 1-.5-.506c0-.28.224-.506.5-.506 1.74 0 2.705.723 3.48 1.305.536.402.958.718 1.52.718.056.003.263.019.379-.087.095-.087.119-.26.121-.396-3.006-.999-5-3.408-5-6.092 0-1.38.512-2.692 1.484-3.81-.429-1.258-.164-2.794.662-3.631a.49.49 0 0 1 .481-.132c.668.18 1.66.705 2.401 1.469a9.598 9.598 0 0 1 5.941 0c.741-.764 1.733-1.29 2.401-1.469a.489.489 0 0 1 .481.132c.827.837 1.091 2.373.662 3.63.975 1.12 1.487 2.43 1.487 3.81 0 2.76-2.127 5.23-5.242 6.17Z" fill="#fff" stroke="#fff" stroke-width="0.2"></path></svg>
            </a></span><span class="footer__link-separator">·</span><span class="footer__link-item">
            <a href="https://twitter.com/neuralmagic" target="_blank">
                <svg width="24" height="24" fill="none" xmlns="http://www.w3.org/2000/svg"><g clip-path="url(#twitter_svg__a)"><path d="m13.874 10.445 9.164 13.043h-5.925l-6.394-9.101-.365-.52-.42.477-8.043 9.144h-.785l8.64-9.821.26-.296-.227-.322L.962.5h5.925l6.047 8.607.365.52.42-.477L21.326.5h.785l-8.055 9.157h-.737l.554.788Zm-3.847 1.972.856 1.197.094.131 6.466 9.046.15.209h4.481l-.566-.791-7.924-11.085-.949-1.328-6.096-8.528-.15-.21H1.909l.565.792 7.554 10.567Z" fill="#fff" stroke="#fff"></path></g><defs><clipPath id="twitter_svg__a"><path fill="#fff" d="M0 0h24v24H0z"></path></clipPath></defs></svg>
            </a></span><span class="footer__link-separator">·</span><span class="footer__link-item">
            <a href="https://www.linkedin.com/company/neural-magic" target="_blank">
                <svg width="26" height="26" fill="none" xmlns="http://www.w3.org/2000/svg"><path clip-rule="evenodd" d="M22.104 14.94v6.336h-4.078V15.38c0-1.543-.637-2.595-2.04-2.595-1.073 0-1.67.71-1.947 1.394-.105.247-.088.59-.088.932v6.166h-4.04s.053-10.444 0-11.394h4.04v1.789c.239-.782 1.53-1.898 3.589-1.898 2.555 0 4.564 1.638 4.564 5.168ZM4.121 21.276h3.595V9.883H4.121v11.393ZM7.944 6.536c0 1-.764 1.794-1.99 1.794H5.93c-1.18 0-1.946-.79-1.946-1.792 0-1.021.788-1.793 1.994-1.793 1.202 0 1.942.77 1.966 1.791Z" stroke="#fff" stroke-width="1.1" stroke-linejoin="round"></path><path clip-rule="evenodd" d="M23.345 25H2.655A1.655 1.655 0 0 1 1 23.345V2.655C1 1.741 1.741 1 2.655 1h20.69C24.259 1 25 1.741 25 2.655v20.69c0 .914-.741 1.655-1.655 1.655Z" stroke="#fff" stroke-width="1.1" stroke-linejoin="round"></path></svg>
            </a></span><span class="footer__link-separator">·</span><span class="footer__link-item">
            <a href="https://www.youtube.com/channel/UCo8dO_WMGYbWCRnj_Dxr4EA" target="_blank">
                <svg width="24" height="24" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="m9.938 16.077 5.749-3.323-5.75-3.323v6.646Zm12.805-8.673c.144.52.243 1.218.31 2.104.077.887.11 1.65.11 2.315l.067.93c0 2.427-.177 4.21-.487 5.351-.277.997-.92 1.64-1.917 1.916-.52.144-1.473.244-2.935.31-1.44.078-2.758.111-3.977.111l-1.76.067c-4.642 0-7.533-.177-8.674-.488-.997-.277-1.64-.92-1.916-1.916-.144-.52-.244-1.218-.31-2.105-.078-.886-.111-1.65-.111-2.315l-.067-.93c0-2.426.177-4.21.488-5.35.276-.997.919-1.64 1.916-1.917.52-.144 1.473-.243 2.935-.31 1.44-.077 2.758-.11 3.977-.11L12.153 5c4.641 0 7.532.177 8.673.487.997.277 1.64.92 1.917 1.917Z" fill="#052D52" stroke="#fff" stroke-width="1.25"></path></svg>
            </a></span></div></div><div class="footer__bottom text--center"><div class="footer__copyright">© 2024 Neuralmagic, Inc.</div></div></div></footer></div>
</body>
</html>