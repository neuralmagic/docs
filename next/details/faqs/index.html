<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-details/faqs" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.2.1">
<title data-rh="true">FAQs | Neural Magic Documentation</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://docs.neuralmagic.com/next/details/faqs"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="FAQs | Neural Magic Documentation"><meta data-rh="true" name="description" content="General Product FAQs"><meta data-rh="true" property="og:description" content="General Product FAQs"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://docs.neuralmagic.com/next/details/faqs"><link data-rh="true" rel="alternate" href="https://docs.neuralmagic.com/next/details/faqs" hreflang="en"><link data-rh="true" rel="alternate" href="https://docs.neuralmagic.com/next/details/faqs" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://CIS4HPXHOK-dsn.algolia.net" crossorigin="anonymous"><link rel="preconnect" href="https://www.google-analytics.com">
<script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","G-L2QW513YN1","auto"),ga("set","anonymizeIp",!0),ga("send","pageview")</script>
<script async src="https://www.google-analytics.com/analytics.js"></script>


<link rel="search" type="application/opensearchdescription+xml" title="Neural Magic Documentation" href="/opensearch.xml"><link rel="stylesheet" href="/assets/css/styles.36c72404.css">
<script src="/assets/js/runtime~main.4d6099e7.js" defer="defer"></script>
<script src="/assets/js/main.8fd00312.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="Neural Magic Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo.svg" alt="Neural Magic Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Docs</b></a><div class="navbar__item dropdown dropdown--hoverable"><a aria-current="page" class="navbar__link active" aria-haspopup="true" aria-expanded="false" role="button" href="/next/">nightly</a><ul class="dropdown__menu"><li><a aria-current="page" class="dropdown__link dropdown__link--active" href="/next/details/faqs">nightly</a></li><li><a class="dropdown__link" href="/details/faqs">1.7.0</a></li></ul></div></div><div class="navbar__items navbar__items--right"><div class="navbarSearchContainer_Bca1"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20" aria-hidden="true"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">GitHub</a><ul class="dropdown__menu"><li><a href="https://github.com/neuralmagic/" target="_blank" rel="noopener noreferrer" class="dropdown__link">Neural Magic</a></li><li><a href="https://github.com/neuralmagic/docs" target="_blank" rel="noopener noreferrer" class="dropdown__link">Docs</a></li><li><a href="https://github.com/neuralmagic/deepsparse" target="_blank" rel="noopener noreferrer" class="dropdown__link">DeepSparse</a></li><li><a href="https://github.com/neuralmagic/sparseml" target="_blank" rel="noopener noreferrer" class="dropdown__link">SparseML</a></li><li><a href="https://github.com/neuralmagic/sparsezoo" target="_blank" rel="noopener noreferrer" class="dropdown__link">SparseZoo</a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">Products</a><ul class="dropdown__menu"><li><a href="https://neuralmagic.com/deepsparse" target="_blank" rel="noopener noreferrer" class="dropdown__link">DeepSparse</a></li><li><a href="https://neuralmagic.com/sparseml" target="_blank" rel="noopener noreferrer" class="dropdown__link">SparseML</a></li><li><a href="https://sparsezoo.neuralmagic.com/" target="_blank" rel="noopener noreferrer" class="dropdown__link">SparseZoo</a></li><li><a href="http://neuralmagic.com/labs" target="_blank" rel="noopener noreferrer" class="dropdown__link">Labs by Neural Magic</a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">Resources</a><ul class="dropdown__menu"><li><a href="https://neuralmagic.com/blog/" target="_blank" rel="noopener noreferrer" class="dropdown__link">Blog</a></li><li><a href="https://neuralmagic.com/support" target="_blank" rel="noopener noreferrer" class="dropdown__link">Support</a></li><li><a href="http://neuralmagic.com/resources/technical-papers/" target="_blank" rel="noopener noreferrer" class="dropdown__link">Research Papers</a></li><li><a href="http://neuralmagic.com/neural-magic-events/" target="_blank" rel="noopener noreferrer" class="dropdown__link">Upcoming Events</a></li><li><a href="http://neuralmagic.com/video" target="_blank" rel="noopener noreferrer" class="dropdown__link">NeuralFlix</a></li><li><a href="http://neuralmagic.com/technology" target="_blank" rel="noopener noreferrer" class="dropdown__link">Our Technology</a></li><li><a href="http://neuralmagic.com/deep-sparse-community" target="_blank" rel="noopener noreferrer" class="dropdown__link">Subscribe</a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">Company</a><ul class="dropdown__menu"><li><a href="http://neuralmagic.com/about" target="_blank" rel="noopener noreferrer" class="dropdown__link">Team &amp; Investors</a></li><li><a href="https://apply.workable.com/neural-magic/" target="_blank" rel="noopener noreferrer" class="dropdown__link">Careers</a></li><li><a href="http://neuralmagic.com/contact" target="_blank" rel="noopener noreferrer" class="dropdown__link">Contact</a></li><li><a href="http://neuralmagic.com/legal" target="_blank" rel="noopener noreferrer" class="dropdown__link">Legal</a></li></ul></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_BF9v"><div class="docsSideNavBackground_MOrL"></div><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_Rg9N"><aside class="theme-doc-sidebar-container docSidebarContainer_tLwi"><div class="sidebarViewport_wp6o"><div class="sidebar_mhZE"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_Y1UP"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/next/">Home</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/next/get-started/">Getting Started</a><button aria-label="Collapse sidebar category &#x27;Getting Started&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/next/get-started/install/">Install</a><button aria-label="Expand sidebar category &#x27;Install&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/next/get-started/deploy">Deploy</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/next/get-started/optimize">Optimize</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/next/get-started/finetune">Sparse Fine-Tuning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/next/get-started/transfer">Sparse Transfer</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/next/llms/">LLMs - Causal Language Modeling</a><button aria-label="Expand sidebar category &#x27;LLMs - Causal Language Modeling&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/next/computer-vision/">Computer Vision</a><button aria-label="Expand sidebar category &#x27;Computer Vision&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/next/nlp/">Natural Language Processing</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/next/guides/">Guides</a><button aria-label="Expand sidebar category &#x27;Guides&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/next/products/">Products</a><button aria-label="Expand sidebar category &#x27;Products&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" href="/next/details/">Details</a><button aria-label="Collapse sidebar category &#x27;Details&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/next/details/faqs">FAQs</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/next/details/glossary">Glossary</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/next/details/research-papers">Research Papers</a></li></ul></li></ul></nav></div></div></aside><main class="docMainContainer_Vlkt"><div class="container docItemWrapper_GJ0o"><div class="row"><div class="col docItemCol_VOVn"><div class="theme-doc-version-banner alert alert--warning margin-bottom--md" role="alert"><div>This is unreleased documentation for the <b>nightly</b> version.</div><div class="margin-top--md">For the latest released documentation, see the <b><a href="/details/faqs">current version</a></b> (<!-- -->1.7.0<!-- -->).</div></div><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/next/details/"><span itemprop="name">Details</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">FAQs</span><meta itemprop="position" content="2"></li></ul></nav><span class="theme-doc-version-badge badge badge--secondary">Version: nightly</span><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>FAQs</h1>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="general-product-faqs">General Product FAQs<a href="#general-product-faqs" class="hash-link" aria-label="Direct link to General Product FAQs" title="Direct link to General Product FAQs">​</a></h2>
<p><strong>What is Neural Magic?</strong></p>
<p>Neural Magic was founded by a team of award-winning MIT computer scientists and is funded by Amdocs, Andreessen Horowitz, Comcast Ventures, NEA, Pillar
VC, Ridgeline Partners, Verizon Ventures, and VMWare. The Neural Magic Platform includes several components, including <a href="/products/deepsparse">DeepSparse</a>, <a href="/products/sparseml">SparseML</a>, and <a href="/products/sparsezoo">SparseZoo</a>.
DeepSparse is an inference runtime offering GPU-class performance on CPUs and tooling to
integrate ML into your application. <a href="/products/sparseml">SparseML</a> and <a href="/products/sparsezoo">SparseZoo,</a> are open-source tooling and a model repository
combination that enables you to create an inference-optimized sparse-model for deployment with DeepSparse.</p>
<p>Together, these components remove the tradeoff between performance and the simplicity and scalability of software-delivered deployments.</p>
<p><em>As of 2024, Neural Magic will be announcing sparsity on GPUs to complement our CPU efforts. Stay tuned!</em></p>
<p><strong>What is DeepSparse?</strong></p>
<p>DeepSparse, created by Neural Magic, is an inference runtime for deep learning models. It delivers state of art, GPU-class performance on commodity CPUs
as well as tooling for integrating a model into an application and monitoring models in production.</p>
<p><strong>Why Neural Magic?</strong></p>
<p>Learn more about Neural Magic and DeepSparse (formerly known as the Neural Magic Inference Engine).
<a href="https://youtu.be/zJy_8uPZd0o" target="_blank" rel="noopener noreferrer">Watch the Why Neural Magic video</a></p>
<p><strong>How does Neural Magic make it work?</strong></p>
<p>This is an older webinar (50m) where we went through the process of optimizing and deploying a model; we’ve enhanced our software since
the recording went out but this will give you some background: <a href="https://youtu.be/UhmmHTsfrzI" target="_blank" rel="noopener noreferrer">Watch the How Does it Work video</a></p>
<p><strong>Does Neural Magic support training of learning models on CPUs?</strong></p>
<p>Neural Magic does not support training of deep learning models at this time. We do see value in providing a consistent CPU environment
for our end users to train and infer on for their deep learning needs, and we have added this to our engineering backlog.</p>
<p><strong>Do you run on AMD hardware?</strong></p>
<p>DeepSparse is validated to work on x86 Intel (Haswell generation and later) and AMD CPUs running Linux, with
support for AVX2, AVX-512, and VNNI instruction sets. Specific support details for some algorithms over different microarchitectures
<a href="/user-guides/deepsparse-engine/hardware-support">is available</a>.</p>
<p>We are open to opportunities to expand our support footprint for different CPU-based processor architectures, based on
market adoption and deep learning use cases.</p>
<p><strong>Do you run on ARM architecture?</strong></p>
<p>We have provided ARM support as of our 1.6 release. We primarily focused on LLMs and transformer models for server-grade systems like AWS Graviton and Ampere Currently, we have limited alpha support for CNN models on embedded systems, particularly those with dot product instructions (ARMv8.2+). ARM on MacOS has beta support. Feel free to <code>pip install deepsparse-nightly</code> if you would like to try it out. We would like to hear your use cases and keep you in the
loop! <a href="https://neuralmagic.com/contact/" target="_blank" rel="noopener noreferrer">Contact us to continue the conversation</a>.</p>
<p><strong>To what use cases is the Neural Magic Platform best suited?</strong></p>
<p>We focus on the models and use cases related to LLMs, computer vision, and NLP where there may be cost sensitivity and both real-time and throughput constraints.</p>
<p><strong>What types of models does Neural Magic support?</strong></p>
<p>Today, we offer support for LLMs, CNN-based computer vision models, specifically classification and object detection model types.
NLP models like BERT are also available. We are continuously adding models to <a href="https://sparsezoo.neuralmagic.com" target="_blank" rel="noopener noreferrer">the SparseZoo.</a>
Additionally, we are constantly investigating new model architectures.</p>
<p><strong>Is dynamic shape supported?</strong></p>
<p>Dynamic shape is currently not supported; be sure to use models with fixed inputs and compile the model for a particular batch size.
Dynamic shape and dynamic batch sizes are on the Neural Magic roadmap; <a href="https://neuralmagic.com/subscribe/" target="_blank" rel="noopener noreferrer">subscribe for updates.</a></p>
<p><strong>Can multiple model inferences be executed?</strong></p>
<p>Model inferences are executed as a single stream by default; concurrent execution <a href="/user-guides/deepsparse-engine/scheduler">can be enabled depending
on the engine execution strategy.</a></p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="benchmarking-faqs">Benchmarking FAQs<a href="#benchmarking-faqs" class="hash-link" aria-label="Direct link to Benchmarking FAQs" title="Direct link to Benchmarking FAQs">​</a></h2>
<p><strong>Do you have benchmarks to compare and contrast?</strong></p>
<p>Yes. Check out our <a href="https://neuralmagic.com/blog/neural-magic-demo/" target="_blank" rel="noopener noreferrer">benchmark demo video</a> or
<a href="https://neuralmagic.com/contact/" target="_blank" rel="noopener noreferrer">contact us</a> to discuss your particular performance requirements.
If you’d rather observe performance for yourself, <a href="https://github.com/neuralmagic" target="_blank" rel="noopener noreferrer">head over to the Neural Magic GitHub repo</a>
to check out our tools and generate your own benchmarks in your environment.</p>
<p><strong>Do you publish ML Perf inference benchmarks?</strong></p>
<p>Checkout ZDNet&#x27;s coverage of our <a href="https://www.zdnet.com/article/neural-magics-sparsity-nvidias-hopper-and-alibabas-network-among-firsts-in-latest-mlperf-ai-benchmarks/" target="_blank" rel="noopener noreferrer">results at ML Perf</a>!</p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="infrastructure-faqs">Infrastructure FAQs<a href="#infrastructure-faqs" class="hash-link" aria-label="Direct link to Infrastructure FAQs" title="Direct link to Infrastructure FAQs">​</a></h2>
<p><strong>Which instruction sets are supported and do we have to enable certain settings?</strong></p>
<p>AVX2, AVX-512, and VNNI. DeepSparse will automatically utilize the most effective available
instructions for the task. Depending on your goals and hardware priorities, optimal performance can be found.
Neural Magic is happy to discuss your use cases and offer recommendations.</p>
<p><strong>Are you suitable for edge deployments (i.e., in-store devices, cameras)?</strong></p>
<p>Yes, absolutely. We can run anywhere you have a CPU with x86 instructions, including on bare metal, in the cloud,
on-prem, or at the edge. Additionally, our model optimization tools are able to reduce the footprint of models
across all architectures. We only guarantee performance in DeepSparse.</p>
<p>We’d love to hear from users highly interested in ML performance. If you want to chat about your use cases
or how others are leveraging the Neural Magic Platform, <a href="https://neuralmagic.com/contact/" target="_blank" rel="noopener noreferrer">please contact us.</a>
Or simply head over to the <a href="https://github.com/neuralmagic" target="_blank" rel="noopener noreferrer">Neural Magic GitHub repo</a> and check out our tools.</p>
<p><strong>Do you have available solutions or applications on the Microsoft/Azure platform?</strong></p>
<p>We deploy extremely easily. We are completely infrastructure-agnostic. As long as it has the “right” CPUs
(e.g., AVX2 or AVX-512) we can run on any cloud platform, including Azure!</p>
<p><strong>Can the inference engine run on Kubernetes? How do you containerize and take advantage of underlying infrastructure?</strong></p>
<p>DeepSparse becomes a component of your model-serving solution. As a result, it can
simply plug into an existing CI/CD deployment pipeline. How you deploy, where you deploy, and what you deploy on
becomes abstracted to DeepSparse so you can tailor your experiences. For example, you can run the
DeepSparse on a CPU VM environment, deployed via a Docker file, and managed through a Kubernetes environment.</p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="model-compression-faqs">Model Compression FAQs<a href="#model-compression-faqs" class="hash-link" aria-label="Direct link to Model Compression FAQs" title="Direct link to Model Compression FAQs">​</a></h2>
<p><strong>Can you comment on how you do pruning and its effects on accuracy?</strong></p>
<p>Neural networks are extremely over-parameterized, allowing most weights to be iteratively removed from the network
without effect on accuracy. Eventually, though, pruning will begin affecting the overall capacity of the network,
the degree of which varies based on the use case. However, this is something entirely under the control of the data scientist
to choose whether to recover fully or to prune more for even better performance.</p>
<p>For example, Neural Magic has been successful in removing 95% of ResNet-50 weights with no loss in accuracy.
For more background on techniques that have informed our methodologies, check out this paper co-written by
Neural Magic, <em><a href="https://arxiv.org/abs/2004.14340" target="_blank" rel="noopener noreferrer">WoodFisher: Efficient Second-Order Approximation for Neural Network Compression.</a></em></p>
<p><strong>When does sparsification actually happen?</strong></p>
<p>In a scenario in which you want to sparsify and then run your own model with DeepSparse, you would first
sparsify your model to achieve the desired level of performance and accuracy using Neural Magic’s <a href="/products/sparseml">SparseML</a> tooling.</p>
<p><strong>What does the sparsification process look like?</strong></p>
<p>Neural Magic’s SparseML tooling, at its core, uses well-established state-of-the-art research principles such as
<a href="https://neuralmagic.com/blog/pruning-gmp/" target="_blank" rel="noopener noreferrer">Gradual Magnitude Pruning</a> (GMP) to sparsify models. This is an iterative process
in which groups of important weights are pruned away and then the network is allowed to recover. To significantly simplify the process,
we offer tools and guidance for you to achieve the best performance possible. To peruse research papers contributed by Neural Magic
staff, <a href="https://neuralmagic.com/resources/technical-papers/" target="_blank" rel="noopener noreferrer">check them out.</a> Or head over to the <a href="https://github.com/neuralmagic" target="_blank" rel="noopener noreferrer">Neural Magic GitHub repo</a>
to get started!</p>
<p><strong>How does sparsification work in relation to TensorFlow?</strong></p>
<p>Today, we are able to sparsify models trained in popular deep learning libraries like TensorFlow. Our unique approach works with the
output supplied by the model library and provides layer sparsification techniques that then can be compiled in the existing library
framework, within the user environment.</p>
<p><strong>When using your software to transfer learn, what about other hyperparameters? Are you just freezing other layers?</strong></p>
<p>For transfer learning, our tooling allows you to save the sparse architecture learned from larger datasets. Other
hyperparameters are fully under your control and allow you the flexibility to easily freeze layers as well.</p>
<p><strong>Do you support INT8 and INT16 (quantized) operations?</strong></p>
<p>DeepSparse runs at FP32 and has support for INT8.  With Intel Cascade Lake generation chips and later,
Intel CPUs include VNNI instructions and support both INT8 and INT16 operations. On these machines, performance improvements
from quantization will be greater. DeepSparse has INT8 support for the ONNX operators QLinearConv, QuantizeLinear,
DequantizeLinear, QLinearMatMul, and MatMulInteger. Our engine also supports 8-bit QLinearAdd, an ONNX Runtime custom operator.</p>
<p><strong>Do you support FP16 (half precision) and BF16 operations?</strong></p>
<p>Neural Magic is looking to include both FP16 and BF16 on our roadmap in the near future.</p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="runtime-faqs">Runtime FAQs<a href="#runtime-faqs" class="hash-link" aria-label="Direct link to Runtime FAQs" title="Direct link to Runtime FAQs">​</a></h2>
<p><strong>Do users have to do any model conversion before using DeepSparse?</strong></p>
<p>DeepSparse executes on an ONNX (Open Neural Network Exchange) representation of a deep learning model.
Our software allows you to produce an ONNX representation. If working with PyTorch, we use the built-in ONNX
export and for TensorFlow, we convert from a standard exported protobuf file to ONNX. Outside of those frameworks,
you would need to convert your model to ONNX first before passing it to DeepSparse.</p>
<p><strong>Why is ONNX the file format used by Neural Magic?</strong></p>
<p>ONNX (Open Neural Network Exchange) is emerging as a standard, open-source format for model representation.
Based on the breadth of vendors supporting ONNX as well as the health of open-source community contributions,
we believe ONNX offers a compelling solution for the market.</p>
<p><strong>Are your users using ONNX runtime already?</strong></p>
<p>End users are using a wide variety of runtimes, both open-source and proprietary. Neural Magic is focused on
ensuring we are open and flexible, to allow our users to achieve deep learning performance regardless of how
they choose to build, deploy, and run their models.</p>
<p><strong>What is the accuracy loss, if any, on the numbers Neural Magic demonstrates?</strong></p>
<p>Results will depend on your use case and specific requirements. We are capable of maintaining 100% baseline accuracy.
In cases where accuracy is not as important as performance, you can use our model optimization tools to further speed
up the model at the expense of accuracy and weigh the tradeoffs.</p>
<p>If you need sparsification, we provide the tooling for tradeoffs between accuracy and performance based on your specific requirements.</p>
<p><strong>For the runtime engine, is Neural Magic modifying the architecture in any way or just optimizing the instruction set at that level?</strong></p>
<p>Specifically for sparsification, our software keeps the architecture intact and changes the weights. For running dense, we do not change anything about the model.</p>
<p><strong>For a CPU are you using all the cores?</strong></p>
<p>DeepSparse optimizes <em>how</em> the model is run on the infrastructure resources applied to it. But, Neural
Magic does not optimize for the number of cores. You are in control to specify how much of the system Neural Magic will use and run on.
Depending on your goals (latency, throughput, and cost constraints), you can optimize your pipeline for maximum efficiency.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://github.com/neuralmagic/docs/tree/main/docs/details/faqs.mdx" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/next/details/"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Details</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/next/details/glossary"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Glossary</div></a></nav></div></div><div class="col col--3"><div class="wrapper_Y1C6"><div class="section_EsUi"><h3 class="sectionTitle_pv0_">Content</h3><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#general-product-faqs" class="table-of-contents__link toc-highlight">General Product FAQs</a></li><li><a href="#benchmarking-faqs" class="table-of-contents__link toc-highlight">Benchmarking FAQs</a></li><li><a href="#infrastructure-faqs" class="table-of-contents__link toc-highlight">Infrastructure FAQs</a></li><li><a href="#model-compression-faqs" class="table-of-contents__link toc-highlight">Model Compression FAQs</a></li><li><a href="#runtime-faqs" class="table-of-contents__link toc-highlight">Runtime FAQs</a></li></ul></div></div><div class="section_EsUi"><h3 class="sectionTitle_pv0_">Actions</h3><div class="sectionLinks_oh4b"><a href="https://github.com/neuralmagic/docs/tree/main/docs/details/faqs.mdx" target="_blank" class="link_RNAl"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 -960 960 960" class="icon_Oxux" fill="var(--ifm-toc-link-color)"><path d="M200-200h57l391-391-57-57-391 391v57Zm-80 80v-170l528-527q12-11 26.5-17t30.5-6q16 0 31 6t26 18l55 56q12 11 17.5 26t5.5 30q0 16-5.5 30.5T817-647L290-120H120Zm640-584-56-56 56 56Zm-141 85-28-29 57 57-29-28Z"></path></svg> Edit this page</a></div></div><div class="section_EsUi"><h3 class="sectionTitle_pv0_">Support</h3><div class="sectionLinks_oh4b"><li><a href="https://join.slack.com/t/discuss-neuralmagic/shared_invite/zt-2gbar46r6-2Tu~SS5iQdHgczAKlQ2jJA" target="_blank" class="link_RNAl"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 127 127" class="icon_Oxux"><path d="M27.2 80c0 7.3-5.9 13.2-13.2 13.2C6.7 93.2.8 87.3.8 80c0-7.3 5.9-13.2 13.2-13.2h13.2V80zm6.6 0c0-7.3 5.9-13.2 13.2-13.2 7.3 0 13.2 5.9 13.2 13.2v33c0 7.3-5.9 13.2-13.2 13.2-7.3 0-13.2-5.9-13.2-13.2V80z" fill="#E01E5A"></path><path d="M47 27c-7.3 0-13.2-5.9-13.2-13.2C33.8 6.5 39.7.6 47 .6c7.3 0 13.2 5.9 13.2 13.2V27H47zm0 6.7c7.3 0 13.2 5.9 13.2 13.2 0 7.3-5.9 13.2-13.2 13.2H13.9C6.6 60.1.7 54.2.7 46.9c0-7.3 5.9-13.2 13.2-13.2H47z" fill="#36C5F0"></path><path d="M99.9 46.9c0-7.3 5.9-13.2 13.2-13.2 7.3 0 13.2 5.9 13.2 13.2 0 7.3-5.9 13.2-13.2 13.2H99.9V46.9zm-6.6 0c0 7.3-5.9 13.2-13.2 13.2-7.3 0-13.2-5.9-13.2-13.2V13.8C66.9 6.5 72.8.6 80.1.6c7.3 0 13.2 5.9 13.2 13.2v33.1z" fill="#2EB67D"></path><path d="M80.1 99.8c7.3 0 13.2 5.9 13.2 13.2 0 7.3-5.9 13.2-13.2 13.2-7.3 0-13.2-5.9-13.2-13.2V99.8h13.2zm0-6.6c-7.3 0-13.2-5.9-13.2-13.2 0-7.3 5.9-13.2 13.2-13.2h33.1c7.3 0 13.2 5.9 13.2 13.2 0 7.3-5.9 13.2-13.2 13.2H80.1z" fill="#ECB22E"></path></svg> Community Slack</a><a href="https://support.neuralmagic.com" target="_blank" class="link_RNAl"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 -960 960 960" class="icon_Oxux" fill="var(--ifm-toc-link-color)"><path d="M440-120v-80h320v-284q0-117-81.5-198.5T480-764q-117 0-198.5 81.5T200-484v244h-40q-33 0-56.5-23.5T80-320v-80q0-21 10.5-39.5T120-469l3-53q8-68 39.5-126t79-101q47.5-43 109-67T480-840q68 0 129 24t109 66.5Q766-707 797-649t40 126l3 52q19 9 29.5 27t10.5 38v92q0 20-10.5 38T840-249v49q0 33-23.5 56.5T760-120H440Zm-80-280q-17 0-28.5-11.5T320-440q0-17 11.5-28.5T360-480q17 0 28.5 11.5T400-440q0 17-11.5 28.5T360-400Zm240 0q-17 0-28.5-11.5T560-440q0-17 11.5-28.5T600-480q17 0 28.5 11.5T640-440q0 17-11.5 28.5T600-400Zm-359-62q-7-106 64-182t177-76q89 0 156.5 56.5T720-519q-91-1-167.5-49T435-698q-16 80-67.5 142.5T241-462Z"></path></svg> Enterprise Support</a></li></div></div><div class="section_EsUi"><h3 class="sectionTitle_pv0_">Issues</h3><div class="sectionLinks_oh4b"><li><a href="https://github.com/neuralmagic/deepsparse/issues" target="_blank" rel="noopener noreferrer" class="link_RNAl"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1024 1024" fill="none" class="icon_Oxux"><path fill-rule="evenodd" clip-rule="evenodd" d="M8 0C3.58 0 0 3.58 0 8C0 11.54 2.29 14.53 5.47 15.59C5.87 15.66 6.02 15.42 6.02 15.21C6.02 15.02 6.01 14.39 6.01 13.72C4 14.09 3.48 13.23 3.32 12.78C3.23 12.55 2.84 11.84 2.5 11.65C2.22 11.5 1.82 11.13 2.49 11.12C3.12 11.11 3.57 11.7 3.72 11.94C4.44 13.15 5.59 12.81 6.05 12.6C6.12 12.08 6.33 11.73 6.56 11.53C4.78 11.33 2.92 10.64 2.92 7.58C2.92 6.71 3.23 5.99 3.74 5.43C3.66 5.23 3.38 4.41 3.82 3.31C3.82 3.31 4.49 3.1 6.02 4.13C6.66 3.95 7.34 3.86 8.02 3.86C8.7 3.86 9.38 3.95 10.02 4.13C11.55 3.09 12.22 3.31 12.22 3.31C12.66 4.41 12.38 5.23 12.3 5.43C12.81 5.99 13.12 6.7 13.12 7.58C13.12 10.65 11.25 11.33 9.47 11.53C9.76 11.78 10.01 12.26 10.01 13.01C10.01 14.08 10 14.94 10 15.21C10 15.42 10.15 15.67 10.55 15.59C13.71 14.53 16 11.53 16 8C16 3.58 12.42 0 8 0Z" transform="scale(64)" fill="#1B1F23"></path></svg>DeepSparse</a></li><li><a href="https://github.com/neuralmagic/sparseml/issues" target="_blank" rel="noopener noreferrer" class="link_RNAl"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1024 1024" fill="none" class="icon_Oxux"><path fill-rule="evenodd" clip-rule="evenodd" d="M8 0C3.58 0 0 3.58 0 8C0 11.54 2.29 14.53 5.47 15.59C5.87 15.66 6.02 15.42 6.02 15.21C6.02 15.02 6.01 14.39 6.01 13.72C4 14.09 3.48 13.23 3.32 12.78C3.23 12.55 2.84 11.84 2.5 11.65C2.22 11.5 1.82 11.13 2.49 11.12C3.12 11.11 3.57 11.7 3.72 11.94C4.44 13.15 5.59 12.81 6.05 12.6C6.12 12.08 6.33 11.73 6.56 11.53C4.78 11.33 2.92 10.64 2.92 7.58C2.92 6.71 3.23 5.99 3.74 5.43C3.66 5.23 3.38 4.41 3.82 3.31C3.82 3.31 4.49 3.1 6.02 4.13C6.66 3.95 7.34 3.86 8.02 3.86C8.7 3.86 9.38 3.95 10.02 4.13C11.55 3.09 12.22 3.31 12.22 3.31C12.66 4.41 12.38 5.23 12.3 5.43C12.81 5.99 13.12 6.7 13.12 7.58C13.12 10.65 11.25 11.33 9.47 11.53C9.76 11.78 10.01 12.26 10.01 13.01C10.01 14.08 10 14.94 10 15.21C10 15.42 10.15 15.67 10.55 15.59C13.71 14.53 16 11.53 16 8C16 3.58 12.42 0 8 0Z" transform="scale(64)" fill="#1B1F23"></path></svg>SparseML</a></li><li><a href="https://github.com/neuralmagic/sparsezoo/issues" target="_blank" rel="noopener noreferrer" class="link_RNAl"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1024 1024" fill="none" class="icon_Oxux"><path fill-rule="evenodd" clip-rule="evenodd" d="M8 0C3.58 0 0 3.58 0 8C0 11.54 2.29 14.53 5.47 15.59C5.87 15.66 6.02 15.42 6.02 15.21C6.02 15.02 6.01 14.39 6.01 13.72C4 14.09 3.48 13.23 3.32 12.78C3.23 12.55 2.84 11.84 2.5 11.65C2.22 11.5 1.82 11.13 2.49 11.12C3.12 11.11 3.57 11.7 3.72 11.94C4.44 13.15 5.59 12.81 6.05 12.6C6.12 12.08 6.33 11.73 6.56 11.53C4.78 11.33 2.92 10.64 2.92 7.58C2.92 6.71 3.23 5.99 3.74 5.43C3.66 5.23 3.38 4.41 3.82 3.31C3.82 3.31 4.49 3.1 6.02 4.13C6.66 3.95 7.34 3.86 8.02 3.86C8.7 3.86 9.38 3.95 10.02 4.13C11.55 3.09 12.22 3.31 12.22 3.31C12.66 4.41 12.38 5.23 12.3 5.43C12.81 5.99 13.12 6.7 13.12 7.58C13.12 10.65 11.25 11.33 9.47 11.53C9.76 11.78 10.01 12.26 10.01 13.01C10.01 14.08 10 14.94 10 15.21C10 15.42 10.15 15.67 10.55 15.59C13.71 14.53 16 11.53 16 8C16 3.58 12.42 0 8 0Z" transform="scale(64)" fill="#1B1F23"></path></svg>SparseZoo</a></li></div></div></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__links text--center"><div class="footer__links"><span class="footer__link-item">
            <a href="https://join.slack.com/t/discuss-neuralmagic/shared_invite/zt-2gbar46r6-2Tu~SS5iQdHgczAKlQ2jJA" target="_blank">
              <svg width="26" height="26" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M5.54 16.166c0 1.022-.823 1.857-1.83 1.857-1.008 0-1.831-.835-1.831-1.857s.823-1.857 1.83-1.857H5.54v1.857ZM7.223 16.166c0-1.388 1.117-2.521 2.485-2.521 1.368 0 2.485 1.133 2.485 2.521v6.313c0 1.387-1.117 2.521-2.485 2.521-1.368 0-2.485-1.134-2.485-2.521v-6.313h0ZM9.932 5.037c-1.071 0-1.947-.889-1.947-1.976s.876-1.976 1.947-1.976c1.072 0 1.948.889 1.948 1.976v1.976H9.932ZM9.708 6.673c1.368 0 2.486 1.133 2.486 2.52 0 1.389-1.118 2.522-2.486 2.522H3.485C2.117 11.715 1 10.582 1 9.194s1.117-2.521 2.485-2.521h6.223ZM20.45 9.834c0-1.087.876-1.976 1.948-1.976s1.948.889 1.948 1.976-.876 1.976-1.948 1.976h-1.947V9.834Z" fill="#052D52" stroke="#fff" stroke-width="1.25" stroke-miterlimit="10" stroke-linecap="round" stroke-linejoin="round"></path><path d="M18.777 9.834c0 1.388-1.117 2.521-2.485 2.521-1.368 0-2.485-1.133-2.485-2.521V3.521C13.807 2.134 14.924 1 16.292 1c1.368 0 2.485 1.134 2.485 2.521v6.313h0ZM16.292 20.722c1.072 0 1.947.888 1.947 1.975 0 1.088-.875 1.976-1.947 1.976s-1.948-.888-1.948-1.976v-1.975h1.948v0ZM16.292 19.025c-1.368 0-2.485-1.134-2.485-2.522 0-1.387 1.117-2.52 2.485-2.52h6.223c1.368 0 2.485 1.133 2.485 2.52 0 1.388-1.117 2.522-2.485 2.522h-6.223Z" stroke="#fff" stroke-width="1.25" stroke-miterlimit="10" stroke-linecap="round" stroke-linejoin="round"></path></svg>
            </a></span><span class="footer__link-separator">·</span><span class="footer__link-item">
            <a href="https://github.com/neuralmagic" target="_blank">
                <svg width="26" height="26" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M15.5 25a.496.496 0 0 1-.313-.111.509.509 0 0 1-.187-.395V20.73c0-.91-.115-1.555-.363-2.029a.51.51 0 0 1-.013-.446.5.5 0 0 1 .342-.282C17.93 17.281 20 15.086 20 12.636c0-1.214-.493-2.373-1.425-3.351a.51.51 0 0 1-.094-.565c.372-.811.293-1.916-.148-2.579-.583.23-1.34.713-1.832 1.304a.493.493 0 0 1-.554.149 8.576 8.576 0 0 0-5.893 0 .497.497 0 0 1-.554-.148c-.492-.59-1.249-1.073-1.833-1.304-.441.663-.52 1.768-.148 2.58.087.188.05.412-.094.563C6.493 10.263 6 11.423 6 12.635c0 2.335 1.863 4.438 4.636 5.232a.506.506 0 0 1 .364.488v.353c0 .633-.251.99-.462 1.18-.452.401-1.036.34-1.1.333h-.01c-.824 0-1.444-.464-2.043-.913-.301-.226-.606-.456-.961-.646.077.105.153.213.23.322.75 1.055 1.599 2.252 2.847 2.252h1c.276 0 .5.227.5.506v2.752a.509.509 0 0 1-.187.395.505.505 0 0 1-.421.099C4.95 23.766 1 18.785 1 13.142 1 6.447 6.383 1 13 1s12 5.447 12 12.142c0 5.642-3.95 10.624-9.392 11.846A.49.49 0 0 1 15.5 25Zm.258-6.193c.164.523.242 1.15.242 1.923v3.114c4.671-1.341 8-5.744 8-10.702 0-6.137-4.935-11.13-11-11.13S2 7.005 2 13.142c0 4.959 3.329 9.36 8 10.703v-1.597h-.5c-1.76 0-2.813-1.482-3.659-2.674-.479-.675-.975-1.373-1.341-1.373a.503.503 0 0 1-.5-.506c0-.28.224-.506.5-.506 1.74 0 2.705.723 3.48 1.305.536.402.958.718 1.52.718.056.003.263.019.379-.087.095-.087.119-.26.121-.396-3.006-.999-5-3.408-5-6.092 0-1.38.512-2.692 1.484-3.81-.429-1.258-.164-2.794.662-3.631a.49.49 0 0 1 .481-.132c.668.18 1.66.705 2.401 1.469a9.598 9.598 0 0 1 5.941 0c.741-.764 1.733-1.29 2.401-1.469a.489.489 0 0 1 .481.132c.827.837 1.091 2.373.662 3.63.975 1.12 1.487 2.43 1.487 3.81 0 2.76-2.127 5.23-5.242 6.17Z" fill="#fff" stroke="#fff" stroke-width="0.2"></path></svg>
            </a></span><span class="footer__link-separator">·</span><span class="footer__link-item">
            <a href="https://twitter.com/neuralmagic" target="_blank">
                <svg width="24" height="24" fill="none" xmlns="http://www.w3.org/2000/svg"><g clip-path="url(#twitter_svg__a)"><path d="m13.874 10.445 9.164 13.043h-5.925l-6.394-9.101-.365-.52-.42.477-8.043 9.144h-.785l8.64-9.821.26-.296-.227-.322L.962.5h5.925l6.047 8.607.365.52.42-.477L21.326.5h.785l-8.055 9.157h-.737l.554.788Zm-3.847 1.972.856 1.197.094.131 6.466 9.046.15.209h4.481l-.566-.791-7.924-11.085-.949-1.328-6.096-8.528-.15-.21H1.909l.565.792 7.554 10.567Z" fill="#fff" stroke="#fff"></path></g><defs><clipPath id="twitter_svg__a"><path fill="#fff" d="M0 0h24v24H0z"></path></clipPath></defs></svg>
            </a></span><span class="footer__link-separator">·</span><span class="footer__link-item">
            <a href="https://www.linkedin.com/company/neural-magic" target="_blank">
                <svg width="26" height="26" fill="none" xmlns="http://www.w3.org/2000/svg"><path clip-rule="evenodd" d="M22.104 14.94v6.336h-4.078V15.38c0-1.543-.637-2.595-2.04-2.595-1.073 0-1.67.71-1.947 1.394-.105.247-.088.59-.088.932v6.166h-4.04s.053-10.444 0-11.394h4.04v1.789c.239-.782 1.53-1.898 3.589-1.898 2.555 0 4.564 1.638 4.564 5.168ZM4.121 21.276h3.595V9.883H4.121v11.393ZM7.944 6.536c0 1-.764 1.794-1.99 1.794H5.93c-1.18 0-1.946-.79-1.946-1.792 0-1.021.788-1.793 1.994-1.793 1.202 0 1.942.77 1.966 1.791Z" stroke="#fff" stroke-width="1.1" stroke-linejoin="round"></path><path clip-rule="evenodd" d="M23.345 25H2.655A1.655 1.655 0 0 1 1 23.345V2.655C1 1.741 1.741 1 2.655 1h20.69C24.259 1 25 1.741 25 2.655v20.69c0 .914-.741 1.655-1.655 1.655Z" stroke="#fff" stroke-width="1.1" stroke-linejoin="round"></path></svg>
            </a></span><span class="footer__link-separator">·</span><span class="footer__link-item">
            <a href="https://www.youtube.com/channel/UCo8dO_WMGYbWCRnj_Dxr4EA" target="_blank">
                <svg width="24" height="24" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="m9.938 16.077 5.749-3.323-5.75-3.323v6.646Zm12.805-8.673c.144.52.243 1.218.31 2.104.077.887.11 1.65.11 2.315l.067.93c0 2.427-.177 4.21-.487 5.351-.277.997-.92 1.64-1.917 1.916-.52.144-1.473.244-2.935.31-1.44.078-2.758.111-3.977.111l-1.76.067c-4.642 0-7.533-.177-8.674-.488-.997-.277-1.64-.92-1.916-1.916-.144-.52-.244-1.218-.31-2.105-.078-.886-.111-1.65-.111-2.315l-.067-.93c0-2.426.177-4.21.488-5.35.276-.997.919-1.64 1.916-1.917.52-.144 1.473-.243 2.935-.31 1.44-.077 2.758-.11 3.977-.11L12.153 5c4.641 0 7.532.177 8.673.487.997.277 1.64.92 1.917 1.917Z" fill="#052D52" stroke="#fff" stroke-width="1.25"></path></svg>
            </a></span></div></div><div class="footer__bottom text--center"><div class="footer__copyright">© 2024 Neuralmagic, Inc.</div></div></div></footer></div>
</body>
</html>