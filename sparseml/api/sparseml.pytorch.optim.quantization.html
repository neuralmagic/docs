

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>sparseml.pytorch.optim.quantization package &mdash; SparseML 0.1.0 documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/copybutton.css" type="text/css" />

  
  
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/clipboard.min.js"></script>
        <script src="../_static/copybutton.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="sparseml.pytorch.utils package" href="sparseml.pytorch.utils.html" />
    <link rel="prev" title="sparseml.pytorch.optim package" href="sparseml.pytorch.optim.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> SparseML
          

          
            
            <img src="../_static/icon-sparseml.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                0.1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">General</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../quicktour.html">Quick Tour</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../recipes.html">Sparsification Recipes</a></li>
</ul>
<p class="caption"><span class="caption-text">API</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="sparseml.html">sparseml package</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="sparseml.html#subpackages">Subpackages</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="sparseml.keras.html">sparseml.keras package</a></li>
<li class="toctree-l3"><a class="reference internal" href="sparseml.onnx.html">sparseml.onnx package</a></li>
<li class="toctree-l3"><a class="reference internal" href="sparseml.optim.html">sparseml.optim package</a></li>
<li class="toctree-l3 current"><a class="reference internal" href="sparseml.pytorch.html">sparseml.pytorch package</a><ul class="current">
<li class="toctree-l4 current"><a class="reference internal" href="sparseml.pytorch.html#subpackages">Subpackages</a></li>
<li class="toctree-l4"><a class="reference internal" href="sparseml.pytorch.html#module-sparseml.pytorch">Module contents</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="sparseml.tensorflow_v1.html">sparseml.tensorflow_v1 package</a></li>
<li class="toctree-l3"><a class="reference internal" href="sparseml.utils.html">sparseml.utils package</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="sparseml.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="sparseml.html#module-sparseml.log">sparseml.log module</a></li>
<li class="toctree-l2"><a class="reference internal" href="sparseml.html#module-sparseml">Module contents</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Help</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://github.com/neuralmagic/sparseml/issues">Bugs, Feature Requests</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/neuralmagic/sparseml/discussions">Support, General Q&amp;A</a></li>
<li class="toctree-l1"><a class="reference external" href="https://docs.neuralmagic.com">Neural Magic Docs</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">SparseML</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="sparseml.html">sparseml package</a> &raquo;</li>
        
          <li><a href="sparseml.pytorch.html">sparseml.pytorch package</a> &raquo;</li>
        
          <li><a href="sparseml.pytorch.optim.html">sparseml.pytorch.optim package</a> &raquo;</li>
        
      <li>sparseml.pytorch.optim.quantization package</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/api/sparseml.pytorch.optim.quantization.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="sparseml-pytorch-optim-quantization-package">
<h1>sparseml.pytorch.optim.quantization package<a class="headerlink" href="#sparseml-pytorch-optim-quantization-package" title="Permalink to this headline">¶</a></h1>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-sparseml.pytorch.optim.quantization.helpers">
<span id="sparseml-pytorch-optim-quantization-helpers-module"></span><h2>sparseml.pytorch.optim.quantization.helpers module<a class="headerlink" href="#module-sparseml.pytorch.optim.quantization.helpers" title="Permalink to this headline">¶</a></h2>
<p>Helper functions for performing quantization aware training with PyTorch</p>
<dl class="py function">
<dt id="sparseml.pytorch.optim.quantization.helpers.add_quant_dequant">
<code class="sig-prename descclassname">sparseml.pytorch.optim.quantization.helpers.</code><code class="sig-name descname">add_quant_dequant</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">module</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/sparseml/pytorch/optim/quantization/helpers.html#add_quant_dequant"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sparseml.pytorch.optim.quantization.helpers.add_quant_dequant" title="Permalink to this definition">¶</a></dt>
<dd><p>Wraps all Conv and Linear submodule with a qconfig with a QuantWrapper
:param module: the module to modify</p>
</dd></dl>

<dl class="py function">
<dt id="sparseml.pytorch.optim.quantization.helpers.fuse_module_conv_bn_relus">
<code class="sig-prename descclassname">sparseml.pytorch.optim.quantization.helpers.</code><code class="sig-name descname">fuse_module_conv_bn_relus</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">module</span><span class="p">:</span> <span class="n">torch.nn.modules.module.Module</span></em>, <em class="sig-param"><span class="n">inplace</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">True</span></em>, <em class="sig-param"><span class="n">override_bn_subclasses_forward</span><span class="p">:</span> <span class="n">Union<span class="p">[</span>bool<span class="p">, </span>str<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">True</span></em><span class="sig-paren">)</span> &#x2192; torch.nn.modules.module.Module<a class="reference internal" href="../_modules/sparseml/pytorch/optim/quantization/helpers.html#fuse_module_conv_bn_relus"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sparseml.pytorch.optim.quantization.helpers.fuse_module_conv_bn_relus" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs fusion of Conv2d, BatchNorm2d, and ReLU layers found in the
given module. To be fused, these layers must appear sequentially in
module.named_modules() and be in the same submodule.
Fuses either Conv2d -&gt; BatchNorm2d or Conv2d -&gt; BatchNorm2d -&gt; ReLU blocks</p>
<p>If this function does not fuse the model in the desired way, implement an
in place fusing function for the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>module</strong> – the module to fuse</p></li>
<li><p><strong>inplace</strong> – set True to perform fusions in-place. default is True</p></li>
<li><p><strong>override_bn_subclasses_forward</strong> – if True, modules that are subclasses of
BatchNorm2d will be modified to be BatchNorm2d but with the forward
pass and state variables copied from the subclass. This is so these
BN modules can pass PyTorch type checking when fusing. Can set to
“override-only” and only parameters will be overwritten, not the
forward pass. Default is True</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the fused module</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="sparseml.pytorch.optim.quantization.helpers.get_qat_qconfig">
<code class="sig-prename descclassname">sparseml.pytorch.optim.quantization.helpers.</code><code class="sig-name descname">get_qat_qconfig</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; torch.quantization.qconfig.QConfig<a class="reference internal" href="../_modules/sparseml/pytorch/optim/quantization/helpers.html#get_qat_qconfig"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sparseml.pytorch.optim.quantization.helpers.get_qat_qconfig" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A QAT fake quantization config for symmetric weight quantization and
asymmetric activation quantization.  The difference between this and
torch.quantization.default_qat_qconfig is that the activation observer
will not have reduce_range enabled.</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-sparseml.pytorch.optim.quantization.quantize_qat_export">
<span id="sparseml-pytorch-optim-quantization-quantize-qat-export-module"></span><h2>sparseml.pytorch.optim.quantization.quantize_qat_export module<a class="headerlink" href="#module-sparseml.pytorch.optim.quantization.quantize_qat_export" title="Permalink to this headline">¶</a></h2>
<p>Helper functions for parsing an exported pytorch model trained with
quantization aware training.</p>
<dl class="py class">
<dt id="sparseml.pytorch.optim.quantization.quantize_qat_export.QuantizationParams">
<em class="property">class </em><code class="sig-prename descclassname">sparseml.pytorch.optim.quantization.quantize_qat_export.</code><code class="sig-name descname">QuantizationParams</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">scale</span></em>, <em class="sig-param"><span class="n">zero_point</span></em>, <em class="sig-param"><span class="n">target</span></em><span class="sig-paren">)</span><a class="headerlink" href="#sparseml.pytorch.optim.quantization.quantize_qat_export.QuantizationParams" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></p>
<dl class="py method">
<dt id="sparseml.pytorch.optim.quantization.quantize_qat_export.QuantizationParams.scale">
<em class="property">property </em><code class="sig-name descname">scale</code><a class="headerlink" href="#sparseml.pytorch.optim.quantization.quantize_qat_export.QuantizationParams.scale" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

<dl class="py method">
<dt id="sparseml.pytorch.optim.quantization.quantize_qat_export.QuantizationParams.target">
<em class="property">property </em><code class="sig-name descname">target</code><a class="headerlink" href="#sparseml.pytorch.optim.quantization.quantize_qat_export.QuantizationParams.target" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

<dl class="py method">
<dt id="sparseml.pytorch.optim.quantization.quantize_qat_export.QuantizationParams.zero_point">
<em class="property">property </em><code class="sig-name descname">zero_point</code><a class="headerlink" href="#sparseml.pytorch.optim.quantization.quantize_qat_export.QuantizationParams.zero_point" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="sparseml.pytorch.optim.quantization.quantize_qat_export.get_quantization_params">
<code class="sig-prename descclassname">sparseml.pytorch.optim.quantization.quantize_qat_export.</code><code class="sig-name descname">get_quantization_params</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model</span><span class="p">:</span> <span class="n">onnx.onnx_ONNX_REL_1_6_ml_pb2.ModelProto</span></em>, <em class="sig-param"><span class="n">node</span><span class="p">:</span> <span class="n">onnx.onnx_ONNX_REL_1_6_ml_pb2.NodeProto</span></em>, <em class="sig-param"><span class="n">include_target</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">False</span></em><span class="sig-paren">)</span> &#x2192; <a class="reference internal" href="#sparseml.pytorch.optim.quantization.quantize_qat_export.QuantizationParams" title="sparseml.pytorch.optim.quantization.quantize_qat_export.QuantizationParams">sparseml.pytorch.optim.quantization.quantize_qat_export.QuantizationParams</a><a class="reference internal" href="../_modules/sparseml/pytorch/optim/quantization/quantize_qat_export.html#get_quantization_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sparseml.pytorch.optim.quantization.quantize_qat_export.get_quantization_params" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – ONNX model to read from</p></li>
<li><p><strong>node</strong> – A QuantizeLinear or DequantizeLinear Node</p></li>
<li><p><strong>include_target</strong> – Set True include quantization target. If False,
target value will be returned as None. Default is None</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>QuantizationParams object with scale and zero point, will include the
quantization target if it is an initializer otherwise target will be None</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="sparseml.pytorch.optim.quantization.quantize_qat_export.quantize_torch_qat_export">
<code class="sig-prename descclassname">sparseml.pytorch.optim.quantization.quantize_qat_export.</code><code class="sig-name descname">quantize_torch_qat_export</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model</span><span class="p">:</span> <span class="n">Union<span class="p">[</span>onnx.onnx_ONNX_REL_1_6_ml_pb2.ModelProto<span class="p">, </span>str<span class="p">]</span></span></em>, <em class="sig-param"><span class="n">output_file_path</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>str<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">inplace</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">True</span></em><span class="sig-paren">)</span> &#x2192; onnx.onnx_ONNX_REL_1_6_ml_pb2.ModelProto<a class="reference internal" href="../_modules/sparseml/pytorch/optim/quantization/quantize_qat_export.html#quantize_torch_qat_export"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sparseml.pytorch.optim.quantization.quantize_qat_export.quantize_torch_qat_export" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – The model to convert, or a file path to it</p></li>
<li><p><strong>output_file_path</strong> – File path to save the converted model to</p></li>
<li><p><strong>inplace</strong> – If true, does conversion of model in place. Default is true</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Converts a model exported from a torch QAT session from a QAT graph with
fake quantize ops surrounding operations to a quantized graph with quantized
operations. All quantized Convs and FC inputs and outputs be surrounded by
fake quantize ops</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-sparseml.pytorch.optim.quantization">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-sparseml.pytorch.optim.quantization" title="Permalink to this headline">¶</a></h2>
<p>Tools for quantizing and exporting PyTorch models</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="sparseml.pytorch.utils.html" class="btn btn-neutral float-right" title="sparseml.pytorch.utils package" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="sparseml.pytorch.optim.html" class="btn btn-neutral float-left" title="sparseml.pytorch.optim package" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021 - present / Neuralmagic, Inc. All Rights Reserved. Licensed under the Apache License, Version 2.0 (the &#34;License&#34;).

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-128364174-1', 'auto');
    
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>