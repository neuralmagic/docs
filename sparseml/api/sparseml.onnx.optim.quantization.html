

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>sparseml.onnx.optim.quantization package &mdash; SparseML 0.1.0 documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/copybutton.css" type="text/css" />

  
  
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/clipboard.min.js"></script>
        <script src="../_static/copybutton.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="sparseml.onnx.utils package" href="sparseml.onnx.utils.html" />
    <link rel="prev" title="sparseml.onnx.optim package" href="sparseml.onnx.optim.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> SparseML
          

          
            
            <img src="../_static/icon-sparseml.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                0.1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">General</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../quicktour.html">Quick Tour</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../recipes.html">Sparsification Recipes</a></li>
</ul>
<p class="caption"><span class="caption-text">API</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="sparseml.html">sparseml package</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="sparseml.html#subpackages">Subpackages</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="sparseml.keras.html">sparseml.keras package</a></li>
<li class="toctree-l3 current"><a class="reference internal" href="sparseml.onnx.html">sparseml.onnx package</a><ul class="current">
<li class="toctree-l4 current"><a class="reference internal" href="sparseml.onnx.html#subpackages">Subpackages</a></li>
<li class="toctree-l4"><a class="reference internal" href="sparseml.onnx.html#module-sparseml.onnx">Module contents</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="sparseml.optim.html">sparseml.optim package</a></li>
<li class="toctree-l3"><a class="reference internal" href="sparseml.pytorch.html">sparseml.pytorch package</a></li>
<li class="toctree-l3"><a class="reference internal" href="sparseml.tensorflow_v1.html">sparseml.tensorflow_v1 package</a></li>
<li class="toctree-l3"><a class="reference internal" href="sparseml.utils.html">sparseml.utils package</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="sparseml.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="sparseml.html#module-sparseml.log">sparseml.log module</a></li>
<li class="toctree-l2"><a class="reference internal" href="sparseml.html#module-sparseml">Module contents</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Help</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://github.com/neuralmagic/sparseml/issues">Bugs, Feature Requests</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/neuralmagic/sparseml/discussions">Support, General Q&amp;A</a></li>
<li class="toctree-l1"><a class="reference external" href="https://docs.neuralmagic.com">Neural Magic Docs</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">SparseML</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="sparseml.html">sparseml package</a> &raquo;</li>
        
          <li><a href="sparseml.onnx.html">sparseml.onnx package</a> &raquo;</li>
        
          <li><a href="sparseml.onnx.optim.html">sparseml.onnx.optim package</a> &raquo;</li>
        
      <li>sparseml.onnx.optim.quantization package</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/api/sparseml.onnx.optim.quantization.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="sparseml-onnx-optim-quantization-package">
<h1>sparseml.onnx.optim.quantization package<a class="headerlink" href="#sparseml-onnx-optim-quantization-package" title="Permalink to this headline">¶</a></h1>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-sparseml.onnx.optim.quantization.calibration">
<span id="sparseml-onnx-optim-quantization-calibration-module"></span><h2>sparseml.onnx.optim.quantization.calibration module<a class="headerlink" href="#module-sparseml.onnx.optim.quantization.calibration" title="Permalink to this headline">¶</a></h2>
<p>Provides a class for performing quantization calibration on an Onnx model.</p>
<dl class="py class">
<dt id="sparseml.onnx.optim.quantization.calibration.CalibrationSession">
<em class="property">class </em><code class="sig-prename descclassname">sparseml.onnx.optim.quantization.calibration.</code><code class="sig-name descname">CalibrationSession</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">onnx_file</span><span class="p">:</span> <span class="n">str</span></em>, <em class="sig-param"><span class="n">calibrate_op_types</span><span class="p">:</span> <span class="n">Iterable<span class="p">[</span>str<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">('Conv', 'MatMul', 'Gemm')</span></em>, <em class="sig-param"><span class="n">exclude_nodes</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>List<span class="p">[</span>str<span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">include_nodes</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>List<span class="p">[</span>str<span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">augmented_model_path</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>str<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">static</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">True</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/sparseml/onnx/optim/quantization/calibration.html#CalibrationSession"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sparseml.onnx.optim.quantization.calibration.CalibrationSession" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Class for performing quantization calibration on an Onnx model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>onnx_file</strong> – File path to saved Onnx model to calibrate</p></li>
<li><p><strong>calibrate_op_types</strong> – List of Onnx ops names to calibrate and quantize within
the model. Currently Onnx only supports quantizing ‘Conv’ and ‘MatMul’ ops.</p></li>
<li><p><strong>exclude_nodes</strong> – List of operator names that should not be quantized</p></li>
<li><p><strong>include_nodes</strong> – List of operator names to force to be quantized</p></li>
<li><p><strong>augmented_model_path</strong> – file path to save augmented model to for verification</p></li>
<li><p><strong>static</strong> – True to use static quantization. Default is True</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="sparseml.onnx.optim.quantization.calibration.CalibrationSession.add_reduce_to_node_output">
<code class="sig-name descname">add_reduce_to_node_output</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">node</span><span class="p">:</span> <span class="n">onnx.onnx_ONNX_REL_1_6_ml_pb2.NodeProto</span></em>, <em class="sig-param"><span class="n">output_edge</span><span class="p">:</span> <span class="n">str</span></em>, <em class="sig-param"><span class="n">op_type</span><span class="p">:</span> <span class="n">str</span></em><span class="sig-paren">)</span> &#x2192; Tuple<span class="p">[</span>onnx.onnx_ONNX_REL_1_6_ml_pb2.NodeProto<span class="p">, </span>onnx.onnx_ONNX_REL_1_6_ml_pb2.ValueInfoProto<span class="p">]</span><a class="reference internal" href="../_modules/sparseml/onnx/optim/quantization/calibration.html#CalibrationSession.add_reduce_to_node_output"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sparseml.onnx.optim.quantization.calibration.CalibrationSession.add_reduce_to_node_output" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>node</strong> – the node to add the reduce op to</p></li>
<li><p><strong>output_edge</strong> – the output of node to generate reduce op for</p></li>
<li><p><strong>op_type</strong> – the reduce operation name</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a tuple of the reduce operation node and its output</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="sparseml.onnx.optim.quantization.calibration.CalibrationSession.generate_augmented_model">
<code class="sig-name descname">generate_augmented_model</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; onnx.onnx_ONNX_REL_1_6_ml_pb2.ModelProto<a class="reference internal" href="../_modules/sparseml/onnx/optim/quantization/calibration.html#CalibrationSession.generate_augmented_model"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sparseml.onnx.optim.quantization.calibration.CalibrationSession.generate_augmented_model" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>return: A new Onnx model with ReduceMin and ReduceMax nodes added to all</dt><dd><p>quantizable nodes in the original model and ensures their outputs are
stored as part of the graph output.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="sparseml.onnx.optim.quantization.calibration.CalibrationSession.get_model_input_names">
<code class="sig-name descname">get_model_input_names</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; List<span class="p">[</span>str<span class="p">]</span><a class="reference internal" href="../_modules/sparseml/onnx/optim/quantization/calibration.html#CalibrationSession.get_model_input_names"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sparseml.onnx.optim.quantization.calibration.CalibrationSession.get_model_input_names" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>List of input names to the model</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="sparseml.onnx.optim.quantization.calibration.CalibrationSession.get_quantization_params_dict">
<code class="sig-name descname">get_quantization_params_dict</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; Dict<span class="p">[</span>str<span class="p">, </span>List<span class="p">[</span>Union<span class="p">[</span>int<span class="p">, </span>float<span class="p">]</span><span class="p">]</span><span class="p">]</span><a class="reference internal" href="../_modules/sparseml/onnx/optim/quantization/calibration.html#CalibrationSession.get_quantization_params_dict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sparseml.onnx.optim.quantization.calibration.CalibrationSession.get_quantization_params_dict" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A dictionary of quantization parameters based on the original
model and calibrated quantization thresholds from runs of the
process_batch function.  The format of the dictionary will be:
{“param_name”: [zero_point, scale]}</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="sparseml.onnx.optim.quantization.calibration.CalibrationSession.model">
<em class="property">property </em><code class="sig-name descname">model</code><a class="headerlink" href="#sparseml.onnx.optim.quantization.calibration.CalibrationSession.model" title="Permalink to this definition">¶</a></dt>
<dd><p>The loaded model, if optimization has run,
will be the optimized version</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>return</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="sparseml.onnx.optim.quantization.calibration.CalibrationSession.model_augmented">
<em class="property">property </em><code class="sig-name descname">model_augmented</code><a class="headerlink" href="#sparseml.onnx.optim.quantization.calibration.CalibrationSession.model_augmented" title="Permalink to this definition">¶</a></dt>
<dd><p>The augmented model, if optimization has run,
will be the optimized version</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>return</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="sparseml.onnx.optim.quantization.calibration.CalibrationSession.process_batch">
<code class="sig-name descname">process_batch</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">input_batch</span><span class="p">:</span> <span class="n">Dict<span class="p">[</span>str<span class="p">, </span>numpy.ndarray<span class="p">]</span></span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../_modules/sparseml/onnx/optim/quantization/calibration.html#CalibrationSession.process_batch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sparseml.onnx.optim.quantization.calibration.CalibrationSession.process_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>Updates the model’s calibration thresholds based on a run of the input batch</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>input_batch</strong> – Dictionary of pre-processed model input batch to use, with
input names mapped to a numpy array of the batch</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-sparseml.onnx.optim.quantization.quantize">
<span id="sparseml-onnx-optim-quantization-quantize-module"></span><h2>sparseml.onnx.optim.quantization.quantize module<a class="headerlink" href="#module-sparseml.onnx.optim.quantization.quantize" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="sparseml.onnx.optim.quantization.quantize.ONNXQuantizer">
<em class="property">class </em><code class="sig-prename descclassname">sparseml.onnx.optim.quantization.quantize.</code><code class="sig-name descname">ONNXQuantizer</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model</span></em>, <em class="sig-param"><span class="n">per_channel</span></em>, <em class="sig-param"><span class="n">mode</span></em>, <em class="sig-param"><span class="n">static</span></em>, <em class="sig-param"><span class="n">fuse_dynamic_quant</span></em>, <em class="sig-param"><span class="n">weight_qType</span></em>, <em class="sig-param"><span class="n">input_qType</span></em>, <em class="sig-param"><span class="n">quantization_params</span></em>, <em class="sig-param"><span class="n">nodes_to_quantize</span></em>, <em class="sig-param"><span class="n">nodes_to_exclude</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/sparseml/onnx/optim/quantization/quantize.html#ONNXQuantizer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sparseml.onnx.optim.quantization.quantize.ONNXQuantizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="py method">
<dt id="sparseml.onnx.optim.quantization.quantize.ONNXQuantizer.find_weight_data">
<code class="sig-name descname">find_weight_data</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">initializer</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/sparseml/onnx/optim/quantization/quantize.html#ONNXQuantizer.find_weight_data"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sparseml.onnx.optim.quantization.quantize.ONNXQuantizer.find_weight_data" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>initializer</strong> – TensorProto initializer object from a graph</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a list of initialized data in a given initializer object</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="sparseml.onnx.optim.quantization.quantize.ONNXQuantizer.quantize_model">
<code class="sig-name descname">quantize_model</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/sparseml/onnx/optim/quantization/quantize.html#ONNXQuantizer.quantize_model"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sparseml.onnx.optim.quantization.quantize.ONNXQuantizer.quantize_model" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="sparseml.onnx.optim.quantization.quantize.QuantizationMode">
<em class="property">class </em><code class="sig-prename descclassname">sparseml.onnx.optim.quantization.quantize.</code><code class="sig-name descname">QuantizationMode</code><a class="reference internal" href="../_modules/sparseml/onnx/optim/quantization/quantize.html#QuantizationMode"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sparseml.onnx.optim.quantization.quantize.QuantizationMode" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="py attribute">
<dt id="sparseml.onnx.optim.quantization.quantize.QuantizationMode.IntegerOps">
<code class="sig-name descname">IntegerOps</code><em class="property"> = 0</em><a class="headerlink" href="#sparseml.onnx.optim.quantization.quantize.QuantizationMode.IntegerOps" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="sparseml.onnx.optim.quantization.quantize.QuantizationMode.QLinearOps">
<code class="sig-name descname">QLinearOps</code><em class="property"> = 1</em><a class="headerlink" href="#sparseml.onnx.optim.quantization.quantize.QuantizationMode.QLinearOps" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="sparseml.onnx.optim.quantization.quantize.QuantizedInitializer">
<em class="property">class </em><code class="sig-prename descclassname">sparseml.onnx.optim.quantization.quantize.</code><code class="sig-name descname">QuantizedInitializer</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">name</span></em>, <em class="sig-param"><span class="n">initializer</span></em>, <em class="sig-param"><span class="n">rmins</span></em>, <em class="sig-param"><span class="n">rmaxs</span></em>, <em class="sig-param"><span class="n">zero_points</span></em>, <em class="sig-param"><span class="n">scales</span></em>, <em class="sig-param"><span class="n">data</span><span class="o">=</span><span class="default_value">[]</span></em>, <em class="sig-param"><span class="n">quantized_data</span><span class="o">=</span><span class="default_value">[]</span></em>, <em class="sig-param"><span class="n">axis</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">qType</span><span class="o">=</span><span class="default_value">2</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/sparseml/onnx/optim/quantization/quantize.html#QuantizedInitializer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sparseml.onnx.optim.quantization.quantize.QuantizedInitializer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Represents a linearly quantized weight input from ONNX operators</p>
</dd></dl>

<dl class="py class">
<dt id="sparseml.onnx.optim.quantization.quantize.QuantizedValue">
<em class="property">class </em><code class="sig-prename descclassname">sparseml.onnx.optim.quantization.quantize.</code><code class="sig-name descname">QuantizedValue</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">name</span></em>, <em class="sig-param"><span class="n">new_quantized_name</span></em>, <em class="sig-param"><span class="n">scale_name</span></em>, <em class="sig-param"><span class="n">zero_point_name</span></em>, <em class="sig-param"><span class="n">quantized_value_type</span></em>, <em class="sig-param"><span class="n">axis</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">qType</span><span class="o">=</span><span class="default_value">2</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/sparseml/onnx/optim/quantization/quantize.html#QuantizedValue"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sparseml.onnx.optim.quantization.quantize.QuantizedValue" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Represents a linearly quantized value (input/output/intializer)</p>
</dd></dl>

<dl class="py class">
<dt id="sparseml.onnx.optim.quantization.quantize.QuantizedValueType">
<em class="property">class </em><code class="sig-prename descclassname">sparseml.onnx.optim.quantization.quantize.</code><code class="sig-name descname">QuantizedValueType</code><a class="reference internal" href="../_modules/sparseml/onnx/optim/quantization/quantize.html#QuantizedValueType"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sparseml.onnx.optim.quantization.quantize.QuantizedValueType" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="py attribute">
<dt id="sparseml.onnx.optim.quantization.quantize.QuantizedValueType.Initializer">
<code class="sig-name descname">Initializer</code><em class="property"> = 1</em><a class="headerlink" href="#sparseml.onnx.optim.quantization.quantize.QuantizedValueType.Initializer" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="sparseml.onnx.optim.quantization.quantize.QuantizedValueType.Input">
<code class="sig-name descname">Input</code><em class="property"> = 0</em><a class="headerlink" href="#sparseml.onnx.optim.quantization.quantize.QuantizedValueType.Input" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt id="sparseml.onnx.optim.quantization.quantize.check_opset_version">
<code class="sig-prename descclassname">sparseml.onnx.optim.quantization.quantize.</code><code class="sig-name descname">check_opset_version</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">org_model</span></em>, <em class="sig-param"><span class="n">force_fusions</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/sparseml/onnx/optim/quantization/quantize.html#check_opset_version"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sparseml.onnx.optim.quantization.quantize.check_opset_version" title="Permalink to this definition">¶</a></dt>
<dd><p>Check opset version of original model and set opset version and fuse_dynamic_quant accordingly.
If opset version &lt; 10, set quantized model opset version to 10.
If opset version == 10, do quantization without using dynamicQuantizeLinear operator.
If opset version == 11, do quantization using dynamicQuantizeLinear operator.
:return: fuse_dynamic_quant boolean value.</p>
</dd></dl>

<dl class="py function">
<dt id="sparseml.onnx.optim.quantization.quantize.quantize">
<code class="sig-prename descclassname">sparseml.onnx.optim.quantization.quantize.</code><code class="sig-name descname">quantize</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model</span></em>, <em class="sig-param"><span class="n">per_channel</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">nbits</span><span class="o">=</span><span class="default_value">8</span></em>, <em class="sig-param"><span class="n">quantization_mode</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">static</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">force_fusions</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">symmetric_activation</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">symmetric_weight</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">quantization_params</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">nodes_to_quantize</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">nodes_to_exclude</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/sparseml/onnx/optim/quantization/quantize.html#quantize"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sparseml.onnx.optim.quantization.quantize.quantize" title="Permalink to this definition">¶</a></dt>
<dd><blockquote>
<div><p>Given an onnx model, create a quantized onnx model and save it into a file</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – ModelProto to quantize</p></li>
<li><p><strong>per_channel</strong> – quantize weights per channel</p></li>
<li><p><strong>nbits</strong> – number of bits to represent quantized data. Currently only supporting 8-bit types</p></li>
<li><p><strong>quantization_mode</strong> – <p>Can be one of the QuantizationMode types.
IntegerOps:</p>
<blockquote>
<div><p>the function will use integer ops. Only ConvInteger and MatMulInteger ops are supported now.</p>
</div></blockquote>
<dl class="simple">
<dt>QLinearOps:</dt><dd><p>the function will use QLinear ops. Only QLinearConv and QLinearMatMul ops are supported now.</p>
</dd>
</dl>
</p></li>
<li><p><strong>static</strong> – <dl class="simple">
<dt>True: The inputs/activations are quantized using static scale and zero point values</dt><dd><p>specified through quantization_params.</p>
</dd>
<dt>False: The inputs/activations are quantized using dynamic scale and zero point values</dt><dd><p>computed while running the model.</p>
</dd>
</dl>
</p></li>
<li><p><strong>force_fusions</strong> – True: Fuses nodes added for dynamic quantization
False: No fusion is applied for nodes which are added for dynamic quantization.
Should be only used in cases where backends want to apply special fusion routines</p></li>
<li><p><strong>symmetric_activation</strong> – True: activations are quantized into signed integers.
False: activations are quantized into unsigned integers.</p></li>
<li><p><strong>symmetric_weight</strong> – True: weights are quantized into signed integers.
False: weights are quantized into unsigned integers.</p></li>
<li><p><strong>quantization_params</strong> – <p>Dictionary to specify the zero point and scale values for inputs to conv and matmul nodes.
Should be specified when static is set to True.
The quantization_params should be specified in the following format:</p>
<blockquote>
<div><dl class="simple">
<dt>{</dt><dd><p>“input_name”: [zero_point, scale]</p>
</dd>
</dl>
<p>}.</p>
</div></blockquote>
<p>zero_point should be of type np.uint8 and scale should be of type np.float32.
example:</p>
<blockquote>
<div><dl class="simple">
<dt>{</dt><dd><p>‘resnet_model/Relu_1:0’: [np.uint8(0), np.float32(0.019539741799235344)],
‘resnet_model/Relu_2:0’: [np.uint8(0), np.float32(0.011359662748873234)]</p>
</dd>
</dl>
<p>}</p>
</div></blockquote>
</p></li>
<li><p><strong>nodes_to_quantize</strong> – <p>List of nodes names to quantize. When this list is not None only the nodes in this list
are quantized.
example:
[</p>
<blockquote>
<div><p>’Conv__224’,
‘Conv__252’</p>
</div></blockquote>
<p>]</p>
</p></li>
<li><p><strong>nodes_to_exclude</strong> – List of nodes names to exclude. The nodes in this list will be excluded from quantization
when it is not None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>ModelProto with quantization</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="sparseml.onnx.optim.quantization.quantize.quantize_data">
<code class="sig-prename descclassname">sparseml.onnx.optim.quantization.quantize.</code><code class="sig-name descname">quantize_data</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">quantize_range</span></em>, <em class="sig-param"><span class="n">qType</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/sparseml/onnx/optim/quantization/quantize.html#quantize_data"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sparseml.onnx.optim.quantization.quantize.quantize_data" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> – data to quantize</p></li>
<li><p><strong>quantize_range</strong> – list of data to weight pack.</p></li>
<li><p><strong>qType</strong> – data type to quantize to. Supported types UINT8 and INT8</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>minimum, maximum, zero point, scale, and quantized weights</p>
</dd>
</dl>
<dl class="simple">
<dt>To pack weights, we compute a linear transformation</dt><dd><ul class="simple">
<li><p>when data type == uint8 mode, from [rmin, rmax] -&gt; [0, 2^{b-1}] and</p></li>
<li><dl class="simple">
<dt>when data type == int8, from [-m , m] -&gt; [-(2^{b-1}-1), 2^{b-1}-1] where</dt><dd><p>m = max(abs(rmin), abs(rmax))</p>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
<p>and add necessary intermediate nodes to trasnform quantized weight to full weight using the equation
r = S(q-z), where</p>
<blockquote>
<div><p>r: real original value
q: quantized value
S: scale
z: zero point</p>
</div></blockquote>
</dd></dl>

</div>
<div class="section" id="module-sparseml.onnx.optim.quantization.quantize_model_post_training">
<span id="sparseml-onnx-optim-quantization-quantize-model-post-training-module"></span><h2>sparseml.onnx.optim.quantization.quantize_model_post_training module<a class="headerlink" href="#module-sparseml.onnx.optim.quantization.quantize_model_post_training" title="Permalink to this headline">¶</a></h2>
<p>Provides a wrapper function for calibrating and quantizing an Onnx model</p>
<dl class="py function">
<dt id="sparseml.onnx.optim.quantization.quantize_model_post_training.quantize_model_post_training">
<code class="sig-prename descclassname">sparseml.onnx.optim.quantization.quantize_model_post_training.</code><code class="sig-name descname">quantize_model_post_training</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">onnx_file</span><span class="p">:</span> <span class="n">str</span></em>, <em class="sig-param"><span class="n">data_loader</span><span class="p">:</span> <span class="n"><a class="reference internal" href="sparseml.onnx.utils.html#sparseml.onnx.utils.data.DataLoader" title="sparseml.onnx.utils.data.DataLoader">sparseml.onnx.utils.data.DataLoader</a></span></em>, <em class="sig-param"><span class="n">output_model_path</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>str<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">calibrate_op_types</span><span class="p">:</span> <span class="n">Iterable<span class="p">[</span>str<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">('Conv', 'MatMul', 'Gemm')</span></em>, <em class="sig-param"><span class="n">exclude_nodes</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>List<span class="p">[</span>str<span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">include_nodes</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>List<span class="p">[</span>str<span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">augmented_model_path</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>str<span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">static</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">True</span></em>, <em class="sig-param"><span class="n">symmetric_weight</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">False</span></em>, <em class="sig-param"><span class="n">force_fusions</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">False</span></em>, <em class="sig-param"><span class="n">show_progress</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">True</span></em>, <em class="sig-param"><span class="n">run_extra_opt</span><span class="p">:</span> <span class="n">bool</span> <span class="o">=</span> <span class="default_value">True</span></em><span class="sig-paren">)</span> &#x2192; Union<span class="p">[</span>None<span class="p">, </span>onnx.onnx_ONNX_REL_1_6_ml_pb2.ModelProto<span class="p">]</span><a class="reference internal" href="../_modules/sparseml/onnx/optim/quantization/quantize_model_post_training.html#quantize_model_post_training"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sparseml.onnx.optim.quantization.quantize_model_post_training.quantize_model_post_training" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrapper function for calibrating and quantizing an Onnx model</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>onnx_file</strong> – File path to saved Onnx model to calibrate and quantize</p></li>
<li><p><strong>data_loader</strong> – Iterable of lists of model inputs or filepath to directory
of numpy arrays. If the model has multiple inputs and an .npz file is
provided, the function will try to extract each input from the .npz file
by name.  If the names do not match, the function will try to extract the
inputs in order.  Will raise an exception of the number of inputs does not
match the number of arrays in the .npz file.</p></li>
<li><p><strong>output_model_path</strong> – Filepath to where the quantized model should be saved to.
If not provided, then the quantized Onnx model object will be returned instead.</p></li>
<li><p><strong>calibrate_op_types</strong> – List of Onnx ops names to calibrate and quantize within
the model. Currently Onnx only supports quantizing ‘Conv’ and ‘MatMul’ ops.</p></li>
<li><p><strong>exclude_nodes</strong> – List of operator names that should not be quantized</p></li>
<li><p><strong>include_nodes</strong> – List of operator names force to be quantized</p></li>
<li><p><strong>augmented_model_path</strong> – file path to save augmented model to for verification</p></li>
<li><p><strong>static</strong> – True to use static quantization. Default is static.</p></li>
<li><p><strong>symmetric_weight</strong> – True to use symmetric weight quantization.
Default is False</p></li>
<li><p><strong>force_fusions</strong> – True to force fusions in quantization. Default is False</p></li>
<li><p><strong>show_progress</strong> – If true, will display a tqdm progress bar during calibration.
Default is True</p></li>
<li><p><strong>run_extra_opt</strong> – If true, will run additional optimizations on the quantized
model. Currently the only optimization is quantizing identity relu outputs in
ResNet blocks</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>None or quantized onnx model object if output_model_path is not provided</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-sparseml.onnx.optim.quantization">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-sparseml.onnx.optim.quantization" title="Permalink to this headline">¶</a></h2>
<p>Post training quantization tools for quantizing and calibrating onnx models.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="sparseml.onnx.utils.html" class="btn btn-neutral float-right" title="sparseml.onnx.utils package" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="sparseml.onnx.optim.html" class="btn btn-neutral float-left" title="sparseml.onnx.optim package" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021 - present / Neuralmagic, Inc. All Rights Reserved. Licensed under the Apache License, Version 2.0 (the &#34;License&#34;).

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-128364174-1', 'auto');
    
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>