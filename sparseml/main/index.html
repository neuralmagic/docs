

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Overview &mdash; SparseML 0.4.0.20210526 documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/nm-theme-adjustment.css" type="text/css" />

  
  
    <link rel="shortcut icon" href="_static/favicon.ico"/>
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/clipboard.min.js"></script>
        <script src="_static/copybutton.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Installation" href="source/installation.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="#" class="icon icon-home"> SparseML
          

          
            
            <img src="_static/icon-sparseml.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                0.4
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">General</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="source/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="source/code.html">Sparsification Code</a></li>
<li class="toctree-l1"><a class="reference internal" href="source/recipes.html">Sparsification Recipes</a></li>
<li class="toctree-l1"><a class="reference internal" href="source/onnx_export.html">ONNX Export</a></li>
</ul>
<p class="caption"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="api/sparseml.html">sparseml package</a></li>
</ul>
<p class="caption"><span class="caption-text">Connect Online</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://github.com/neuralmagic/sparseml/issues">Bugs, Feature Requests</a></li>
<li class="toctree-l1"><a class="reference external" href="https://discuss.neuralmagic.com/">Support, General Q&amp;A Forums</a></li>
<li class="toctree-l1"><a class="reference external" href="https://join.slack.com/t/discuss-neuralmagic/shared_invite/zt-q1a1cnvo-YBoICSIw3L1dmQpjBeDurQ">Deep Sparse Community Slack</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/neuralmagic">Neural Magic GitHub</a></li>
<li class="toctree-l1"><a class="reference external" href="https://docs.neuralmagic.com">Neural Magic Docs</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="#">SparseML</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="#" class="icon icon-home"></a> &raquo;</li>
        
      <li>Overview</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/index.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <!--
Copyright (c) 2021 - present / Neuralmagic, Inc. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing,
software distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
--><h1><img alt="tool icon" src="https://raw.githubusercontent.com/neuralmagic/sparseml/main/docs/source/icon-sparseml.png" />&nbsp;&nbsp;SparseML</h1><h3>Libraries for applying sparsification recipes to neural networks with a few lines of code, enabling faster and smaller models</h3><p>
    <a href="https://docs.neuralmagic.com/sparseml/">
        <img alt="Documentation" src="https://img.shields.io/badge/documentation-darkred?&style=for-the-badge&logo=read-the-docs" height=25>
    </a>
    <a href="https://join.slack.com/t/discuss-neuralmagic/shared_invite/zt-q1a1cnvo-YBoICSIw3L1dmQpjBeDurQ/">
        <img src="https://img.shields.io/badge/slack-purple?style=for-the-badge&logo=slack" height=25>
    </a>
    <a href="https://discuss.neuralmagic.com/">
        <img src="https://img.shields.io/badge/support%20forums-navy?style=for-the-badge&logo=discourse" height=25>
    </a>
    <a href="https://github.com/neuralmagic/sparseml/actions/workflows/test-check.yaml">
        <img alt="Main" src="https://img.shields.io/github/workflow/status/neuralmagic/sparseml/Test%20Checks/main?label=build&style=for-the-badge" height=25>
    </a>
    <a href="https://github.com/neuralmagic/sparseml/releases">
        <img alt="GitHub release" src="https://img.shields.io/github/release/neuralmagic/sparseml.svg?style=for-the-badge" height=25>
    </a>
    <a href="https://github.com/neuralmagic/sparseml/blob/main/LICENSE">
        <img alt="GitHub" src="https://img.shields.io/github/license/neuralmagic/sparseml.svg?color=lightgray&style=for-the-badge" height=25>
    </a>
    <a href="https://github.com/neuralmagic/sparseml/blob/main/CODE_OF_CONDUCT.md">
        <img alt="Contributor Covenant" src="https://img.shields.io/badge/Contributor%20Covenant-v2.0%20adopted-ff69b4.svg?color=yellow&style=for-the-badge" height=25>
    </a>
    <a href="https://www.youtube.com/channel/UCo8dO_WMGYbWCRnj_Dxr4EA">
        <img src="https://img.shields.io/badge/-YouTube-red?&style=for-the-badge&logo=youtube&logoColor=white" height=25>
    </a>
     <a href="https://medium.com/limitlessai">
        <img src="https://img.shields.io/badge/medium-%2312100E.svg?&style=for-the-badge&logo=medium&logoColor=white" height=25>
    </a>
    <a href="https://twitter.com/neuralmagic">
        <img src="https://img.shields.io/twitter/follow/neuralmagic?color=darkgreen&label=Follow&style=social" height=25>
    </a>
</p><div class="section" id="overview">
<h1>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">¶</a></h1>
<p>SparseML is a toolkit that includes APIs, CLIs, scripts and libraries that apply state-of-the-art <a class="reference external" href="https://docs.neuralmagic.com/main/source/getstarted.html#sparsification">sparsification</a> algorithms such as pruning and quantization to any neural network.
General, recipe-driven approaches built around these algorithms enable the simplification of creating faster and smaller models for the ML performance community at large.</p>
<p>The <a class="reference external" href="https://github.com/neuralmagic/sparseml">GitHub repository</a> contains integrations within the PyTorch, Keras, and TensorFlow V1 ecosystems, allowing for seamless model sparsification.</p>
<p><span class="raw-html-m2r"><img alt="SparseML Flow" src="https://docs.neuralmagic.com/docs/source/infographics/sparseml.png" width="960px" /></span></p>
</div>
<div class="section" id="highlights">
<h1>Highlights<a class="headerlink" href="#highlights" title="Permalink to this headline">¶</a></h1>
<div class="section" id="integrations">
<h2>Integrations<a class="headerlink" href="#integrations" title="Permalink to this headline">¶</a></h2>
<p>
    <a href="https://github.com/neuralmagic/sparseml/tree/main/integrations/pytorch">
        <img src="https://docs.neuralmagic.com/docs/source/highlights/sparseml/pytorch-torchvision.png" width="136px" />
    </a>
    <a href="https://github.com/neuralmagic/sparseml/tree/main/integrations/ultralytics-yolov3">
        <img src="https://docs.neuralmagic.com/docs/source/highlights/sparseml/ultralytics-yolov3.png" width="136px" />
    </a>
    <a href="https://github.com/neuralmagic/sparseml/tree/main/integrations/ultralytics-yolov5">
        <img src="https://docs.neuralmagic.com/docs/source/highlights/sparseml/ultralytics-yolov5.png" width="136px" />
    </a>
    <a href="https://github.com/neuralmagic/sparseml/tree/main/integrations/huggingface-transformers">
        <img src="https://docs.neuralmagic.com/docs/source/highlights/sparseml/huggingface-transformers.png" width="136px" />
    </a>
    <a href="https://github.com/neuralmagic/sparseml/tree/main/integrations/rwightman-timm">
        <img src="https://docs.neuralmagic.com/docs/source/highlights/sparseml/rwightman-timm.png" width="136px" />
    </a>
</p></div>
<div class="section" id="creating-sparse-models">
<h2>Creating Sparse Models<a class="headerlink" href="#creating-sparse-models" title="Permalink to this headline">¶</a></h2>
<p>
    <a href="https://github.com/neuralmagic/sparseml/tree/main/integrations/pytorch/notebooks/classification.ipynb">
        <img src="https://docs.neuralmagic.com/docs/source/tutorials/classification_resnet-50.png" width="136px" />
    </a>
    <a href="https://github.com/neuralmagic/sparseml/tree/main/integrations/ultralytics-yolov3/tutorials/sparsifying_yolov3_using_recipes.md">
        <img src="https://docs.neuralmagic.com/docs/source/tutorials/detection_yolov3.png" width="136px" />
    </a>
</p></div>
<div class="section" id="transfer-learning-from-sparse-models">
<h2>Transfer Learning from Sparse Models<a class="headerlink" href="#transfer-learning-from-sparse-models" title="Permalink to this headline">¶</a></h2>
<p>
    <a href="https://github.com/neuralmagic/sparseml/tree/main/integrations/pytorch/notebooks/sparse_quantized_transfer_learning.ipynb">
        <img src="https://docs.neuralmagic.com/docs/source/tutorials/classification_resnet-50.png" width="136px" />
    </a>
</p></div>
</div>
<div class="section" id="tutorials">
<h1>Tutorials<a class="headerlink" href="#tutorials" title="Permalink to this headline">¶</a></h1>
<p>Coming soon!</p>
</div>
<div class="section" id="installation">
<h1>Installation<a class="headerlink" href="#installation" title="Permalink to this headline">¶</a></h1>
<p>This repository is tested on Python 3.6+, and Linux/Debian systems.
It is recommended to install in a <a class="reference external" href="https://docs.python.org/3/library/venv.html">virtual environment</a> to keep your system in order.
Currently supported ML Frameworks are the following: <code class="docutils literal notranslate"><span class="pre">torch&gt;=1.1.0,&lt;=1.8.0</span></code>, <code class="docutils literal notranslate"><span class="pre">tensorflow&gt;=1.8.0,&lt;=2.0.0</span></code>, <code class="docutils literal notranslate"><span class="pre">tensorflow.keras</span> <span class="pre">&gt;=</span> <span class="pre">2.2.0</span></code>.</p>
<p>Install with pip using:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip install sparseml
</pre></div>
</div>
<p>More information on installation such as optional dependencies and requirements can be found <a class="reference external" href="https://docs.neuralmagic.com/sparseml/source/installation.html">here</a>.</p>
</div>
<div class="section" id="quick-tour">
<h1>Quick Tour<a class="headerlink" href="#quick-tour" title="Permalink to this headline">¶</a></h1>
<p>To enable flexibility, ease of use, and repeatability, sparsifying a model is done using a recipe.
The recipes encode the instructions needed for modifying the model and/or training process as a list of modifiers.
Example modifiers can be anything from setting the learning rate for the optimizer to gradual magnitude pruning.
The files are written in <a class="reference external" href="https://yaml.org/">YAML</a> and stored in YAML or <a class="reference external" href="https://www.markdownguide.org/">markdown</a> files using <a class="reference external" href="https://assemble.io/docs/YAML-front-matter.html">YAML front matter</a>.
The rest of the SparseML system is coded to parse the recipes into a native format for the desired framework and apply the modifications to the model and training pipeline.</p>
<p><code class="docutils literal notranslate"><span class="pre">ScheduledModifierManager</span></code> classes can be created from recipes in all supported ML frameworks.
The manager classes handle overriding the training graphs to apply the modifiers as described in the desired recipe.
Managers can apply recipes in one shot or training aware ways.
One shot is invoked by calling <code class="docutils literal notranslate"><span class="pre">.apply(...)</span></code> on the manager while training aware requires calls into <code class="docutils literal notranslate"><span class="pre">initialize(...)</span></code> (optional), <code class="docutils literal notranslate"><span class="pre">modify(...)</span></code>, and <code class="docutils literal notranslate"><span class="pre">finalize(...)</span></code>.</p>
<p>For the frameworks, this means only a few lines of code need to be added to begin supporting pruning, quantization, and other modifications to most training pipelines.
For example, the following applies a recipe in a training aware manner:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">()</span>  <span class="c1"># model definition</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Optimizer</span><span class="p">()</span>  <span class="c1"># optimizer definition</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">TrainData</span><span class="p">()</span>  <span class="c1"># train data definition</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="n">BATCH_SIZE</span>  <span class="c1"># training batch size</span>
<span class="n">steps_per_epoch</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span> <span class="o">//</span> <span class="n">batch_size</span>

<span class="kn">from</span> <span class="nn">sparseml.pytorch.optim</span> <span class="kn">import</span> <span class="n">ScheduledModifierManager</span>
<span class="n">manager</span> <span class="o">=</span> <span class="n">ScheduledModifierManager</span><span class="o">.</span><span class="n">from_yaml</span><span class="p">(</span><span class="n">PATH_TO_RECIPE</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">manager</span><span class="o">.</span><span class="n">modify</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">steps_per_epoch</span><span class="p">)</span>

<span class="c1"># PyTorch training code</span>

<span class="n">manager</span><span class="o">.</span><span class="n">finalize</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
<p>Instead of training aware, the following example code shows how to execute a recipe in a one shot manner:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">()</span>  <span class="c1"># model definition</span>

<span class="kn">from</span> <span class="nn">sparseml.pytorch.optim</span> <span class="kn">import</span> <span class="n">ScheduledModifierManager</span>
<span class="n">manager</span> <span class="o">=</span> <span class="n">ScheduledModifierManager</span><span class="o">.</span><span class="n">from_yaml</span><span class="p">(</span><span class="n">PATH_TO_RECIPE</span><span class="p">)</span>
<span class="n">manager</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
<p>More information on the codebase and contained processes can be found in the SparseML docs:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://docs.neuralmagic.com/sparseml/source/code">Sparsification Code</a></p></li>
<li><p><a class="reference external" href="https://docs.neuralmagic.com/sparseml/source/recipes">Sparsification Recipes</a></p></li>
<li><p><a class="reference external" href="https://docs.neuralmagic.com/sparseml/source/onnx_export">Exporting to ONNX</a></p></li>
</ul>
</div>
<div class="section" id="resources">
<h1>Resources<a class="headerlink" href="#resources" title="Permalink to this headline">¶</a></h1>
<div class="section" id="learning-more">
<h2>Learning More<a class="headerlink" href="#learning-more" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Documentation: <a class="reference external" href="https://docs.neuralmagic.com/sparseml/">SparseML</a>, <a class="reference external" href="https://docs.neuralmagic.com/sparsezoo/">SparseZoo</a>, <a class="reference external" href="https://docs.neuralmagic.com/sparsify/">Sparsify</a>, <a class="reference external" href="https://docs.neuralmagic.com/deepsparse/">DeepSparse</a></p></li>
<li><p>Neural Magic: <a class="reference external" href="https://www.neuralmagic.com/blog/">Blog</a>, <a class="reference external" href="https://www.neuralmagic.com/resources/">Resources</a></p></li>
</ul>
</div>
<div class="section" id="release-history">
<h2>Release History<a class="headerlink" href="#release-history" title="Permalink to this headline">¶</a></h2>
<p>Official builds are hosted on PyPI</p>
<ul class="simple">
<li><p>stable: <a class="reference external" href="https://pypi.org/project/sparseml/">sparseml</a></p></li>
<li><p>nightly (dev): <a class="reference external" href="https://pypi.org/project/sparseml-nightly/">sparseml-nightly</a></p></li>
</ul>
<p>Additionally, more information can be found via <a class="reference external" href="https://github.com/neuralmagic/sparseml/releases">GitHub Releases.</a></p>
</div>
<div class="section" id="license">
<h2>License<a class="headerlink" href="#license" title="Permalink to this headline">¶</a></h2>
<p>The project is licensed under the <a class="reference external" href="https://github.com/neuralmagic/sparseml/blob/main/LICENSE">Apache License Version 2.0</a>.</p>
</div>
</div>
<div class="section" id="community">
<h1>Community<a class="headerlink" href="#community" title="Permalink to this headline">¶</a></h1>
<div class="section" id="contribute">
<h2>Contribute<a class="headerlink" href="#contribute" title="Permalink to this headline">¶</a></h2>
<p>We appreciate contributions to the code, examples, integrations, and documentation as well as bug reports and feature requests! <a class="reference external" href="https://github.com/neuralmagic/sparseml/blob/main/CONTRIBUTING.md">Learn how here</a>.</p>
</div>
<div class="section" id="join">
<h2>Join<a class="headerlink" href="#join" title="Permalink to this headline">¶</a></h2>
<p>For user help or questions about SparseML, sign up or log in: <strong>Deep Sparse Community</strong> <a class="reference external" href="https://discuss.neuralmagic.com/">Discourse Forum</a> and/or <a class="reference external" href="https://join.slack.com/t/discuss-neuralmagic/shared_invite/zt-q1a1cnvo-YBoICSIw3L1dmQpjBeDurQ">Slack</a>. We are growing the community member by member and happy to see you there.</p>
<p>You can get the latest news, webinar and event invites, research papers, and other ML Performance tidbits by <a class="reference external" href="https://neuralmagic.com/subscribe/">subscribing</a> to the Neural Magic community.</p>
<p>For more general questions about Neural Magic, please fill out this <a class="reference external" href="http://neuralmagic.com/contact/">form</a>.</p>
</div>
<div class="section" id="cite">
<h2>Cite<a class="headerlink" href="#cite" title="Permalink to this headline">¶</a></h2>
<p>Find this project useful in your research or other communications? Please consider citing:</p>
<div class="highlight-bibtex notranslate"><div class="highlight"><pre><span></span><span class="nc">@InProceedings</span><span class="p">{</span>
    <span class="nl">pmlr-v119-kurtz20a</span><span class="p">,</span>
    <span class="na">title</span> <span class="p">=</span> <span class="s">{Inducing and Exploiting Activation Sparsity for Fast Inference on Deep Neural Networks}</span><span class="p">,</span>
    <span class="na">author</span> <span class="p">=</span> <span class="s">{Kurtz, Mark and Kopinsky, Justin and Gelashvili, Rati and Matveev, Alexander and Carr, John and Goin, Michael and Leiserson, William and Moore, Sage and Nell, Bill and Shavit, Nir and Alistarh, Dan}</span><span class="p">,</span>
    <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 37th International Conference on Machine Learning}</span><span class="p">,</span>
    <span class="na">pages</span> <span class="p">=</span> <span class="s">{5533--5543}</span><span class="p">,</span>
    <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
    <span class="na">editor</span> <span class="p">=</span> <span class="s">{Hal Daumé III and Aarti Singh}</span><span class="p">,</span>
    <span class="na">volume</span> <span class="p">=</span> <span class="s">{119}</span><span class="p">,</span>
    <span class="na">series</span> <span class="p">=</span> <span class="s">{Proceedings of Machine Learning Research}</span><span class="p">,</span>
    <span class="na">address</span> <span class="p">=</span> <span class="s">{Virtual}</span><span class="p">,</span>
    <span class="na">month</span> <span class="p">=</span> <span class="s">{13--18 Jul}</span><span class="p">,</span>
    <span class="na">publisher</span> <span class="p">=</span> <span class="s">{PMLR}</span><span class="p">,</span>
    <span class="na">pdf</span> <span class="p">=</span> <span class="s">{http://proceedings.mlr.press/v119/kurtz20a/kurtz20a.pdf}</span><span class="p">,</span>
    <span class="na">url</span> <span class="p">=</span> <span class="s">{http://proceedings.mlr.press/v119/kurtz20a.html}</span><span class="p">,</span>
    <span class="na">abstract</span> <span class="p">=</span> <span class="s">{Optimizing convolutional neural networks for fast inference has recently become an extremely active area of research. One of the go-to solutions in this context is weight pruning, which aims to reduce computational and memory footprint by removing large subsets of the connections in a neural network. Surprisingly, much less attention has been given to exploiting sparsity in the activation maps, which tend to be naturally sparse in many settings thanks to the structure of rectified linear (ReLU) activation functions. In this paper, we present an in-depth analysis of methods for maximizing the sparsity of the activations in a trained neural network, and show that, when coupled with an efficient sparse-input convolution algorithm, we can leverage this sparsity for significant performance gains. To induce highly sparse activation maps without accuracy loss, we introduce a new regularization technique, coupled with a new threshold-based sparsification method based on a parameterized activation function called Forced-Activation-Threshold Rectified Linear Unit (FATReLU). We examine the impact of our methods on popular image classification models, showing that most architectures can adapt to significantly sparser activation maps without any accuracy loss. Our second contribution is showing that these these compression gains can be translated into inference speedups: we provide a new algorithm to enable fast convolution operations over networks with sparse activations, and show that it can enable significant speedups for end-to-end inference on a range of popular models on the large-scale ImageNet image classification task on modern Intel CPUs, with little or no retraining cost.}</span>
<span class="p">}</span>
</pre></div>
</div>
<div class="highlight-bibtex notranslate"><div class="highlight"><pre><span></span><span class="nc">@misc</span><span class="p">{</span>
    <span class="nl">singh2020woodfisher</span><span class="p">,</span>
    <span class="na">title</span><span class="p">=</span><span class="s">{WoodFisher: Efficient Second-Order Approximation for Neural Network Compression}</span><span class="p">,</span>
    <span class="na">author</span><span class="p">=</span><span class="s">{Sidak Pal Singh and Dan Alistarh}</span><span class="p">,</span>
    <span class="na">year</span><span class="p">=</span><span class="s">{2020}</span><span class="p">,</span>
    <span class="na">eprint</span><span class="p">=</span><span class="s">{2004.14340}</span><span class="p">,</span>
    <span class="na">archivePrefix</span><span class="p">=</span><span class="s">{arXiv}</span><span class="p">,</span>
    <span class="na">primaryClass</span><span class="p">=</span><span class="s">{cs.LG}</span>
<span class="p">}</span>
</pre></div>
</div>
<div class="toctree-wrapper compound">
<p class="caption"><span class="caption-text">General</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="source/installation.html">Installation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="source/installation.html#supported-framework-versions">Supported Framework Versions</a></li>
<li class="toctree-l2"><a class="reference internal" href="source/installation.html#optional-dependencies">Optional Dependencies</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="source/code.html">Sparsification Code</a><ul>
<li class="toctree-l2"><a class="reference internal" href="source/code.html#pytorch-sparsification">PyTorch Sparsification</a></li>
<li class="toctree-l2"><a class="reference internal" href="source/code.html#keras-sparsification">Keras Sparsification</a></li>
<li class="toctree-l2"><a class="reference internal" href="source/code.html#tensorflow-v1-sparsification">TensorFlow V1 Sparsification</a><ul>
<li class="toctree-l3"><a class="reference internal" href="source/code.html#estimator-based-pipelines">Estimator-Based Pipelines</a></li>
<li class="toctree-l3"><a class="reference internal" href="source/code.html#session-based-pipelines">Session-Based Pipelines</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="source/recipes.html">Sparsification Recipes</a><ul>
<li class="toctree-l2"><a class="reference internal" href="source/recipes.html#modifiers-intro">Modifiers Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="source/recipes.html#training-epoch-modifiers">Training Epoch Modifiers</a></li>
<li class="toctree-l2"><a class="reference internal" href="source/recipes.html#pruning-modifiers">Pruning Modifiers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="source/recipes.html#constantpruningmodifier">ConstantPruningModifier</a></li>
<li class="toctree-l3"><a class="reference internal" href="source/recipes.html#quantization-modifiers">Quantization Modifiers</a></li>
<li class="toctree-l3"><a class="reference internal" href="source/recipes.html#learning-rate-modifiers">Learning Rate Modifiers</a></li>
<li class="toctree-l3"><a class="reference internal" href="source/recipes.html#params-variables-modifiers">Params/Variables Modifiers</a></li>
<li class="toctree-l3"><a class="reference internal" href="source/recipes.html#optimizer-modifiers">Optimizer Modifiers</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="source/onnx_export.html">ONNX Export</a><ul>
<li class="toctree-l2"><a class="reference internal" href="source/onnx_export.html#exporting-pytorch-to-onnx">Exporting PyTorch to ONNX</a></li>
<li class="toctree-l2"><a class="reference internal" href="source/onnx_export.html#exporting-keras-to-onnx">Exporting Keras to ONNX</a></li>
<li class="toctree-l2"><a class="reference internal" href="source/onnx_export.html#exporting-tensorflow-v1-to-onnx">Exporting TensorFlow V1 to ONNX</a></li>
</ul>
</li>
</ul>
</div>
<div class="toctree-wrapper compound">
<p class="caption"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="api/sparseml.html">sparseml package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="api/sparseml.html#subpackages">Subpackages</a></li>
<li class="toctree-l2"><a class="reference internal" href="api/sparseml.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="api/sparseml.html#module-sparseml.base">sparseml.base module</a></li>
<li class="toctree-l2"><a class="reference internal" href="api/sparseml.html#module-sparseml.log">sparseml.log module</a></li>
<li class="toctree-l2"><a class="reference internal" href="api/sparseml.html#module-sparseml.version">sparseml.version module</a></li>
<li class="toctree-l2"><a class="reference internal" href="api/sparseml.html#module-sparseml">Module contents</a></li>
</ul>
</li>
</ul>
</div>
<div class="toctree-wrapper compound">
<p class="caption"><span class="caption-text">Connect Online</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://github.com/neuralmagic/sparseml/issues">Bugs, Feature Requests</a></li>
<li class="toctree-l1"><a class="reference external" href="https://discuss.neuralmagic.com/">Support, General Q&amp;A Forums</a></li>
<li class="toctree-l1"><a class="reference external" href="https://join.slack.com/t/discuss-neuralmagic/shared_invite/zt-q1a1cnvo-YBoICSIw3L1dmQpjBeDurQ">Deep Sparse Community Slack</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/neuralmagic">Neural Magic GitHub</a></li>
<li class="toctree-l1"><a class="reference external" href="https://docs.neuralmagic.com">Neural Magic Docs</a></li>
</ul>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="source/installation.html" class="btn btn-neutral float-right" title="Installation" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021 - present / Neuralmagic, Inc. All Rights Reserved. Licensed under the Apache License, Version 2.0 (the &#34;License&#34;).

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  
<div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    <span class="fa fa-book"> Other Versions</span>
    v: main
    <span class="fa fa-caret-down"></span>
  </span>
  <div class="rst-other-versions">
    <dl>
      <dt>Tags</dt>
      <dd><a href="../v0.3.0/index.html">v0.3.0</a></dd>
      <dd><a href="../v0.3.1/index.html">v0.3.1</a></dd>
    </dl>
    <dl>
      <dt>Branches</dt>
      <dd><a href="index.html">main</a></dd>
    </dl>
  </div>
</div>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-128364174-1', 'auto');
    
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>