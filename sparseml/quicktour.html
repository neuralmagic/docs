

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Quick Tour &mdash; SparseML 0.1.0 documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/copybutton.css" type="text/css" />

  
  
    <link rel="shortcut icon" href="_static/favicon.ico"/>
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/clipboard.min.js"></script>
        <script src="_static/copybutton.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Installation" href="installation.html" />
    <link rel="prev" title="SparseML 0.1" href="index.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> SparseML
          

          
            
            <img src="_static/icon-sparseml.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                0.1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">General</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Quick Tour</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#pytorch-sparsification">PyTorch Sparsification</a></li>
<li class="toctree-l2"><a class="reference internal" href="#keras-optimization">Keras Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="#tensorflow-v1-sparsification">TensorFlow V1 Sparsification</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#estimator-based-pipelines">Estimator-Based pipelines</a></li>
<li class="toctree-l3"><a class="reference internal" href="#session-based-pipelines">Session-Based pipelines</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#exporting-to-onnx">Exporting to ONNX</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#exporting-pytorch-to-onnx">Exporting PyTorch to ONNX</a></li>
<li class="toctree-l3"><a class="reference internal" href="#exporting-keras-to-onnx">Exporting Keras to ONNX</a></li>
<li class="toctree-l3"><a class="reference internal" href="#exporting-tensorflow-v1-to-onnx">Exporting TensorFlow V1 to ONNX</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes.html">Sparsification Recipes</a></li>
</ul>
<p class="caption"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="api/sparseml.html">sparseml package</a></li>
</ul>
<p class="caption"><span class="caption-text">Help</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://github.com/neuralmagic/sparseml/issues">Bugs, Feature Requests</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/neuralmagic/sparseml/discussions">Support, General Q&amp;A</a></li>
<li class="toctree-l1"><a class="reference external" href="https://docs.neuralmagic.com">Neural Magic Docs</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">SparseML</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Quick Tour</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/quicktour.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <!--
Copyright (c) 2021 - present / Neuralmagic, Inc. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing,
software distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
--><div class="section" id="quick-tour">
<h1>Quick Tour<a class="headerlink" href="#quick-tour" title="Permalink to this headline">Â¶</a></h1>
<p>To enable flexibility, ease of use, and repeatability, sparsifying a model is generally done using a recipe.
The recipes encode the instructions needed for modifying the model and/or training process as a list of modifiers.
Example modifiers can be anything from setting the learning rate for the optimizer to gradual magnitude pruning.
The files are written in <a class="reference external" href="https://yaml.org/">YAML</a> and stored in YAML or <a class="reference external" href="https://www.markdownguide.org/">markdown</a> files using <a class="reference external" href="https://assemble.io/docs/YAML-front-matter.html">YAML front matter</a>.
The rest of the SparseML system is coded to parse the recipes into a native format for the desired framework and apply the modifications to the model and training pipeline.</p>
<p>A sample recipe for pruning a model generally looks like the following:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">version</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.1.0</span>
<span class="nt">modifiers</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="kt">!EpochRangeModifier</span>
        <span class="nt">start_epoch</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.0</span>
        <span class="nt">end_epoch</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">70.0</span>

    <span class="p p-Indicator">-</span> <span class="kt">!LearningRateModifier</span>
        <span class="nt">start_epoch</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
        <span class="nt">end_epoch</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">-1.0</span>
        <span class="nt">update_frequency</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">-1.0</span>
        <span class="nt">init_lr</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.005</span>
        <span class="nt">lr_class</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">MultiStepLR</span>
        <span class="nt">lr_kwargs</span><span class="p">:</span> <span class="p p-Indicator">{</span><span class="s">&#39;milestones&#39;</span><span class="p p-Indicator">:</span> <span class="p p-Indicator">[</span><span class="nv">43</span><span class="p p-Indicator">,</span> <span class="nv">60</span><span class="p p-Indicator">],</span> <span class="s">&#39;gamma&#39;</span><span class="p p-Indicator">:</span> <span class="nv">0.1</span><span class="p p-Indicator">}</span>

    <span class="p p-Indicator">-</span> <span class="kt">!GMPruningModifier</span>
        <span class="nt">start_epoch</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
        <span class="nt">end_epoch</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">40</span>
        <span class="nt">update_frequency</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1.0</span>
        <span class="nt">init_sparsity</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.05</span>
        <span class="nt">final_sparsity</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.85</span>
        <span class="nt">mask_type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">unstructured</span>
        <span class="nt">params</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="s">&#39;sections.0.0.conv1.weight&#39;</span><span class="p p-Indicator">,</span> <span class="s">&#39;sections.0.0.conv2.weight&#39;</span><span class="p p-Indicator">,</span> <span class="s">&#39;sections.0.0.conv3.weight&#39;</span><span class="p p-Indicator">]</span>
</pre></div>
</div>
<p>More information on the available recipes, formats, and arguments can be found <a class="reference external" href="https://github.com/neuralmagic/sparseml/blob/main/docs/source/recipes.md">here</a>. Additionally, all code implementations of the modifiers under the <code class="docutils literal notranslate"><span class="pre">optim</span></code> packages for the frameworks are documented with example YAML formats.</p>
<p>Pre-configured recipes and the resulting models can be explored and downloaded from the <a class="reference external" href="https://github.com/neuralmagic/sparsezoo">SparseZoo</a>. Also, <a class="reference external" href="https://github.com/neuralmagic/sparsify">Sparsify</a> enables autoML style creation of optimization recipes for use with SparseML.</p>
<p>For a more in-depth read, check out <a class="reference external" href="https://docs.neuralmagic.com/sparseml/">SparseML documentation</a>.</p>
<div class="section" id="pytorch-sparsification">
<h2>PyTorch Sparsification<a class="headerlink" href="#pytorch-sparsification" title="Permalink to this headline">Â¶</a></h2>
<p>The PyTorch sparsification libraries are located under the <code class="docutils literal notranslate"><span class="pre">sparseml.pytorch.optim</span></code> package.
Inside are APIs designed to make model sparsification as easy as possible by integrating seamlessly into PyTorch training pipelines.</p>
<p>The integration is done using the <code class="docutils literal notranslate"><span class="pre">ScheduledOptimizer</span></code> class.
It is intended to wrap your current optimizer and its step function.
The step function then calls into the <code class="docutils literal notranslate"><span class="pre">ScheduledModifierManager</span></code> class which can be created from a recipe file.
With this setup, the training process can then be modified as desired to sparsify the model.</p>
<p>To enable all of this, the integration code youâll need to write is only a handful of lines:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sparseml.pytorch.optim</span> <span class="kn">import</span> <span class="n">ScheduledModifierManager</span><span class="p">,</span> <span class="n">ScheduledOptimizer</span>

<span class="n">model</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># your model definition</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># your optimizer definition</span>
<span class="n">num_train_batches</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span> <span class="o">/</span> <span class="n">batch_size</span>  <span class="c1"># your number of batches per training epoch</span>

<span class="n">manager</span> <span class="o">=</span> <span class="n">ScheduledModifierManager</span><span class="o">.</span><span class="n">from_yaml</span><span class="p">(</span><span class="s2">&quot;/PATH/TO/recipe.yaml&quot;</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">ScheduledOptimizer</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">manager</span><span class="p">,</span> <span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">num_train_batches</span><span class="p">)</span>

<span class="c1"># PyTorch training code...</span>
</pre></div>
</div>
</div>
<div class="section" id="keras-optimization">
<h2>Keras Optimization<a class="headerlink" href="#keras-optimization" title="Permalink to this headline">Â¶</a></h2>
<p>The Keras sparsification libraries are located under the <code class="docutils literal notranslate"><span class="pre">sparseml.keras.optim</span></code> package.
Inside are APIs designed to make model sparsification as easy as possible by integrating seamlessly into Keras training pipelines.</p>
<p>The integration is done using the <code class="docutils literal notranslate"><span class="pre">ScheduledModifierManager</span></code> class which can be created from a recipe file.
This class handles modifying the Keras objects for the desired algorithms using the <code class="docutils literal notranslate"><span class="pre">modify</span></code> method.
The edited model, optimizer, and any callbacks necessary to modify the training process are returned.
The model and optimizer can be used normally and the callbacks must be passed into the <code class="docutils literal notranslate"><span class="pre">fit</span></code> or <code class="docutils literal notranslate"><span class="pre">fit_generator</span></code> function.
If using <code class="docutils literal notranslate"><span class="pre">train_on_batch</span></code>, the callbacks must be invoked after each call.
After training is completed, call into the managerâs <code class="docutils literal notranslate"><span class="pre">finalize</span></code> method to clean up the graph for exporting.</p>
<p>To enable all of this, the integration code youâll need to write is only a handful of lines:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sparseml.keras.optim</span> <span class="kn">import</span> <span class="n">ScheduledModifierManager</span>

<span class="n">model</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># your model definition</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># your optimizer definition</span>
<span class="n">num_train_batches</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span> <span class="o">/</span> <span class="n">batch_size</span>  <span class="c1"># your number of batches per training epoch</span>

<span class="n">manager</span> <span class="o">=</span> <span class="n">ScheduledModifierManager</span><span class="o">.</span><span class="n">from_yaml</span><span class="p">(</span><span class="s2">&quot;/PATH/TO/recipe.yaml&quot;</span><span class="p">)</span>
<span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">callbacks</span> <span class="o">=</span> <span class="n">manager</span><span class="o">.</span><span class="n">modify</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">num_train_batches</span>
<span class="p">)</span>

<span class="c1"># Keras compilation and training code...</span>
<span class="c1"># Be sure to compile model after calling modify and pass the callbacks into the fit or fit_generator function.</span>
<span class="c1"># Note, if you are using train_on_batch, then you will need to invoke the callbacks after every step.</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">)</span>

<span class="c1"># finalize cleans up the graph for export</span>
<span class="n">save_model</span> <span class="o">=</span> <span class="n">manager</span><span class="o">.</span><span class="n">finalize</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="tensorflow-v1-sparsification">
<h2>TensorFlow V1 Sparsification<a class="headerlink" href="#tensorflow-v1-sparsification" title="Permalink to this headline">Â¶</a></h2>
<p>The TensorFlow sparsification libraries for TensorFlow version 1.X are located under the <code class="docutils literal notranslate"><span class="pre">sparseml.tensorflow_v1.optim</span></code> package.
Inside are APIs designed to make model sparsification as easy as possible by integrating seamlessly into TensorFlow V1 training pipelines.</p>
<p>The integration is done using the <code class="docutils literal notranslate"><span class="pre">ScheduledModifierManager</span></code> class which can be created from a recipe file.
This class handles modifying the TensorFlow graph for the desired algorithms.
With this setup, the training process can then be modified as desired to sparsify the model.</p>
<div class="section" id="estimator-based-pipelines">
<h3>Estimator-Based pipelines<a class="headerlink" href="#estimator-based-pipelines" title="Permalink to this headline">Â¶</a></h3>
<p>Estimator-based pipelines are simpler to integrate with as compared to session-based pipelines.
The <code class="docutils literal notranslate"><span class="pre">ScheduledModifierManager</span></code> can override the necessary callbacks in the estimator to modify the graph using the <code class="docutils literal notranslate"><span class="pre">modify_estimator</span></code> function.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sparseml.tensorflow_v1.optim</span> <span class="kn">import</span> <span class="n">ScheduledModifierManager</span>

<span class="n">estimator</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># your estimator definition</span>
<span class="n">num_train_batches</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span> <span class="o">/</span> <span class="n">batch_size</span>  <span class="c1"># your number of batches per training epoch</span>

<span class="n">manager</span> <span class="o">=</span> <span class="n">ScheduledModifierManager</span><span class="o">.</span><span class="n">from_yaml</span><span class="p">(</span><span class="s2">&quot;/PATH/TO/config.yaml&quot;</span><span class="p">)</span>
<span class="n">manager</span><span class="o">.</span><span class="n">modify_estimator</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">num_train_batches</span><span class="p">)</span>

<span class="c1"># Normal estimator training code...</span>
</pre></div>
</div>
</div>
<div class="section" id="session-based-pipelines">
<h3>Session-Based pipelines<a class="headerlink" href="#session-based-pipelines" title="Permalink to this headline">Â¶</a></h3>
<p>Session-based pipelines need a little bit more as compared to estimator-based pipelines; however,
it is still designed to require only a few lines of code for integration.
After graph creation, the managerâs <code class="docutils literal notranslate"><span class="pre">create_ops</span></code> method must be called.
This will modify the graph as needed for the algorithms and return modifying ops and extras.
After creating the session and training normally, call into <code class="docutils literal notranslate"><span class="pre">session.run</span></code> with the modifying ops after each step.
Modifying extras contain objects such as tensorboard summaries of the modifiers to be used if desired.
Finally, once completed, <code class="docutils literal notranslate"><span class="pre">complete_graph</span></code> must be called to remove the modifying ops for saving and export.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sparseml.tensorflow_v1.utils</span> <span class="kn">import</span> <span class="n">tf_compat</span>
<span class="kn">from</span> <span class="nn">sparseml.tensorflow_v1.optim</span> <span class="kn">import</span> <span class="n">ScheduledModifierManager</span>


<span class="k">with</span> <span class="n">tf_compat</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span><span class="o">.</span><span class="n">as_default</span><span class="p">()</span> <span class="k">as</span> <span class="n">graph</span><span class="p">:</span>
    <span class="c1"># Normal graph setup....</span>
    <span class="n">num_train_batches</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span> <span class="o">/</span> <span class="n">batch_size</span>  <span class="c1"># your number of batches per training epoch</span>
    
    <span class="c1"># Modifying graphs, be sure his is called after graph is created and before session is created</span>
    <span class="n">manager</span> <span class="o">=</span> <span class="n">ScheduledModifierManager</span><span class="o">.</span><span class="n">from_yaml</span><span class="p">(</span><span class="s2">&quot;/PATH/TO/config.yaml&quot;</span><span class="p">)</span>
    <span class="n">mod_ops</span><span class="p">,</span> <span class="n">mod_extras</span> <span class="o">=</span> <span class="n">manager</span><span class="o">.</span><span class="n">create_ops</span><span class="p">(</span><span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">num_train_batches</span><span class="p">)</span>
    
    <span class="k">with</span> <span class="n">tf_compat</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
        <span class="c1"># Normal training code...</span>
        <span class="c1"># Call sess.run with the mod_ops after every batch update</span>
        <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">mod_ops</span><span class="p">)</span>
    
        <span class="c1"># Call into complete_graph after training is done</span>
        <span class="n">manager</span><span class="o">.</span><span class="n">complete_graph</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="exporting-to-onnx">
<h2>Exporting to ONNX<a class="headerlink" href="#exporting-to-onnx" title="Permalink to this headline">Â¶</a></h2>
<p><a class="reference external" href="https://onnx.ai/">ONNX</a> is a generic representation for neural network graphs that most ML frameworks can be converted to. Some inference engines such as <a class="reference external" href="https://github.com/neuralmagic/deepsparse">DeepSparse</a> natively take in ONNX for deployment pipelines, so convenience functions for conversion and export are provided for the supported frameworks.</p>
<div class="section" id="exporting-pytorch-to-onnx">
<h3>Exporting PyTorch to ONNX<a class="headerlink" href="#exporting-pytorch-to-onnx" title="Permalink to this headline">Â¶</a></h3>
<p>ONNX is built into the PyTorch system natively.
The <code class="docutils literal notranslate"><span class="pre">ModuleExporter</span></code> class under the <code class="docutils literal notranslate"><span class="pre">sparseml.pytorch.utils</span></code> package features an <code class="docutils literal notranslate"><span class="pre">export_onnx</span></code> function built on top of this native support.
Example code:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">sparseml.pytorch.models</span> <span class="kn">import</span> <span class="n">mnist_net</span>
<span class="kn">from</span> <span class="nn">sparseml.pytorch.utils</span> <span class="kn">import</span> <span class="n">ModuleExporter</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">mnist_net</span><span class="p">()</span>
<span class="n">exporter</span> <span class="o">=</span> <span class="n">ModuleExporter</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">output_dir</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">,</span> <span class="s2">&quot;onnx-export&quot;</span><span class="p">))</span>
<span class="n">exporter</span><span class="o">.</span><span class="n">export_onnx</span><span class="p">(</span><span class="n">sample_batch</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="section" id="exporting-keras-to-onnx">
<h3>Exporting Keras to ONNX<a class="headerlink" href="#exporting-keras-to-onnx" title="Permalink to this headline">Â¶</a></h3>
<p>ONNX is not built into the Keras system, but is supported through an ONNX official tool <a class="reference external" href="https://github.com/onnx/keras-onnx">keras2onnx</a>. The <code class="docutils literal notranslate"><span class="pre">ModelExporter</span></code> class under the <code class="docutils literal notranslate"><span class="pre">sparseml.keras.utils</span></code> package features an <code class="docutils literal notranslate"><span class="pre">export_onnx</span></code> function built on top of keras2onnx.
Example code:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">sparseml.keras.utils</span> <span class="kn">import</span> <span class="n">ModelExporter</span>

<span class="n">model</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># fill in with your model</span>
<span class="n">exporter</span> <span class="o">=</span> <span class="n">ModelExporter</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">output_dir</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">,</span> <span class="s2">&quot;onnx-export&quot;</span><span class="p">))</span>
<span class="n">exporter</span><span class="o">.</span><span class="n">export_onnx</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="section" id="exporting-tensorflow-v1-to-onnx">
<h3>Exporting TensorFlow V1 to ONNX<a class="headerlink" href="#exporting-tensorflow-v1-to-onnx" title="Permalink to this headline">Â¶</a></h3>
<p>ONNX is not built into the TensorFlow system, but it is supported through an ONNX official tool
<a class="reference external" href="https://github.com/onnx/tensorflow-onnx">tf2onnx</a>.
The <code class="docutils literal notranslate"><span class="pre">GraphExporter</span></code> class under the <code class="docutils literal notranslate"><span class="pre">sparseml.tensorflow_v1.utils</span></code> package features an
<code class="docutils literal notranslate"><span class="pre">export_onnx</span></code> function built on top of tf2onnx.
Note that the ONNX file is created from the protobuf graph representation, so <code class="docutils literal notranslate"><span class="pre">export_pb</span></code> must be called first.
Example code:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">sparseml.tensorflow_v1.utils</span> <span class="kn">import</span> <span class="n">tf_compat</span><span class="p">,</span> <span class="n">GraphExporter</span>
<span class="kn">from</span> <span class="nn">sparseml.tensorflow_v1.models</span> <span class="kn">import</span> <span class="n">mnist_net</span>

<span class="n">exporter</span> <span class="o">=</span> <span class="n">GraphExporter</span><span class="p">(</span><span class="n">output_dir</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">,</span> <span class="s2">&quot;mnist-tf-export&quot;</span><span class="p">))</span>

<span class="k">with</span> <span class="n">tf_compat</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span><span class="o">.</span><span class="n">as_default</span><span class="p">()</span> <span class="k">as</span> <span class="n">graph</span><span class="p">:</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf_compat</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span>
        <span class="n">tf_compat</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;inputs&quot;</span>
    <span class="p">)</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">mnist_net</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="n">input_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">inputs</span><span class="o">.</span><span class="n">name</span><span class="p">]</span>
    <span class="n">output_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">logits</span><span class="o">.</span><span class="n">name</span><span class="p">]</span>

    <span class="k">with</span> <span class="n">tf_compat</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
        <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf_compat</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>
        <span class="n">exporter</span><span class="o">.</span><span class="n">export_pb</span><span class="p">(</span><span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">logits</span><span class="p">])</span>

<span class="n">exporter</span><span class="o">.</span><span class="n">export_onnx</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">input_names</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">output_names</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="installation.html" class="btn btn-neutral float-right" title="Installation" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="index.html" class="btn btn-neutral float-left" title="SparseML 0.1" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021 - present / Neuralmagic, Inc. All Rights Reserved. Licensed under the Apache License, Version 2.0 (the &#34;License&#34;).

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-128364174-1', 'auto');
    
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>