

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>sparseml.pytorch.utils.module &mdash; SparseML 0.1.0 documentation</title>
  

  
  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/copybutton.css" type="text/css" />

  
  
    <link rel="shortcut icon" href="../../../../_static/favicon.ico"/>
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
        <script src="../../../../_static/jquery.js"></script>
        <script src="../../../../_static/underscore.js"></script>
        <script src="../../../../_static/doctools.js"></script>
        <script src="../../../../_static/clipboard.min.js"></script>
        <script src="../../../../_static/copybutton.js"></script>
    
    <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../../index.html" class="icon icon-home"> SparseML
          

          
            
            <img src="../../../../_static/icon-sparseml.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                0.1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">General</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../quicktour.html">Quick Tour</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../recipes.html">Sparsification Recipes</a></li>
</ul>
<p class="caption"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../api/sparseml.html">sparseml package</a></li>
</ul>
<p class="caption"><span class="caption-text">Help</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://github.com/neuralmagic/sparseml/issues">Bugs, Feature Requests</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/neuralmagic/sparseml/discussions">Support, General Q&amp;A</a></li>
<li class="toctree-l1"><a class="reference external" href="https://docs.neuralmagic.com">Neural Magic Docs</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">SparseML</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../../../index.html">Module code</a> &raquo;</li>
        
      <li>sparseml.pytorch.utils.module</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for sparseml.pytorch.utils.module</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright (c) 2021 - present / Neuralmagic, Inc. All Rights Reserved.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#    http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing,</span>
<span class="c1"># software distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Code related to running a module through training and testing over a dataset.</span>
<span class="sd">Allows reporting of progress and override functions and hooks.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">from</span> <span class="nn">abc</span> <span class="kn">import</span> <span class="n">ABC</span><span class="p">,</span> <span class="n">abstractmethod</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">OrderedDict</span>
<span class="kn">from</span> <span class="nn">contextlib</span> <span class="kn">import</span> <span class="n">ExitStack</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">Module</span>
<span class="kn">from</span> <span class="nn">torch.optim.optimizer</span> <span class="kn">import</span> <span class="n">Optimizer</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="nn">torch.utils.hooks</span> <span class="kn">import</span> <span class="n">RemovableHandle</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">auto</span>

<span class="kn">from</span> <span class="nn">sparseml.pytorch.utils.helpers</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">get_optim_learning_rate</span><span class="p">,</span>
    <span class="n">tensors_batch_size</span><span class="p">,</span>
    <span class="n">tensors_module_forward</span><span class="p">,</span>
    <span class="n">tensors_to_device</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">sparseml.pytorch.utils.logger</span> <span class="kn">import</span> <span class="n">PyTorchLogger</span>
<span class="kn">from</span> <span class="nn">sparseml.pytorch.utils.loss</span> <span class="kn">import</span> <span class="n">DEFAULT_LOSS_KEY</span><span class="p">,</span> <span class="n">LossWrapper</span>


<span class="k">try</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">torch.cuda.amp</span> <span class="kn">import</span> <span class="n">GradScaler</span><span class="p">,</span> <span class="n">autocast</span>

    <span class="n">amp_import_error</span> <span class="o">=</span> <span class="kc">None</span>
<span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">amp_error</span><span class="p">:</span>
    <span class="n">autocast</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">GradScaler</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">amp_import_error</span> <span class="o">=</span> <span class="n">amp_error</span>


<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;def_model_backward&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ModuleRunFuncs&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ModuleRunHooks&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ModuleRunResults&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ModuleDeviceContext&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ModuleTester&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ModuleTrainer&quot;</span><span class="p">,</span>
<span class="p">]</span>


<div class="viewcode-block" id="def_model_backward"><a class="viewcode-back" href="../../../../api/sparseml.pytorch.utils.html#sparseml.pytorch.utils.module.def_model_backward">[docs]</a><span class="k">def</span> <span class="nf">def_model_backward</span><span class="p">(</span>
    <span class="n">losses</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">],</span> <span class="n">model</span><span class="p">:</span> <span class="n">Module</span><span class="p">,</span> <span class="n">scaler</span><span class="p">:</span> <span class="n">GradScaler</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Default function to perform a backwards pass for a model and the calculated losses</span>
<span class="sd">    Calls backwards for the DEFAULT_LOSS_KEY in losses Dict</span>

<span class="sd">    :param model: the model to run the backward for</span>
<span class="sd">    :param losses: the losses dictionary containing named tensors,</span>
<span class="sd">                   DEFAULT_LOSS_KEY is expected to exist and backwards is called on that</span>
<span class="sd">    :param scaler: GradScaler object for running in mixed precision with amp. If scaler</span>
<span class="sd">        is not None will call scaler.scale on the loss object. Default is None</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># assume loss is at default loss key</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">losses</span><span class="p">[</span><span class="n">DEFAULT_LOSS_KEY</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">scaler</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">scale</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span></div>


<div class="viewcode-block" id="ModuleRunHooks"><a class="viewcode-back" href="../../../../api/sparseml.pytorch.utils.html#sparseml.pytorch.utils.module.ModuleRunHooks">[docs]</a><span class="k">class</span> <span class="nc">ModuleRunHooks</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Container for hooks that can be added to module runs like training and testing</span>
<span class="sd">    for different stages of running a batch through a model.</span>

<span class="sd">    | Lifecycle:</span>
<span class="sd">    |   - data batch size callback</span>
<span class="sd">    |   - data to device callback</span>
<span class="sd">    |   - batch start hook</span>
<span class="sd">    |   - data model forward callback</span>
<span class="sd">    |   - batch forward hook</span>
<span class="sd">    |   - loss calculation</span>
<span class="sd">    |   - batch loss hook</span>
<span class="sd">    |   - model backward callback</span>
<span class="sd">    |   - batch backward hook</span>
<span class="sd">    |   - optimizer / gradient update</span>
<span class="sd">    |   - batch end hook</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_batch_start_hooks</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_batch_forward_hooks</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_batch_loss_hooks</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_batch_backward_hooks</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_batch_end_hooks</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>

<div class="viewcode-block" id="ModuleRunHooks.register_batch_start_hook"><a class="viewcode-back" href="../../../../api/sparseml.pytorch.utils.html#sparseml.pytorch.utils.module.ModuleRunHooks.register_batch_start_hook">[docs]</a>    <span class="k">def</span> <span class="nf">register_batch_start_hook</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">hook</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="kc">None</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RemovableHandle</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Called at the start of a batch with the following info:</span>
<span class="sd">        (counter, step_count, batch_size, data)</span>
<span class="sd">        where counter is passed in to the run (ex: epoch),</span>
<span class="sd">        step_count is the number of items run so far,</span>
<span class="sd">        batch_size is the number of elements fed in the batch,</span>
<span class="sd">        data is the data output from the loader</span>

<span class="sd">        :param hook: the hook to add that is called into when reached in the</span>
<span class="sd">            batch process</span>
<span class="sd">        :return: a removable handle to remove the hook when desired</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">handle</span> <span class="o">=</span> <span class="n">RemovableHandle</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_batch_start_hooks</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_batch_start_hooks</span><span class="p">[</span><span class="n">handle</span><span class="o">.</span><span class="n">id</span><span class="p">]</span> <span class="o">=</span> <span class="n">hook</span>

        <span class="k">return</span> <span class="n">handle</span></div>

<div class="viewcode-block" id="ModuleRunHooks.register_batch_forward_hook"><a class="viewcode-back" href="../../../../api/sparseml.pytorch.utils.html#sparseml.pytorch.utils.module.ModuleRunHooks.register_batch_forward_hook">[docs]</a>    <span class="k">def</span> <span class="nf">register_batch_forward_hook</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">hook</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="kc">None</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RemovableHandle</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Called after forward execution of a batch in the model with the following info:</span>
<span class="sd">        (counter, step_count, batch_size, data, pred)</span>
<span class="sd">        where counter is passed in to the run (ex: epoch),</span>
<span class="sd">        step_count is the number of items run so far,</span>
<span class="sd">        batch_size is the number of elements fed in the batch,</span>
<span class="sd">        data is the data output from the loader,</span>
<span class="sd">        pred is the result from the model after the forward</span>

<span class="sd">        :param hook: the hook to add that is called into when reached in the</span>
<span class="sd">            batch process</span>
<span class="sd">        :return: a removable handle to remove the hook when desired</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">handle</span> <span class="o">=</span> <span class="n">RemovableHandle</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_batch_forward_hooks</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_batch_forward_hooks</span><span class="p">[</span><span class="n">handle</span><span class="o">.</span><span class="n">id</span><span class="p">]</span> <span class="o">=</span> <span class="n">hook</span>

        <span class="k">return</span> <span class="n">handle</span></div>

<div class="viewcode-block" id="ModuleRunHooks.register_batch_loss_hook"><a class="viewcode-back" href="../../../../api/sparseml.pytorch.utils.html#sparseml.pytorch.utils.module.ModuleRunHooks.register_batch_loss_hook">[docs]</a>    <span class="k">def</span> <span class="nf">register_batch_loss_hook</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">hook</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]],</span> <span class="kc">None</span><span class="p">]</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Called after loss calculation of the batch with the following info:</span>
<span class="sd">        (counter, step_count, batch_size, data, pred, losses)</span>
<span class="sd">        where counter is passed in to the run (ex: epoch),</span>
<span class="sd">        step_count is the number of items run so far,</span>
<span class="sd">        batch_size is the number of elements fed in the batch,</span>
<span class="sd">        data is the data output from the loader,</span>
<span class="sd">        pred is the result from the model after the forward,</span>
<span class="sd">        losses are the resulting loss dictionary</span>

<span class="sd">        :param hook: the hook to add that is called into when reached in the</span>
<span class="sd">            batch process</span>
<span class="sd">        :return: a removable handle to remove the hook when desired</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">handle</span> <span class="o">=</span> <span class="n">RemovableHandle</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_batch_loss_hooks</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_batch_loss_hooks</span><span class="p">[</span><span class="n">handle</span><span class="o">.</span><span class="n">id</span><span class="p">]</span> <span class="o">=</span> <span class="n">hook</span>

        <span class="k">return</span> <span class="n">handle</span></div>

<div class="viewcode-block" id="ModuleRunHooks.register_batch_backward_hook"><a class="viewcode-back" href="../../../../api/sparseml.pytorch.utils.html#sparseml.pytorch.utils.module.ModuleRunHooks.register_batch_backward_hook">[docs]</a>    <span class="k">def</span> <span class="nf">register_batch_backward_hook</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">hook</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]],</span> <span class="kc">None</span><span class="p">]</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Called after calling backward on the loss for the batch with the following info:</span>
<span class="sd">        (counter, step_count, batch_size, data, pred, losses)</span>
<span class="sd">        where counter is passed in to the run (ex: epoch),</span>
<span class="sd">        step_count is the number of items run so far,</span>
<span class="sd">        batch_size is the number of elements fed in the batch,</span>
<span class="sd">        data is the data output from the loader,</span>
<span class="sd">        pred is the result from the model after the forward,</span>
<span class="sd">        losses are the resulting loss dictionary</span>

<span class="sd">        :param hook: the hook to add that is called into when reached in the</span>
<span class="sd">            batch process</span>
<span class="sd">        :return: a removable handle to remove the hook when desired</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">handle</span> <span class="o">=</span> <span class="n">RemovableHandle</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_batch_backward_hooks</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_batch_backward_hooks</span><span class="p">[</span><span class="n">handle</span><span class="o">.</span><span class="n">id</span><span class="p">]</span> <span class="o">=</span> <span class="n">hook</span>

        <span class="k">return</span> <span class="n">handle</span></div>

<div class="viewcode-block" id="ModuleRunHooks.register_batch_end_hook"><a class="viewcode-back" href="../../../../api/sparseml.pytorch.utils.html#sparseml.pytorch.utils.module.ModuleRunHooks.register_batch_end_hook">[docs]</a>    <span class="k">def</span> <span class="nf">register_batch_end_hook</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">hook</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]],</span> <span class="kc">None</span><span class="p">]</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Called after all calculations are done for the batch with the following info:</span>
<span class="sd">        (counter, step_count, batch_size, data, pred, losses)</span>
<span class="sd">        where counter is passed in to the run (ex: epoch),</span>
<span class="sd">        step_count is the number of items run so far,</span>
<span class="sd">        batch_size is the number of elements fed in the batch,</span>
<span class="sd">        data is the data output from the loader,</span>
<span class="sd">        pred is the result from the model after the forward,</span>
<span class="sd">        losses are the resulting loss dictionary</span>

<span class="sd">        :param hook: the hook to add that is called into when reached in the</span>
<span class="sd">            batch process</span>
<span class="sd">        :return: a removable handle to remove the hook when desired</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">handle</span> <span class="o">=</span> <span class="n">RemovableHandle</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_batch_end_hooks</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_batch_end_hooks</span><span class="p">[</span><span class="n">handle</span><span class="o">.</span><span class="n">id</span><span class="p">]</span> <span class="o">=</span> <span class="n">hook</span>

        <span class="k">return</span> <span class="n">handle</span></div>

<div class="viewcode-block" id="ModuleRunHooks.invoke_batch_start"><a class="viewcode-back" href="../../../../api/sparseml.pytorch.utils.html#sparseml.pytorch.utils.module.ModuleRunHooks.invoke_batch_start">[docs]</a>    <span class="k">def</span> <span class="nf">invoke_batch_start</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">counter</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">step_count</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">Any</span>
    <span class="p">):</span>
        <span class="k">for</span> <span class="n">hook</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_start_hooks</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
            <span class="n">hook</span><span class="p">(</span><span class="n">counter</span><span class="p">,</span> <span class="n">step_count</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span></div>

<div class="viewcode-block" id="ModuleRunHooks.invoke_batch_forward"><a class="viewcode-back" href="../../../../api/sparseml.pytorch.utils.html#sparseml.pytorch.utils.module.ModuleRunHooks.invoke_batch_forward">[docs]</a>    <span class="k">def</span> <span class="nf">invoke_batch_forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">counter</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">step_count</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">pred</span><span class="p">:</span> <span class="n">Any</span>
    <span class="p">):</span>
        <span class="k">for</span> <span class="n">hook</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_forward_hooks</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
            <span class="n">hook</span><span class="p">(</span><span class="n">counter</span><span class="p">,</span> <span class="n">step_count</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span></div>

<div class="viewcode-block" id="ModuleRunHooks.invoke_batch_loss"><a class="viewcode-back" href="../../../../api/sparseml.pytorch.utils.html#sparseml.pytorch.utils.module.ModuleRunHooks.invoke_batch_loss">[docs]</a>    <span class="k">def</span> <span class="nf">invoke_batch_loss</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">counter</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">step_count</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">data</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
        <span class="n">pred</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
        <span class="n">losses</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">],</span>
    <span class="p">):</span>
        <span class="k">for</span> <span class="n">hook</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_loss_hooks</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
            <span class="n">hook</span><span class="p">(</span><span class="n">counter</span><span class="p">,</span> <span class="n">step_count</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">losses</span><span class="p">)</span></div>

<div class="viewcode-block" id="ModuleRunHooks.invoke_batch_backward"><a class="viewcode-back" href="../../../../api/sparseml.pytorch.utils.html#sparseml.pytorch.utils.module.ModuleRunHooks.invoke_batch_backward">[docs]</a>    <span class="k">def</span> <span class="nf">invoke_batch_backward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">counter</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">step_count</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">data</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
        <span class="n">pred</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
        <span class="n">losses</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">],</span>
    <span class="p">):</span>
        <span class="k">for</span> <span class="n">hook</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_backward_hooks</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
            <span class="n">hook</span><span class="p">(</span><span class="n">counter</span><span class="p">,</span> <span class="n">step_count</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">losses</span><span class="p">)</span></div>

<div class="viewcode-block" id="ModuleRunHooks.invoke_batch_end"><a class="viewcode-back" href="../../../../api/sparseml.pytorch.utils.html#sparseml.pytorch.utils.module.ModuleRunHooks.invoke_batch_end">[docs]</a>    <span class="k">def</span> <span class="nf">invoke_batch_end</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">counter</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">step_count</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">data</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
        <span class="n">pred</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
        <span class="n">losses</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">],</span>
    <span class="p">):</span>
        <span class="k">for</span> <span class="n">hook</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_end_hooks</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
            <span class="n">hook</span><span class="p">(</span><span class="n">counter</span><span class="p">,</span> <span class="n">step_count</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">losses</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="ModuleRunFuncs"><a class="viewcode-back" href="../../../../api/sparseml.pytorch.utils.html#sparseml.pytorch.utils.module.ModuleRunFuncs">[docs]</a><span class="k">class</span> <span class="nc">ModuleRunFuncs</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Functions used as callables to calculate or perform necessary operations</span>
<span class="sd">    for running a model through training or testing.</span>

<span class="sd">    | Lifecycle:</span>
<span class="sd">    |   - data batch size callback</span>
<span class="sd">    |   - data to device callback</span>
<span class="sd">    |   - batch start hook</span>
<span class="sd">    |   - data model forward callback</span>
<span class="sd">    |   - batch forward hook</span>
<span class="sd">    |   - loss calculation</span>
<span class="sd">    |   - batch loss hook</span>
<span class="sd">    |   - model backward callback</span>
<span class="sd">    |   - batch backward hook</span>
<span class="sd">    |   - optimizer / gradient update</span>
<span class="sd">    |   - batch end hook</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span> <span class="o">=</span> <span class="n">tensors_batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_to_device</span> <span class="o">=</span> <span class="n">tensors_to_device</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_model_forward</span> <span class="o">=</span> <span class="n">tensors_module_forward</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_model_backward</span> <span class="o">=</span> <span class="n">def_model_backward</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">batch_size</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Any</span><span class="p">],</span> <span class="nb">int</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :return used to calculate the batch size of a given grouping of tensors.</span>
<span class="sd">            Expected to be called with the output from a data loader and</span>
<span class="sd">            then return an int representing the batch size.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span>

    <span class="nd">@batch_size</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">batch_size</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Any</span><span class="p">],</span> <span class="nb">int</span><span class="p">]):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Used to calculate the batch size of a given grouping of tensors.</span>
<span class="sd">        Expected to be called with the output from a data loader</span>
<span class="sd">        then return an int representing the batch size.</span>

<span class="sd">        :param value: the callable used to calculate batch size</span>
<span class="sd">            for a grouping of tensors</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span> <span class="o">=</span> <span class="n">value</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">to_device</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Any</span><span class="p">,</span> <span class="nb">str</span><span class="p">],</span> <span class="n">Any</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :return used to place a given grouping of tensors onto the proper device.</span>
<span class="sd">            Expected to be called with the output from a data loader and the</span>
<span class="sd">            desired device as a string then return the grouping on the proper device.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_to_device</span>

    <span class="nd">@to_device</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">to_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Any</span><span class="p">,</span> <span class="nb">str</span><span class="p">],</span> <span class="n">Any</span><span class="p">]):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Used to place a given grouping of tensors onto the proper device.</span>
<span class="sd">        Expected to be called with the output from a data loader and the</span>
<span class="sd">        desired device as a string then return the grouping on the proper device</span>

<span class="sd">        :param value: the callable used to place a grouping of tensors onto</span>
<span class="sd">            the proper device</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_to_device</span> <span class="o">=</span> <span class="n">value</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">model_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Any</span><span class="p">,</span> <span class="n">Module</span><span class="p">],</span> <span class="n">Any</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :return used to propagate a given grouping of tensors through a model and</span>
<span class="sd">            return the result.</span>
<span class="sd">            Expected to be called with the model and the output from a data loader</span>
<span class="sd">            then return the result from the model forward pass.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_forward</span>

    <span class="nd">@model_forward</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">model_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Any</span><span class="p">,</span> <span class="n">Module</span><span class="p">],</span> <span class="n">Any</span><span class="p">]):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Used to propagate a given grouping of tensors through a model</span>
<span class="sd">        and return the result.</span>
<span class="sd">        Expected to be called with the model and the output from a data loader</span>
<span class="sd">        then return the result from the model forward pass.</span>

<span class="sd">        :param value: the callable used to run a grouping of tensors through a model</span>
<span class="sd">        :return: the result of running the data through the model</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_model_forward</span> <span class="o">=</span> <span class="n">value</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">model_backward</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">],</span> <span class="n">Module</span><span class="p">],</span> <span class="kc">None</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :return used to call backward for a given model and the calculated losses.</span>
<span class="sd">            Expected to be called with the model and the output from the loss function</span>
<span class="sd">            as a dict mapping of names to tensors returns nothing</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_backward</span>

    <span class="nd">@model_backward</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">model_backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">],</span> <span class="n">Module</span><span class="p">],</span> <span class="kc">None</span><span class="p">]):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Used to call backward for a given model and the calculated losses.</span>
<span class="sd">        Expected to be called with the model and the output from the loss function</span>
<span class="sd">        as a dict mapping of names to tensors returns nothing</span>

<span class="sd">        :param value: the callable used to run a backwards pass for the given</span>
<span class="sd">            loss functions</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_model_backward</span> <span class="o">=</span> <span class="n">value</span>

<div class="viewcode-block" id="ModuleRunFuncs.copy"><a class="viewcode-back" href="../../../../api/sparseml.pytorch.utils.html#sparseml.pytorch.utils.module.ModuleRunFuncs.copy">[docs]</a>    <span class="k">def</span> <span class="nf">copy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_funcs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Copy the functions from the current instance into a new instance</span>

<span class="sd">        :param run_funcs: the instance to copy the functions into</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">run_funcs</span> <span class="o">=</span> <span class="n">run_funcs</span>  <span class="c1"># type: ModuleRunFuncs</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span> <span class="o">=</span> <span class="n">run_funcs</span><span class="o">.</span><span class="n">_batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_to_device</span> <span class="o">=</span> <span class="n">run_funcs</span><span class="o">.</span><span class="n">_to_device</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_model_forward</span> <span class="o">=</span> <span class="n">run_funcs</span><span class="o">.</span><span class="n">_model_forward</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_model_backward</span> <span class="o">=</span> <span class="n">run_funcs</span><span class="o">.</span><span class="n">_model_backward</span></div></div>


<div class="viewcode-block" id="ModuleRunResults"><a class="viewcode-back" href="../../../../api/sparseml.pytorch.utils.html#sparseml.pytorch.utils.module.ModuleRunResults">[docs]</a><span class="k">class</span> <span class="nc">ModuleRunResults</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Class containing the results / losses from a model run for training or testing</span>
<span class="sd">    Keeps all result values as a dictionary and Tensor containing all values</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_results</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">results</span> <span class="o">=</span> <span class="p">[</span>
            <span class="s2">&quot;</span><span class="si">{}</span><span class="s2">=</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">result_mean</span><span class="p">(</span><span class="n">key</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">())</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_results</span>
        <span class="p">]</span>

        <span class="k">return</span> <span class="s2">&quot;ModuleRunResults(</span><span class="si">{}</span><span class="s2">)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">results</span><span class="p">))</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">results</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        All of the stored results for the loss functions</span>

<span class="sd">        :return: a dictionary containing a mapping of name (str) to a list of tensors</span>
<span class="sd">            that were recorded for that loss</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_results</span>

<div class="viewcode-block" id="ModuleRunResults.result"><a class="viewcode-back" href="../../../../api/sparseml.pytorch.utils.html#sparseml.pytorch.utils.module.ModuleRunResults.result">[docs]</a>    <span class="k">def</span> <span class="nf">result</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The result of a single loss function</span>

<span class="sd">        :param key: the name of the loss function to get the results for</span>
<span class="sd">        :return: a list of tensors containing all of the results for that loss</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_results</span><span class="p">[</span><span class="n">key</span><span class="p">]</span></div>

<div class="viewcode-block" id="ModuleRunResults.result_list_tensor"><a class="viewcode-back" href="../../../../api/sparseml.pytorch.utils.html#sparseml.pytorch.utils.module.ModuleRunResults.result_list_tensor">[docs]</a>    <span class="k">def</span> <span class="nf">result_list_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the results as a list tensor where all items have been stacked into</span>
<span class="sd">        the first index of the tensor.</span>

<span class="sd">        :param key: the name of the loss function to get the results for</span>
<span class="sd">        :return: a tensor containing all of the tensors for that result</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">result</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">res</span><span class="p">)</span></div>

<div class="viewcode-block" id="ModuleRunResults.result_mean"><a class="viewcode-back" href="../../../../api/sparseml.pytorch.utils.html#sparseml.pytorch.utils.module.ModuleRunResults.result_mean">[docs]</a>    <span class="k">def</span> <span class="nf">result_mean</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The mean result of a single loss function</span>

<span class="sd">        :param key: the name of the loss function to get the mean result for</span>
<span class="sd">        :return: a single tensor containing the average of all the results for that loss</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">result_list_tensor</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">res</span><span class="p">)</span></div>

<div class="viewcode-block" id="ModuleRunResults.result_std"><a class="viewcode-back" href="../../../../api/sparseml.pytorch.utils.html#sparseml.pytorch.utils.module.ModuleRunResults.result_std">[docs]</a>    <span class="k">def</span> <span class="nf">result_std</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The standard deviation of the result for a single loss function</span>

<span class="sd">        :param key: the name of the loss function to get the standard</span>
<span class="sd">            deviation result for</span>
<span class="sd">        :return: a single tensor containing the standard deviation of all</span>
<span class="sd">            the results for that loss</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">result_list_tensor</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">res</span><span class="p">)</span></div>

<div class="viewcode-block" id="ModuleRunResults.append"><a class="viewcode-back" href="../../../../api/sparseml.pytorch.utils.html#sparseml.pytorch.utils.module.ModuleRunResults.append">[docs]</a>    <span class="k">def</span> <span class="nf">append</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">losses</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">],</span> <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        add new losses to the current stored results</span>

<span class="sd">        :param losses: the losses to be added</span>
<span class="sd">        :param batch_size: the batch size the losses were run for</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">losses</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_results</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_results</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>

            <span class="n">result</span> <span class="o">=</span> <span class="n">val</span><span class="o">.</span><span class="n">detach_</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_results</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">result</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="ModuleDeviceContext"><a class="viewcode-back" href="../../../../api/sparseml.pytorch.utils.html#sparseml.pytorch.utils.module.ModuleDeviceContext">[docs]</a><span class="k">class</span> <span class="nc">ModuleDeviceContext</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Simple class to define device settings or context to be used when running a Module</span>

<span class="sd">    :param use_mixed_precision: set True to execute model using mixed precision with</span>
<span class="sd">        torch.cuda.amp. Default is False</span>
<span class="sd">    :param world_size: the world size (total number of devices) used when running</span>
<span class="sd">        the given module using DistributedDataParallel. Losses will be scaled by the</span>
<span class="sd">        world size. Default is 1.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">use_mixed_precision</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">world_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_use_mixed_precision</span> <span class="o">=</span> <span class="n">use_mixed_precision</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_world_size</span> <span class="o">=</span> <span class="n">world_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_validate</span><span class="p">()</span>

<div class="viewcode-block" id="ModuleDeviceContext.default_context"><a class="viewcode-back" href="../../../../api/sparseml.pytorch.utils.html#sparseml.pytorch.utils.module.ModuleDeviceContext.default_context">[docs]</a>    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">default_context</span><span class="p">():</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :return: A ModuleDeviceContext with default settings enabled</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">ModuleDeviceContext</span><span class="p">(</span><span class="n">use_mixed_precision</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">world_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></div>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">use_mixed_precision</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :return: True if mixed precision with torch.cuda.amp should be used.</span>
<span class="sd">            False otherwise</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_use_mixed_precision</span>

    <span class="nd">@use_mixed_precision</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">use_mixed_precision</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="nb">bool</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :param value: True if mixed precision with torch.cuda.amp should be used.</span>
<span class="sd">            False otherwise</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_use_mixed_precision</span> <span class="o">=</span> <span class="n">value</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_validate</span><span class="p">()</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">world_size</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :return: the world size (total number of devices) used when running</span>
<span class="sd">        the given module using DistributedDataParallel. Losses will be scaled by the</span>
<span class="sd">        world size</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_world_size</span>

    <span class="nd">@world_size</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">world_size</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :param value: the world size (total number of devices) used when running</span>
<span class="sd">        the given module using DistributedDataParallel. Losses will be scaled by the</span>
<span class="sd">        world size</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_world_size</span> <span class="o">=</span> <span class="n">value</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_validate</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_validate</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">use_mixed_precision</span><span class="p">,</span> <span class="nb">bool</span>
        <span class="p">),</span> <span class="s2">&quot;use_mixed_precision must be a boolean&quot;</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">&gt;</span> <span class="mi">0</span>
        <span class="p">),</span> <span class="s2">&quot;world_size must be a positive int&quot;</span></div>


<span class="k">class</span> <span class="nc">ModuleRunner</span><span class="p">(</span><span class="n">ABC</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Abstract class for running data through a module and recording the results</span>

<span class="sd">    :param module: the model to run evaluation for</span>
<span class="sd">    :param device: the default device to run evaluation on</span>
<span class="sd">        (where data will be copied to)</span>
<span class="sd">    :param loss: the loss functions callable used to calculate loss values after</span>
<span class="sd">        executing a forward pass</span>
<span class="sd">    :param loggers: list of loggers to log training results to</span>
<span class="sd">    :param log_name: the key to store all log files under</span>
<span class="sd">    :param log_steps: The number of steps (batches) to log at,</span>
<span class="sd">        ex 100 will log every 100 batches</span>
<span class="sd">    :param log_summary: True to log the final summary results after the run completes</span>
<span class="sd">    :param device_context: ModuleDeviceContext with settings to enable mixed precision</span>
<span class="sd">        using torch.cuda.amp or adjust losses when using DistributedDataParallel.</span>
<span class="sd">        Default settings do not use mixed precision or account for DDP.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">module</span><span class="p">:</span> <span class="n">Module</span><span class="p">,</span>
        <span class="n">device</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">loss</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">LossWrapper</span><span class="p">,</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Any</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">]],</span>
        <span class="n">loggers</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">PyTorchLogger</span><span class="p">],</span>
        <span class="n">log_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">log_steps</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">log_summary</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">device_context</span><span class="p">:</span> <span class="n">ModuleDeviceContext</span> <span class="o">=</span> <span class="n">ModuleDeviceContext</span><span class="o">.</span><span class="n">default_context</span><span class="p">(),</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_module</span> <span class="o">=</span> <span class="n">module</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_device</span> <span class="o">=</span> <span class="n">device</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">loss</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">LossWrapper</span><span class="p">)</span>
            <span class="k">else</span> <span class="n">LossWrapper</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">deconstruct_tensors</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_loggers</span> <span class="o">=</span> <span class="n">loggers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_log_name</span> <span class="o">=</span> <span class="n">log_name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_log_steps</span> <span class="o">=</span> <span class="n">log_steps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_log_summary</span> <span class="o">=</span> <span class="n">log_summary</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_device_context</span> <span class="o">=</span> <span class="n">device_context</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_run_funcs</span> <span class="o">=</span> <span class="n">ModuleRunFuncs</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_run_hooks</span> <span class="o">=</span> <span class="n">ModuleRunHooks</span><span class="p">()</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">module</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Module</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :return: the model to run</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_module</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">device</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :return: the default device to run on (where data will be copied to)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_device</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">loss</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">LossWrapper</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :return: the loss functions callable used to calculate loss values</span>
<span class="sd">            after executing a forward pass</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">run_funcs</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ModuleRunFuncs</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :return: functions used while running evaluation of the model as</span>
<span class="sd">            callbacks to do certain stages</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_run_funcs</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">run_hooks</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ModuleRunHooks</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :return: hooks used while running evaluation of the model to</span>
<span class="sd">            receive intermediate results</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_run_hooks</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">device_context</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ModuleDeviceContext</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :return: ModuleDeviceContext with settings for enabling mixed precision</span>
<span class="sd">        using torch.cuda.amp or adjusting losses when using DistributedDataParallel.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_device_context</span>

    <span class="k">def</span> <span class="nf">run</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">data_loader</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">,</span>
        <span class="n">desc</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">counter</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">show_progress</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">track_results</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">max_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="n">ModuleRunResults</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Run evaluation over all the data in the given data loader</span>

<span class="sd">        :param data_loader: the data loader used to gather batches to be</span>
<span class="sd">            run through the model</span>
<span class="sd">        :param desc: description used in the progress indicator</span>
<span class="sd">        :param counter: counter passed to the hooks for external</span>
<span class="sd">            state keeping (ex: epoch)</span>
<span class="sd">        :param show_progress: True to show a progress bar, False otherwise</span>
<span class="sd">        :param track_results: True to track and return the results of the evaluation,</span>
<span class="sd">            False to return None</span>
<span class="sd">        :param max_steps: maximum number of steps/batches to run through,</span>
<span class="sd">            will stop after reaching this. if &lt;= 0 then no restriction is placed</span>
<span class="sd">        :return: the results of evaluation if track_results else None</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_log_summary</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">track_results</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;runner must be run with track_results=True to log the final results&quot;</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_runner_setup</span><span class="p">()</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="n">counter_len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_loader</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="c1"># can&#39;t track data loaders length</span>
            <span class="n">counter_len</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">if</span> <span class="n">max_steps</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">counter_len</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">progress_steps</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">max_steps</span><span class="p">,</span> <span class="n">counter_len</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">max_steps</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">progress_steps</span> <span class="o">=</span> <span class="n">max_steps</span>
        <span class="k">elif</span> <span class="n">counter_len</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">progress_steps</span> <span class="o">=</span> <span class="n">counter_len</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">progress_steps</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="n">data_iter</span> <span class="o">=</span> <span class="p">(</span>
            <span class="nb">enumerate</span><span class="p">(</span><span class="n">data_loader</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">show_progress</span>
            <span class="k">else</span> <span class="n">auto</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">data_loader</span><span class="p">),</span> <span class="n">desc</span><span class="o">=</span><span class="n">desc</span><span class="p">,</span> <span class="n">total</span><span class="o">=</span><span class="n">progress_steps</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">results</span> <span class="o">=</span> <span class="n">ModuleRunResults</span><span class="p">()</span> <span class="k">if</span> <span class="n">track_results</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="n">previous_steps</span> <span class="o">=</span> <span class="p">(</span><span class="n">counter</span> <span class="k">if</span> <span class="n">counter</span> <span class="o">&gt;</span> <span class="o">-</span><span class="mi">1</span> <span class="k">else</span> <span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="n">counter_len</span>
        <span class="n">first_batch_size</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">epoch_timer</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">batch</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">data_iter</span><span class="p">:</span>
            <span class="n">step_timer</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_run_funcs</span><span class="o">.</span><span class="n">batch_size</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>  <span class="c1"># type: int</span>

            <span class="k">if</span> <span class="n">first_batch_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">first_batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>

            <span class="n">should_log</span> <span class="o">=</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_loggers</span>
                <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_log_steps</span>
                <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_log_steps</span> <span class="o">&gt;</span> <span class="mi">0</span>
                <span class="ow">and</span> <span class="n">batch</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">_log_steps</span> <span class="o">==</span> <span class="mi">0</span>
            <span class="p">)</span>
            <span class="n">log_step</span> <span class="o">=</span> <span class="n">previous_steps</span> <span class="o">+</span> <span class="n">batch</span>
            <span class="n">batch_results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_runner_batch</span><span class="p">(</span>
                <span class="n">counter</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">should_log</span><span class="p">,</span> <span class="n">log_step</span>
            <span class="p">)</span>

            <span class="k">if</span> <span class="n">should_log</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">loss</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">batch_results</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_log_scalar</span><span class="p">(</span>
                        <span class="s2">&quot;</span><span class="si">{}</span><span class="s2">/</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_log_name</span><span class="p">,</span> <span class="n">loss</span><span class="p">),</span>
                        <span class="n">val</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
                        <span class="n">log_step</span><span class="p">,</span>
                    <span class="p">)</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">_log_scalar</span><span class="p">(</span>
                    <span class="s2">&quot;</span><span class="si">{}</span><span class="s2">/Epoch Counter&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_log_name</span><span class="p">),</span>
                    <span class="n">counter</span><span class="p">,</span>
                    <span class="n">log_step</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_log_scalar</span><span class="p">(</span>
                    <span class="s2">&quot;</span><span class="si">{}</span><span class="s2">/Batch Size&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_log_name</span><span class="p">),</span>
                    <span class="n">batch_size</span><span class="p">,</span>
                    <span class="n">log_step</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">step_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">step_timer</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_log_scalar</span><span class="p">(</span>
                    <span class="s2">&quot;</span><span class="si">{}</span><span class="s2">/Seconds per step&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_log_name</span><span class="p">),</span>
                    <span class="n">step_time</span><span class="p">,</span>
                    <span class="n">log_step</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_log_scalar</span><span class="p">(</span>
                    <span class="s2">&quot;</span><span class="si">{}</span><span class="s2">/Steps per second&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_log_name</span><span class="p">),</span>
                    <span class="mf">1.0</span> <span class="o">/</span> <span class="n">step_time</span><span class="p">,</span>
                    <span class="n">log_step</span><span class="p">,</span>
                <span class="p">)</span>

                <span class="k">if</span> <span class="n">progress_steps</span><span class="p">:</span>
                    <span class="n">remaining_steps</span> <span class="o">=</span> <span class="n">progress_steps</span> <span class="o">-</span> <span class="n">batch</span> <span class="o">-</span> <span class="mi">1</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_log_scalar</span><span class="p">(</span>
                        <span class="s2">&quot;</span><span class="si">{}</span><span class="s2">/Est remaining minutes&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_log_name</span><span class="p">),</span>
                        <span class="p">(</span><span class="n">step_time</span> <span class="o">*</span> <span class="n">remaining_steps</span><span class="p">)</span> <span class="o">/</span> <span class="mi">60</span><span class="p">,</span>
                        <span class="n">log_step</span><span class="p">,</span>
                    <span class="p">)</span>

            <span class="k">if</span> <span class="n">results</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">batch_results</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>

            <span class="k">if</span> <span class="mi">0</span> <span class="o">&lt;</span> <span class="n">max_steps</span> <span class="o">&lt;=</span> <span class="n">batch</span><span class="p">:</span>
                <span class="k">break</span>

        <span class="n">should_log</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loggers</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_log_summary</span> <span class="ow">and</span> <span class="n">results</span>
        <span class="n">log_step</span> <span class="o">=</span> <span class="n">counter</span>  <span class="c1"># log under the counter step for the summaries</span>

        <span class="k">if</span> <span class="n">should_log</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">loss</span> <span class="ow">in</span> <span class="n">results</span><span class="o">.</span><span class="n">results</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="n">val</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">result_mean</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_log_scalar</span><span class="p">(</span>
                    <span class="s2">&quot;</span><span class="si">{}</span><span class="s2">/</span><span class="si">{}</span><span class="s2"> Summary&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_log_name</span><span class="p">,</span> <span class="n">loss</span><span class="p">),</span>
                    <span class="n">val</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
                    <span class="n">log_step</span><span class="p">,</span>
                <span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_log_scalar</span><span class="p">(</span>
                <span class="s2">&quot;</span><span class="si">{}</span><span class="s2">/Batch Size Summary&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_log_name</span><span class="p">),</span>
                <span class="n">first_batch_size</span><span class="p">,</span>
                <span class="n">log_step</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_log_scalar</span><span class="p">(</span>
                <span class="s2">&quot;</span><span class="si">{}</span><span class="s2">/Minutes per epoch&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_log_name</span><span class="p">),</span>
                <span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">epoch_timer</span><span class="p">)</span> <span class="o">/</span> <span class="mi">60</span><span class="p">,</span>
                <span class="n">log_step</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_runner_complete</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="n">should_log</span><span class="p">,</span> <span class="n">log_step</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">results</span>

    <span class="k">def</span> <span class="nf">run_epoch</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">data_loader</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">,</span>
        <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">show_progress</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">track_results</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">max_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Convenience function for evaluation over all the data in the given data loader</span>
<span class="sd">        for a specific epoch and making the progress visible.</span>

<span class="sd">        :param data_loader: the data loader used to gather batches to be run</span>
<span class="sd">            through the model</span>
<span class="sd">        :param epoch: the current evaluation epoch number</span>
<span class="sd">        :param show_progress: True to show a progress bar, False otherwise</span>
<span class="sd">        :param track_results: True to track and return the results of the training,</span>
<span class="sd">            False to return None</span>
<span class="sd">        :param max_steps: maximum number of steps/batches to run through,</span>
<span class="sd">            will stop after reaching this. if &lt;= 0 then no restriction is placed</span>
<span class="sd">        :return: the results of evaluation if track_results else None</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
            <span class="n">data_loader</span><span class="p">,</span>
            <span class="s2">&quot;</span><span class="si">{}</span><span class="s2"> epoch </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_log_name</span><span class="p">,</span> <span class="n">epoch</span><span class="p">),</span>
            <span class="n">epoch</span><span class="p">,</span>
            <span class="n">show_progress</span><span class="p">,</span>
            <span class="n">track_results</span><span class="p">,</span>
            <span class="n">max_steps</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_log_scalar</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">item</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">step</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">logger</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loggers</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">log_scalar</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">item</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">_runner_setup</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">_runner_batch</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">counter</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">batch</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">data</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
        <span class="n">should_log</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">log_step</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">_runner_complete</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">results</span><span class="p">:</span> <span class="n">ModuleRunResults</span><span class="p">,</span> <span class="n">should_log</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span> <span class="n">log_step</span><span class="p">:</span> <span class="nb">int</span>
    <span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>


<div class="viewcode-block" id="ModuleTrainer"><a class="viewcode-back" href="../../../../api/sparseml.pytorch.utils.html#sparseml.pytorch.utils.module.ModuleTrainer">[docs]</a><span class="k">class</span> <span class="nc">ModuleTrainer</span><span class="p">(</span><span class="n">ModuleRunner</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Container for running a module through training over a given data loader</span>
<span class="sd">    for specific settings.</span>

<span class="sd">    | Lifecycle:</span>
<span class="sd">    |   - data batch size callback</span>
<span class="sd">    |   - data to device callback</span>
<span class="sd">    |   - batch start hook</span>
<span class="sd">    |   - data model forward callback</span>
<span class="sd">    |   - batch forward hook</span>
<span class="sd">    |   - loss calculation</span>
<span class="sd">    |   - batch loss hook</span>
<span class="sd">    |   - model backward callback</span>
<span class="sd">    |   - batch backward hook</span>
<span class="sd">    |   - optimizer / gradient update</span>
<span class="sd">    |   - batch end hook</span>

<span class="sd">    :param module: the model to run training for</span>
<span class="sd">    :param device: the default device to run training on (where data will be copied to)</span>
<span class="sd">    :param loss: the loss functions callable used to calculate loss values</span>
<span class="sd">        after executing a forward pass</span>
<span class="sd">    :param optimizer: the optimizer used to apply gradient updates with</span>
<span class="sd">    :param num_accumulated_batches: number of batches to accumulate before</span>
<span class="sd">        updating the optimizer</span>
<span class="sd">    :param optim_closure: a closure passed into the optimizer on step</span>
<span class="sd">    :param loggers: list of loggers to log training results to</span>
<span class="sd">    :param log_name: the key to store all log files under</span>
<span class="sd">    :param log_steps: The number of steps (batches) to log at,</span>
<span class="sd">        ex 100 will log every 100 batches</span>
<span class="sd">    :param log_summary: True to log the final summary results after the run completes</span>
<span class="sd">    :param device_context: ModuleDeviceContext with settings to enable mixed precision</span>
<span class="sd">        using torch.cuda.amp or adjust losses when using DistributedDataParallel.</span>
<span class="sd">        Default settings do not use mixed precision or account for DDP.</span>
<span class="sd">        Will raise an exception if torch version does not support amp.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">module</span><span class="p">:</span> <span class="n">Module</span><span class="p">,</span>
        <span class="n">device</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">loss</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">LossWrapper</span><span class="p">,</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Any</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">]],</span>
        <span class="n">optimizer</span><span class="p">:</span> <span class="n">Optimizer</span><span class="p">,</span>
        <span class="n">num_accumulated_batches</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">optim_closure</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">loggers</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">PyTorchLogger</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">log_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;Train&quot;</span><span class="p">,</span>
        <span class="n">log_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
        <span class="n">log_summary</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">device_context</span><span class="p">:</span> <span class="n">ModuleDeviceContext</span> <span class="o">=</span> <span class="n">ModuleDeviceContext</span><span class="o">.</span><span class="n">default_context</span><span class="p">(),</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">module</span><span class="p">,</span>
            <span class="n">device</span><span class="p">,</span>
            <span class="n">loss</span><span class="p">,</span>
            <span class="n">loggers</span><span class="p">,</span>
            <span class="n">log_name</span><span class="p">,</span>
            <span class="n">log_steps</span><span class="p">,</span>
            <span class="n">log_summary</span><span class="p">,</span>
            <span class="n">device_context</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer</span> <span class="o">=</span> <span class="n">optimizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_num_accumulated_batches</span> <span class="o">=</span> <span class="n">num_accumulated_batches</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_optim_closure</span> <span class="o">=</span> <span class="n">optim_closure</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_accumulated</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_context</span><span class="o">.</span><span class="n">use_mixed_precision</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">autocast</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">GradScaler</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="nb">type</span><span class="p">(</span><span class="n">amp_import_error</span><span class="p">)(</span>
                    <span class="n">amp_import_error</span><span class="o">.</span><span class="n">msg</span>
                    <span class="o">+</span> <span class="s2">&quot; autocast and GradScaler introduced in torch version 1.6.0.&quot;</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="n">optim_closure</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="s2">&quot;Optimizer closures are not currently supported when training &quot;</span>
                    <span class="s2">&quot;using torch.cuda.amp.GradScaler.&quot;</span>
                <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_scaler</span> <span class="o">=</span> <span class="n">GradScaler</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_scaler</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">optimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optimizer</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :return: the optimizer used to apply gradient updates with</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">num_accumulated_batches</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :return: number of batches to accumulate before updating the optimizer</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_accumulated_batches</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">optim_closure</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="n">Callable</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :return: a closure passed into the optimizer on step</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_optim_closure</span>

    <span class="k">def</span> <span class="nf">_runner_setup</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_module</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_module</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_accumulated</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="nf">_runner_batch</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">counter</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">batch</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">data</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
        <span class="n">should_log</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">log_step</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="c1"># setup</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_accumulated</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_run_funcs</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_run_hooks</span><span class="o">.</span><span class="n">invoke_batch_start</span><span class="p">(</span><span class="n">counter</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>

        <span class="c1"># optimizer / gradients reset</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_accumulated</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_accumulated_batches</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="n">forward_context</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">autocast</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_context</span><span class="o">.</span><span class="n">use_mixed_precision</span> <span class="k">else</span> <span class="n">ExitStack</span>
        <span class="p">)</span>
        <span class="k">with</span> <span class="n">forward_context</span><span class="p">():</span>
            <span class="c1"># forward steps</span>
            <span class="n">pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_run_funcs</span><span class="o">.</span><span class="n">model_forward</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_module</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_run_hooks</span><span class="o">.</span><span class="n">invoke_batch_forward</span><span class="p">(</span><span class="n">counter</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>

            <span class="c1"># loss calculation</span>
            <span class="n">losses</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>
            <span class="c1"># scale loss by world size</span>
            <span class="n">losses</span><span class="p">[</span><span class="n">DEFAULT_LOSS_KEY</span><span class="p">]</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_context</span><span class="o">.</span><span class="n">world_size</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_run_hooks</span><span class="o">.</span><span class="n">invoke_batch_loss</span><span class="p">(</span>
                <span class="n">counter</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">losses</span>
            <span class="p">)</span>

        <span class="c1"># backward steps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_run_funcs</span><span class="o">.</span><span class="n">model_backward</span><span class="p">(</span><span class="n">losses</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_module</span><span class="p">,</span> <span class="n">scaler</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_scaler</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_run_hooks</span><span class="o">.</span><span class="n">invoke_batch_backward</span><span class="p">(</span>
            <span class="n">counter</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">losses</span>
        <span class="p">)</span>

        <span class="c1"># optimizer / gradients update</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_accumulated</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_accumulated_batches</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_context</span><span class="o">.</span><span class="n">use_mixed_precision</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_scaler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_optimizer</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_scaler</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">closure</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_optim_closure</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_accumulated</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_run_hooks</span><span class="o">.</span><span class="n">invoke_batch_end</span><span class="p">(</span><span class="n">counter</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">losses</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">should_log</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_log_scalar</span><span class="p">(</span>
                <span class="s2">&quot;</span><span class="si">{}</span><span class="s2">/Learning Rate&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_log_name</span><span class="p">),</span>
                <span class="n">get_optim_learning_rate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_optimizer</span><span class="p">),</span>
                <span class="n">log_step</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="n">losses</span>

    <span class="k">def</span> <span class="nf">_runner_complete</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">results</span><span class="p">:</span> <span class="n">ModuleRunResults</span><span class="p">,</span> <span class="n">should_log</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span> <span class="n">log_step</span><span class="p">:</span> <span class="nb">int</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">should_log</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_log_scalar</span><span class="p">(</span>
                <span class="s2">&quot;</span><span class="si">{}</span><span class="s2">/Learning Rate Summary&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_log_name</span><span class="p">),</span>
                <span class="n">get_optim_learning_rate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_optimizer</span><span class="p">),</span>
                <span class="n">log_step</span><span class="p">,</span>
            <span class="p">)</span></div>


<div class="viewcode-block" id="ModuleTester"><a class="viewcode-back" href="../../../../api/sparseml.pytorch.utils.html#sparseml.pytorch.utils.module.ModuleTester">[docs]</a><span class="k">class</span> <span class="nc">ModuleTester</span><span class="p">(</span><span class="n">ModuleRunner</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Container for running a module through evaluation over a given data loader</span>
<span class="sd">    for specific settings.</span>

<span class="sd">    | Lifecycle:</span>
<span class="sd">    |   - data batch size callback</span>
<span class="sd">    |   - data to device callback</span>
<span class="sd">    |   - batch start hook</span>
<span class="sd">    |   - data model forward callback</span>
<span class="sd">    |   - batch forward hook</span>
<span class="sd">    |   - loss calculation</span>
<span class="sd">    |   - batch loss hook</span>
<span class="sd">    |   - batch end hook</span>

<span class="sd">    :param module: the model to run evaluation for</span>
<span class="sd">    :param device: the default device to run evaluation on</span>
<span class="sd">        (where data will be copied to)</span>
<span class="sd">    :param loss: the loss functions callable used to calculate loss values after</span>
<span class="sd">        executing a forward pass</span>
<span class="sd">    :param loggers: list of loggers to log training results to</span>
<span class="sd">    :param log_name: the key to store all log files under</span>
<span class="sd">    :param log_steps: The number of steps (batches) to log at,</span>
<span class="sd">        ex 100 will log every 100 batches</span>
<span class="sd">    :param log_summary: True to log the final summary results after the run completes</span>
<span class="sd">    :param device_context: ModuleDeviceContext with settings to enable mixed precision</span>
<span class="sd">        using torch.cuda.amp or adjust losses when using DistributedDataParallel.</span>
<span class="sd">        Default settings do not use mixed precision or account for DDP.</span>
<span class="sd">        Will raise an exception if torch version does not support amp.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">module</span><span class="p">:</span> <span class="n">Module</span><span class="p">,</span>
        <span class="n">device</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">loss</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">LossWrapper</span><span class="p">,</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Any</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">]],</span>
        <span class="n">loggers</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">PyTorchLogger</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">log_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;Test&quot;</span><span class="p">,</span>
        <span class="n">log_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
        <span class="n">log_summary</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">device_context</span><span class="p">:</span> <span class="n">ModuleDeviceContext</span> <span class="o">=</span> <span class="n">ModuleDeviceContext</span><span class="o">.</span><span class="n">default_context</span><span class="p">(),</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">module</span><span class="p">,</span>
            <span class="n">device</span><span class="p">,</span>
            <span class="n">loss</span><span class="p">,</span>
            <span class="n">loggers</span><span class="p">,</span>
            <span class="n">log_name</span><span class="p">,</span>
            <span class="n">log_steps</span><span class="p">,</span>
            <span class="n">log_summary</span><span class="p">,</span>
            <span class="n">device_context</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_context</span><span class="o">.</span><span class="n">use_mixed_precision</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">autocast</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">GradScaler</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="nb">type</span><span class="p">(</span><span class="n">amp_import_error</span><span class="p">)(</span>
                    <span class="n">amp_import_error</span><span class="o">.</span><span class="n">msg</span>
                    <span class="o">+</span> <span class="s2">&quot; autocast and GradScaler introduced in torch version 1.6.0.&quot;</span>
                <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_runner_setup</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_module</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_module</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_runner_batch</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">counter</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">batch</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">data</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
        <span class="n">should_log</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">log_step</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="c1"># setup</span>
            <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_run_funcs</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_run_hooks</span><span class="o">.</span><span class="n">invoke_batch_start</span><span class="p">(</span><span class="n">counter</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>

            <span class="n">forward_context</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">autocast</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_context</span><span class="o">.</span><span class="n">use_mixed_precision</span> <span class="k">else</span> <span class="n">ExitStack</span>
            <span class="p">)</span>
            <span class="k">with</span> <span class="n">forward_context</span><span class="p">():</span>
                <span class="c1"># forward steps</span>
                <span class="n">pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_run_funcs</span><span class="o">.</span><span class="n">model_forward</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_module</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_run_hooks</span><span class="o">.</span><span class="n">invoke_batch_forward</span><span class="p">(</span>
                    <span class="n">counter</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">pred</span>
                <span class="p">)</span>

                <span class="c1"># loss steps</span>
                <span class="n">losses</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>
                <span class="c1"># scale loss by world size</span>
                <span class="n">losses</span><span class="p">[</span><span class="n">DEFAULT_LOSS_KEY</span><span class="p">]</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_context</span><span class="o">.</span><span class="n">world_size</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_run_hooks</span><span class="o">.</span><span class="n">invoke_batch_loss</span><span class="p">(</span>
                    <span class="n">counter</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">losses</span>
                <span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_run_hooks</span><span class="o">.</span><span class="n">invoke_batch_end</span><span class="p">(</span>
                <span class="n">counter</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">losses</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="n">losses</span>

    <span class="k">def</span> <span class="nf">_runner_complete</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">results</span><span class="p">:</span> <span class="n">ModuleRunResults</span><span class="p">,</span> <span class="n">should_log</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span> <span class="n">log_step</span><span class="p">:</span> <span class="nb">int</span>
    <span class="p">):</span>
        <span class="k">pass</span></div>
</pre></div>

           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021 - present / Neuralmagic, Inc. All Rights Reserved. Licensed under the Apache License, Version 2.0 (the &#34;License&#34;).

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-128364174-1', 'auto');
    
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>