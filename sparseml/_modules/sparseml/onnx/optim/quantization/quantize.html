

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>sparseml.onnx.optim.quantization.quantize &mdash; SparseML 0.1.0 documentation</title>
  

  
  <link rel="stylesheet" href="../../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../../_static/copybutton.css" type="text/css" />

  
  
    <link rel="shortcut icon" href="../../../../../_static/favicon.ico"/>
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../../../" src="../../../../../_static/documentation_options.js"></script>
        <script src="../../../../../_static/jquery.js"></script>
        <script src="../../../../../_static/underscore.js"></script>
        <script src="../../../../../_static/doctools.js"></script>
        <script src="../../../../../_static/clipboard.min.js"></script>
        <script src="../../../../../_static/copybutton.js"></script>
    
    <script type="text/javascript" src="../../../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../../../index.html" class="icon icon-home"> SparseML
          

          
            
            <img src="../../../../../_static/icon-sparseml.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                0.1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">General</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../quicktour.html">Quick Tour</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../recipes.html">Sparsification Recipes</a></li>
</ul>
<p class="caption"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../api/sparseml.html">sparseml package</a></li>
</ul>
<p class="caption"><span class="caption-text">Help</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://github.com/neuralmagic/sparseml/issues">Bugs, Feature Requests</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/neuralmagic/sparseml/discussions">Support, General Q&amp;A</a></li>
<li class="toctree-l1"><a class="reference external" href="https://docs.neuralmagic.com">Neural Magic Docs</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../../index.html">SparseML</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../../../../index.html">Module code</a> &raquo;</li>
        
      <li>sparseml.onnx.optim.quantization.quantize</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for sparseml.onnx.optim.quantization.quantize</h1><div class="highlight"><pre>
<span></span><span class="c1"># Licensed under the MIT License.</span>
<span class="c1">#</span>
<span class="c1"># Cloned from:</span>
<span class="c1"># https://github.com/microsoft/onnxruntime/tree/master/onnxruntime/python/tools/quantization</span>
<span class="c1"># Latest Commit: fc5e65a</span>
<span class="c1"># Modifications: quantize_data function modified for compatibility with NMIE</span>
<span class="c1"># --------------------------------------------------------------------------</span>

<span class="c1"># neuralmagic: no copyright</span>
<span class="c1"># flake8: noqa</span>

<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">struct</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">onnx</span>
<span class="kn">import</span> <span class="nn">onnx.numpy_helper</span>
<span class="kn">from</span> <span class="nn">onnx</span> <span class="kn">import</span> <span class="n">onnx_pb</span> <span class="k">as</span> <span class="n">onnx_proto</span>
<span class="kn">from</span> <span class="nn">onnx</span> <span class="kn">import</span> <span class="n">shape_inference</span>


<span class="n">__producer__</span> <span class="o">=</span> <span class="s2">&quot;onnx.quantize&quot;</span>
<span class="n">__version__</span> <span class="o">=</span> <span class="s2">&quot;0.1.0&quot;</span>
<span class="n">onnx_domain</span> <span class="o">=</span> <span class="s2">&quot;ai.onnx&quot;</span>
<span class="n">ms_domain</span> <span class="o">=</span> <span class="s2">&quot;com.microsoft&quot;</span>
<span class="n">onnx_op_set_version</span> <span class="o">=</span> <span class="mi">11</span>

<span class="n">type_to_name</span> <span class="o">=</span> <span class="p">{</span>
    <span class="mi">1</span><span class="p">:</span> <span class="s2">&quot;FLOAT&quot;</span><span class="p">,</span>
    <span class="mi">2</span><span class="p">:</span> <span class="s2">&quot;UINT8&quot;</span><span class="p">,</span>
    <span class="mi">3</span><span class="p">:</span> <span class="s2">&quot;INT8&quot;</span><span class="p">,</span>
    <span class="mi">4</span><span class="p">:</span> <span class="s2">&quot;UINT16&quot;</span><span class="p">,</span>
    <span class="mi">5</span><span class="p">:</span> <span class="s2">&quot;INT16&quot;</span><span class="p">,</span>
    <span class="mi">6</span><span class="p">:</span> <span class="s2">&quot;INT32&quot;</span><span class="p">,</span>
    <span class="mi">7</span><span class="p">:</span> <span class="s2">&quot;INT64&quot;</span><span class="p">,</span>
    <span class="mi">8</span><span class="p">:</span> <span class="s2">&quot;STRING&quot;</span><span class="p">,</span>
    <span class="mi">9</span><span class="p">:</span> <span class="s2">&quot;BOOL&quot;</span><span class="p">,</span>
    <span class="mi">10</span><span class="p">:</span> <span class="s2">&quot;FLOAT16&quot;</span><span class="p">,</span>
    <span class="mi">11</span><span class="p">:</span> <span class="s2">&quot;DOUBLE&quot;</span><span class="p">,</span>
    <span class="mi">12</span><span class="p">:</span> <span class="s2">&quot;UINT32&quot;</span><span class="p">,</span>
    <span class="mi">13</span><span class="p">:</span> <span class="s2">&quot;UINT64&quot;</span><span class="p">,</span>
    <span class="mi">14</span><span class="p">:</span> <span class="s2">&quot;COMPLEX64&quot;</span><span class="p">,</span>
    <span class="mi">15</span><span class="p">:</span> <span class="s2">&quot;COMPLEX128&quot;</span><span class="p">,</span>
<span class="p">}</span>

<span class="c1"># Quantization mode</span>
<span class="c1"># IntegerOps: Use IntegerOps in quantized model. Only ConvInteger and MatMulInteger ops are supported now.</span>
<span class="c1"># QLinearOps: Use QLinearOps in quantized model. Only QLinearConv and QLinearMatMul ops are supported now.</span>


<div class="viewcode-block" id="QuantizationMode"><a class="viewcode-back" href="../../../../../api/sparseml.onnx.optim.quantization.html#sparseml.onnx.optim.quantization.quantize.QuantizationMode">[docs]</a><span class="k">class</span> <span class="nc">QuantizationMode</span><span class="p">:</span>
    <span class="n">IntegerOps</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">QLinearOps</span> <span class="o">=</span> <span class="mi">1</span></div>


<span class="n">quantization_modes</span> <span class="o">=</span> <span class="p">[</span>
    <span class="nb">getattr</span><span class="p">(</span><span class="n">QuantizationMode</span><span class="p">,</span> <span class="n">attr</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">attr</span> <span class="ow">in</span> <span class="nb">dir</span><span class="p">(</span><span class="n">QuantizationMode</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">callable</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">QuantizationMode</span><span class="p">,</span> <span class="n">attr</span><span class="p">))</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">attr</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;__&quot;</span><span class="p">)</span>
<span class="p">]</span>


<div class="viewcode-block" id="QuantizedInitializer"><a class="viewcode-back" href="../../../../../api/sparseml.onnx.optim.quantization.html#sparseml.onnx.optim.quantization.quantize.QuantizedInitializer">[docs]</a><span class="k">class</span> <span class="nc">QuantizedInitializer</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Represents a linearly quantized weight input from ONNX operators</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">name</span><span class="p">,</span>
        <span class="n">initializer</span><span class="p">,</span>
        <span class="n">rmins</span><span class="p">,</span>
        <span class="n">rmaxs</span><span class="p">,</span>
        <span class="n">zero_points</span><span class="p">,</span>
        <span class="n">scales</span><span class="p">,</span>
        <span class="n">data</span><span class="o">=</span><span class="p">[],</span>
        <span class="n">quantized_data</span><span class="o">=</span><span class="p">[],</span>
        <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">qType</span><span class="o">=</span><span class="n">onnx_proto</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">UINT8</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">initializer</span> <span class="o">=</span> <span class="n">initializer</span>  <span class="c1"># TensorProto initializer in ONNX graph</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rmins</span> <span class="o">=</span> <span class="n">rmins</span>  <span class="c1"># List of minimum range for each axis</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rmaxs</span> <span class="o">=</span> <span class="n">rmaxs</span>  <span class="c1"># List of maximum range for each axis</span>
        <span class="c1"># 1D tensor of zero points computed for each axis. scalar if axis is empty</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">zero_points</span> <span class="o">=</span> <span class="n">zero_points</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scales</span> <span class="o">=</span> <span class="n">scales</span>  <span class="c1"># 1D tensor of scales computed for each axis. scalar if axis is empty</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">data</span>  <span class="c1"># original data from initializer TensorProto</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">quantized_data</span> <span class="o">=</span> <span class="n">quantized_data</span>  <span class="c1"># weight-packed data from data</span>
        <span class="c1"># Scalar to specify which dimension in the initializer to weight pack.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">axis</span> <span class="o">=</span> <span class="n">axis</span>
        <span class="c1"># If empty, single zero point and scales computed from a single rmin and rmax</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">qType</span> <span class="o">=</span> <span class="n">qType</span>  <span class="c1"># type of quantized data.</span></div>


<div class="viewcode-block" id="QuantizedValueType"><a class="viewcode-back" href="../../../../../api/sparseml.onnx.optim.quantization.html#sparseml.onnx.optim.quantization.quantize.QuantizedValueType">[docs]</a><span class="k">class</span> <span class="nc">QuantizedValueType</span><span class="p">:</span>
    <span class="n">Input</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">Initializer</span> <span class="o">=</span> <span class="mi">1</span></div>


<div class="viewcode-block" id="QuantizedValue"><a class="viewcode-back" href="../../../../../api/sparseml.onnx.optim.quantization.html#sparseml.onnx.optim.quantization.quantize.QuantizedValue">[docs]</a><span class="k">class</span> <span class="nc">QuantizedValue</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Represents a linearly quantized value (input/output/intializer)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">name</span><span class="p">,</span>
        <span class="n">new_quantized_name</span><span class="p">,</span>
        <span class="n">scale_name</span><span class="p">,</span>
        <span class="n">zero_point_name</span><span class="p">,</span>
        <span class="n">quantized_value_type</span><span class="p">,</span>
        <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">qType</span><span class="o">=</span><span class="n">onnx_proto</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">UINT8</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">original_name</span> <span class="o">=</span> <span class="n">name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">q_name</span> <span class="o">=</span> <span class="n">new_quantized_name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale_name</span> <span class="o">=</span> <span class="n">scale_name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">zp_name</span> <span class="o">=</span> <span class="n">zero_point_name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">value_type</span> <span class="o">=</span> <span class="n">quantized_value_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">axis</span> <span class="o">=</span> <span class="n">axis</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">qType</span> <span class="o">=</span> <span class="n">qType</span></div>


<div class="viewcode-block" id="quantize_data"><a class="viewcode-back" href="../../../../../api/sparseml.onnx.optim.quantization.html#sparseml.onnx.optim.quantization.quantize.quantize_data">[docs]</a><span class="k">def</span> <span class="nf">quantize_data</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">quantize_range</span><span class="p">,</span> <span class="n">qType</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    :parameter data: data to quantize</span>
<span class="sd">    :parameter quantize_range: list of data to weight pack.</span>
<span class="sd">    :parameter qType: data type to quantize to. Supported types UINT8 and INT8</span>
<span class="sd">    :return: minimum, maximum, zero point, scale, and quantized weights</span>
<span class="sd">    To pack weights, we compute a linear transformation</span>
<span class="sd">        - when data type == uint8 mode, from [rmin, rmax] -&gt; [0, 2^{b-1}] and</span>
<span class="sd">        - when data type == int8, from [-m , m] -&gt; [-(2^{b-1}-1), 2^{b-1}-1] where</span>
<span class="sd">            m = max(abs(rmin), abs(rmax))</span>
<span class="sd">    and add necessary intermediate nodes to trasnform quantized weight to full weight using the equation</span>
<span class="sd">    r = S(q-z), where</span>
<span class="sd">        r: real original value</span>
<span class="sd">        q: quantized value</span>
<span class="sd">        S: scale</span>
<span class="sd">        z: zero point</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">rmin</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">rmax</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">qType</span> <span class="o">==</span> <span class="n">onnx_proto</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">INT8</span><span class="p">:</span>
        <span class="n">max_range</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">rmin</span><span class="p">),</span> <span class="nb">abs</span><span class="p">(</span><span class="n">rmax</span><span class="p">))</span>
        <span class="n">scale</span> <span class="o">=</span> <span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">max_range</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="n">quantize_range</span>
        <span class="n">zero_point</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="c1"># signed byte type</span>
        <span class="n">quantized_data</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">/</span> <span class="n">scale</span><span class="p">)</span><span class="o">.</span><span class="n">round</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;b&quot;</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">qType</span> <span class="o">==</span> <span class="n">onnx_proto</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">UINT8</span><span class="p">:</span>
        <span class="c1"># Original ORT Code:</span>
        <span class="c1"># scale = (float(rmax) - rmin) / quantize_range if rmin != rmax else 1</span>
        <span class="c1"># zero_point = round((0 - rmin) / scale)  # round to nearest integer</span>
        <span class="c1"># Modifications for compatibility with NMIE</span>
        <span class="n">max_range</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">rmin</span><span class="p">),</span> <span class="nb">abs</span><span class="p">(</span><span class="n">rmax</span><span class="p">))</span>
        <span class="n">scale</span> <span class="o">=</span> <span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">max_range</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="n">quantize_range</span>
        <span class="n">zero_point</span> <span class="o">=</span> <span class="mi">128</span>
        <span class="n">quantized_data</span> <span class="o">=</span> <span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">/</span> <span class="n">scale</span><span class="p">)</span><span class="o">.</span><span class="n">round</span><span class="p">()</span> <span class="o">+</span> <span class="n">zero_point</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span>
            <span class="s2">&quot;B&quot;</span>
        <span class="p">)</span>  <span class="c1"># unsigned byte type</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;Unexpected data type </span><span class="si">{}</span><span class="s2"> requested. Only INT8 and UINT8 are supported.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">qType</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="k">return</span> <span class="n">rmin</span><span class="p">,</span> <span class="n">rmax</span><span class="p">,</span> <span class="n">zero_point</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">quantized_data</span></div>


<span class="k">def</span> <span class="nf">_attribute_to_kwarg</span><span class="p">(</span><span class="n">attribute</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert attribute to kwarg format for use with onnx.helper.make_node.</span>
<span class="sd">        :parameter attribute: attribute in AttributeProto format.</span>
<span class="sd">        :return: attribute in {key: value} format.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">attribute</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;attribute </span><span class="si">{}</span><span class="s2"> does not have type specified.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">attribute</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="c1"># Based on attribute type definitions from AttributeProto</span>
    <span class="c1"># definition in https://github.com/onnx/onnx/blob/master/onnx/onnx.proto</span>
    <span class="k">if</span> <span class="n">attribute</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">value</span> <span class="o">=</span> <span class="n">attribute</span><span class="o">.</span><span class="n">f</span>
    <span class="k">elif</span> <span class="n">attribute</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">value</span> <span class="o">=</span> <span class="n">attribute</span><span class="o">.</span><span class="n">i</span>
    <span class="k">elif</span> <span class="n">attribute</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
        <span class="n">value</span> <span class="o">=</span> <span class="n">attribute</span><span class="o">.</span><span class="n">s</span>
    <span class="k">elif</span> <span class="n">attribute</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
        <span class="n">value</span> <span class="o">=</span> <span class="n">attribute</span><span class="o">.</span><span class="n">t</span>
    <span class="k">elif</span> <span class="n">attribute</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="mi">5</span><span class="p">:</span>
        <span class="n">value</span> <span class="o">=</span> <span class="n">attribute</span><span class="o">.</span><span class="n">g</span>
    <span class="k">elif</span> <span class="n">attribute</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="mi">6</span><span class="p">:</span>
        <span class="n">value</span> <span class="o">=</span> <span class="n">attribute</span><span class="o">.</span><span class="n">floats</span>
    <span class="k">elif</span> <span class="n">attribute</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="mi">7</span><span class="p">:</span>
        <span class="n">value</span> <span class="o">=</span> <span class="n">attribute</span><span class="o">.</span><span class="n">ints</span>
    <span class="k">elif</span> <span class="n">attribute</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="mi">8</span><span class="p">:</span>
        <span class="n">value</span> <span class="o">=</span> <span class="n">attribute</span><span class="o">.</span><span class="n">strings</span>
    <span class="k">elif</span> <span class="n">attribute</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="mi">9</span><span class="p">:</span>
        <span class="n">value</span> <span class="o">=</span> <span class="n">attribute</span><span class="o">.</span><span class="n">tensors</span>
    <span class="k">elif</span> <span class="n">attribute</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="mi">10</span><span class="p">:</span>
        <span class="n">value</span> <span class="o">=</span> <span class="n">attribute</span><span class="o">.</span><span class="n">graphs</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;attribute </span><span class="si">{}</span><span class="s2"> has unsupported type </span><span class="si">{}</span><span class="s2">.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">attribute</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">attribute</span><span class="o">.</span><span class="n">type</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="k">return</span> <span class="p">{</span><span class="n">attribute</span><span class="o">.</span><span class="n">name</span><span class="p">:</span> <span class="n">value</span><span class="p">}</span>


<span class="k">def</span> <span class="nf">_find_by_name</span><span class="p">(</span><span class="n">item_name</span><span class="p">,</span> <span class="n">item_list</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Helper function to find item by name in a list.</span>
<span class="sd">        parameter item_name: name of the item.</span>
<span class="sd">        parameter item_list: list of items.</span>
<span class="sd">        return: item if found. None otherwise.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">items</span> <span class="o">=</span> <span class="p">[</span><span class="n">item</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">item_list</span> <span class="k">if</span> <span class="n">item</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="n">item_name</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">items</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">items</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="kc">None</span>


<span class="k">def</span> <span class="nf">_get_mul_node</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Helper function to create a Mul node.</span>
<span class="sd">        parameter inputs: list of input names.</span>
<span class="sd">        parameter output: output name.</span>
<span class="sd">        parameter name: name of the node.</span>
<span class="sd">        return: Mul node in NodeProto format.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;Mul&quot;</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="p">[</span><span class="n">output</span><span class="p">],</span> <span class="n">name</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_find_node_by_name</span><span class="p">(</span><span class="n">node_name</span><span class="p">,</span> <span class="n">graph</span><span class="p">,</span> <span class="n">new_nodes_list</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Helper function to check if a node exists in a graph or</span>
<span class="sd">    new set of nodes created during quantization.</span>
<span class="sd">        parameter node_name: name of the node.</span>
<span class="sd">        parameter graph: GraphProto.</span>
<span class="sd">        parameter new_nodes_list: list of nodes added during quantization.</span>
<span class="sd">        return: NodeProto if found. None otherwise.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">graph_nodes_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">graph</span><span class="o">.</span><span class="n">node</span><span class="p">)</span>  <span class="c1"># deep copy</span>
    <span class="n">graph_nodes_list</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">new_nodes_list</span><span class="p">)</span>
    <span class="n">node</span> <span class="o">=</span> <span class="n">_find_by_name</span><span class="p">(</span><span class="n">node_name</span><span class="p">,</span> <span class="n">graph_nodes_list</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">node</span>


<span class="k">def</span> <span class="nf">_add_initializer_if_not_present</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="nb">type</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Helper function to add an initializer if it is not present in the graph.</span>
<span class="sd">        parameter graph: GraphProto.</span>
<span class="sd">        parameter name: Initializer&#39;s name.</span>
<span class="sd">        parameter value: Initializer&#39;s value.</span>
<span class="sd">        parameter shape: Initializer&#39;s shape.</span>
<span class="sd">        parameter type: Initializer&#39;s type.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">_find_by_name</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">graph</span><span class="o">.</span><span class="n">initializer</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">initializer</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_tensor</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="nb">type</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
        <span class="n">graph</span><span class="o">.</span><span class="n">initializer</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="n">initializer</span><span class="p">])</span>


<span class="k">def</span> <span class="nf">_get_qrange_for_qType</span><span class="p">(</span><span class="n">qType</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Helper function to get the quantization range for a type.</span>
<span class="sd">        parameter qType: quantization type.</span>
<span class="sd">        return: quantization range.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">qType</span> <span class="o">==</span> <span class="n">onnx_proto</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">UINT8</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">255</span>  <span class="c1"># 2^b - 1</span>
    <span class="k">elif</span> <span class="n">qType</span> <span class="o">==</span> <span class="n">onnx_proto</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">INT8</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">254</span>  <span class="c1"># [-(2^{b-1}-1), 2^{b-1}-1]: [-127, 127] for 8 bits.</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;unsupported quantization data type&quot;</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_find_nodes_using_initializer</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span> <span class="n">initializer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Helper function to find all nodes with an initializer as a input.</span>
<span class="sd">        parameter graph: GraphProto.</span>
<span class="sd">        parameter initializer: Initializer in TensorProto format.</span>
<span class="sd">        return: List of nodes.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">result</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">graph</span><span class="o">.</span><span class="n">node</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">node_input</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">node_input</span> <span class="o">==</span> <span class="n">initializer</span><span class="o">.</span><span class="n">name</span><span class="p">:</span>
                <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">result</span>


<div class="viewcode-block" id="ONNXQuantizer"><a class="viewcode-back" href="../../../../../api/sparseml.onnx.optim.quantization.html#sparseml.onnx.optim.quantization.quantize.ONNXQuantizer">[docs]</a><span class="k">class</span> <span class="nc">ONNXQuantizer</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">,</span>
        <span class="n">per_channel</span><span class="p">,</span>
        <span class="n">mode</span><span class="p">,</span>
        <span class="n">static</span><span class="p">,</span>
        <span class="n">fuse_dynamic_quant</span><span class="p">,</span>
        <span class="n">weight_qType</span><span class="p">,</span>
        <span class="n">input_qType</span><span class="p">,</span>
        <span class="n">quantization_params</span><span class="p">,</span>
        <span class="n">nodes_to_quantize</span><span class="p">,</span>
        <span class="n">nodes_to_exclude</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">shape_inference</span><span class="o">.</span><span class="n">infer_shapes</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">value_infos</span> <span class="o">=</span> <span class="p">{</span><span class="n">vi</span><span class="o">.</span><span class="n">name</span><span class="p">:</span> <span class="n">vi</span> <span class="k">for</span> <span class="n">vi</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">value_info</span><span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">per_channel</span> <span class="o">=</span> <span class="n">per_channel</span>  <span class="c1"># weight-pack per channel</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="n">mode</span>  <span class="c1"># QuantizationMode.Value</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">static</span> <span class="o">=</span> <span class="n">static</span>  <span class="c1"># use static quantization for inputs.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fuse_dynamic_quant</span> <span class="o">=</span> <span class="n">fuse_dynamic_quant</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_qType</span> <span class="o">=</span> <span class="n">input_qType</span>  <span class="c1"># quantize input type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight_qType</span> <span class="o">=</span> <span class="n">weight_qType</span>  <span class="c1"># quantize data type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">quantization_params</span> <span class="o">=</span> <span class="n">quantization_params</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nodes_to_quantize</span> <span class="o">=</span> <span class="n">nodes_to_quantize</span>  <span class="c1"># specific nodes to quantize</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nodes_to_exclude</span> <span class="o">=</span> <span class="n">nodes_to_exclude</span>  <span class="c1"># specific nodes to exclude</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="ow">in</span> <span class="n">quantization_modes</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;unsupported quantization mode </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mode</span><span class="p">))</span>

        <span class="c1"># QuantizeRange tensor name and zero tensor name for scale and zero point calculation.</span>
        <span class="c1"># Used when static is False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fixed_qrange_uint8_name</span> <span class="o">=</span> <span class="s2">&quot;fixed_quantization_range_uint8&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fixed_qrange_int8_name</span> <span class="o">=</span> <span class="s2">&quot;fixed_quantization_range_int8&quot;</span>
        <span class="c1"># For uint8 data-type, to compute zero point, we subtract rmin from 0 (represented by fixed_zero_name tensor)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fixed_zero_name</span> <span class="o">=</span> <span class="s2">&quot;fixed_zero&quot;</span>
        <span class="c1"># For int8 data-type, zero point is always zero (respresented by fixed_zero_point_name tensor)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fixed_zero_zp_name</span> <span class="o">=</span> <span class="s2">&quot;fixed_zero_zp&quot;</span>

        <span class="c1"># List of quantized weights</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_quantized_weights</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="c1"># Map of all original value names to quantized value names</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">quantized_value_map</span> <span class="o">=</span> <span class="p">{}</span>

<div class="viewcode-block" id="ONNXQuantizer.quantize_model"><a class="viewcode-back" href="../../../../../api/sparseml.onnx.optim.quantization.html#sparseml.onnx.optim.quantization.quantize.ONNXQuantizer.quantize_model">[docs]</a>    <span class="k">def</span> <span class="nf">quantize_model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Create a new topologically sorted list for quantizing a model</span>
        <span class="n">new_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">node</span><span class="p">:</span>
            <span class="c1"># if a list of ops to be quantized is provided then only quantize those ops</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">nodes_to_quantize</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                <span class="ow">and</span> <span class="n">node</span><span class="o">.</span><span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">nodes_to_quantize</span>
            <span class="p">):</span>
                <span class="n">new_list</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_handle_other_ops</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">new_list</span><span class="p">)</span>
            <span class="k">elif</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">nodes_to_exclude</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">node</span><span class="o">.</span><span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">nodes_to_exclude</span>
            <span class="p">):</span>
                <span class="n">new_list</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_handle_other_ops</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">new_list</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;Conv&quot;</span><span class="p">:</span>
                    <span class="n">new_list</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_quantize_convolution</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">new_list</span><span class="p">)</span>
                <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;MatMul&quot;</span><span class="p">:</span>
                    <span class="n">new_list</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_quantize_matmul</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">new_list</span><span class="p">)</span>
                <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;Gather&quot;</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_valid_quantize_value</span><span class="p">(</span>
                    <span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="p">):</span>
                    <span class="n">new_list</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_quantize_gather_ops</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">new_list</span><span class="p">)</span>
                <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;Add&quot;</span> <span class="ow">or</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;Mul&quot;</span><span class="p">:</span>
                    <span class="n">new_list</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_quantize_binary_math_ops</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">new_list</span><span class="p">)</span>
                <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;Relu&quot;</span> <span class="ow">or</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;Clip&quot;</span><span class="p">:</span>
                    <span class="n">new_list</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_handle_activation_ops</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">new_list</span><span class="p">)</span>
                <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;Attention&quot;</span><span class="p">:</span>
                    <span class="n">new_list</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_quantize_attention</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">new_list</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">new_list</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_handle_other_ops</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">new_list</span><span class="p">)</span>

        <span class="n">new_list</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dequantize_outputs</span><span class="p">(</span><span class="n">new_list</span><span class="p">)</span>

        <span class="c1"># extend is used to append to the list for a protobuf fields</span>
        <span class="c1"># https://developers.google.com/protocol-buffers/docs/reference/python-generated?csw=1#fields</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">ClearField</span><span class="p">(</span><span class="s2">&quot;node&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">node</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">new_list</span><span class="p">)</span>

        <span class="c1"># Remove weights which are already quantized from graph.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_remove_quantized_weights</span><span class="p">()</span>

        <span class="c1"># update opset.</span>
        <span class="n">opset_info</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span>
            <span class="p">(</span>
                <span class="n">opset</span>
                <span class="k">for</span> <span class="n">opset</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">opset_import</span>
                <span class="k">if</span> <span class="n">opset</span><span class="o">.</span><span class="n">domain</span> <span class="o">==</span> <span class="s2">&quot;&quot;</span> <span class="ow">or</span> <span class="n">opset</span><span class="o">.</span><span class="n">domain</span> <span class="o">==</span> <span class="n">onnx_domain</span>
            <span class="p">),</span>
            <span class="kc">None</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">opset_info</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">opset_import</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">opset_info</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">opset_import</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span>
            <span class="p">[</span><span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_opsetid</span><span class="p">(</span><span class="n">onnx_domain</span><span class="p">,</span> <span class="n">onnx_op_set_version</span><span class="p">)]</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span></div>

<div class="viewcode-block" id="ONNXQuantizer.find_weight_data"><a class="viewcode-back" href="../../../../../api/sparseml.onnx.optim.quantization.html#sparseml.onnx.optim.quantization.quantize.ONNXQuantizer.find_weight_data">[docs]</a>    <span class="k">def</span> <span class="nf">find_weight_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">initializer</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :param initializer: TensorProto initializer object from a graph</span>
<span class="sd">        :return: a list of initialized data in a given initializer object</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">initializer</span><span class="o">.</span><span class="n">data_type</span> <span class="o">==</span> <span class="n">onnx_proto</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">:</span>
            <span class="n">weights</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">numpy_helper</span><span class="o">.</span><span class="n">to_array</span><span class="p">(</span><span class="n">initializer</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Only float type quantization is supported. Weights </span><span class="si">{}</span><span class="s2"> is </span><span class="si">{}</span><span class="s2">. &quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">initializer</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">type_to_name</span><span class="p">[</span><span class="n">initializer</span><span class="o">.</span><span class="n">data_type</span><span class="p">]</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">weights</span></div>

    <span class="k">def</span> <span class="nf">_is_valid_quantize_value</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value_name</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">value_name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">value_infos</span><span class="p">:</span>
            <span class="n">value_info</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">value_infos</span><span class="p">[</span><span class="n">value_name</span><span class="p">]</span>
            <span class="k">return</span> <span class="p">(</span>
                <span class="n">value_info</span><span class="o">.</span><span class="n">type</span><span class="o">.</span><span class="n">HasField</span><span class="p">(</span><span class="s2">&quot;tensor_type&quot;</span><span class="p">)</span>
                <span class="ow">and</span> <span class="n">value_info</span><span class="o">.</span><span class="n">type</span><span class="o">.</span><span class="n">tensor_type</span><span class="o">.</span><span class="n">elem_type</span>
                <span class="o">==</span> <span class="n">onnx_proto</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span>
            <span class="p">)</span>
        <span class="n">weight</span> <span class="o">=</span> <span class="n">_find_by_name</span><span class="p">(</span><span class="n">value_name</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">initializer</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">weight</span><span class="o">.</span><span class="n">data_type</span> <span class="o">==</span> <span class="n">onnx_proto</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span>

    <span class="k">def</span> <span class="nf">_remove_quantized_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Remove the weights which are already quantized from graph initializer list.</span>
<span class="sd">        This function assumes that after quantization, all nodes that previously use a weight:</span>
<span class="sd">            - use output from DequantizeLinear as input if they do not support quantization.</span>
<span class="sd">            - use quantized weight if they support quantization.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">weight</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_quantized_weights</span><span class="p">:</span>
            <span class="c1"># Remove existing weight initializer</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">initializer</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">weight</span><span class="o">.</span><span class="n">initializer</span><span class="p">)</span>

            <span class="c1"># Removing input weight to a convolution</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">weight_input</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span>
                    <span class="n">val</span> <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">input</span> <span class="k">if</span> <span class="n">val</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="n">weight</span><span class="o">.</span><span class="n">name</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">input</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">weight_input</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">StopIteration</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">ir_version</span> <span class="o">&lt;</span> <span class="mi">4</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span>
                        <span class="s2">&quot;Warning: invalid weight name </span><span class="si">{}</span><span class="s2"> found in the graph (not a graph input)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                            <span class="n">weight</span><span class="o">.</span><span class="n">name</span>
                        <span class="p">)</span>
                    <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_update_graph</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Given a weight object, update the graph by doing the following:</span>
<span class="sd">         - remove old initializer, update new initializers for quantized weight, zero point, and scale</span>
<span class="sd">         - remove old weight input, update with new inputs for quantized weight, zero point, and scale</span>
<span class="sd">        This function does NOT update the nodes in the graph, just initializers and inputs</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">quantized_value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">quantized_value_map</span><span class="p">[</span><span class="n">weight</span><span class="o">.</span><span class="n">name</span><span class="p">]</span>
        <span class="k">assert</span> <span class="n">quantized_value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="n">packed_weight_name</span> <span class="o">=</span> <span class="n">quantized_value</span><span class="o">.</span><span class="n">q_name</span>
        <span class="n">scale_name</span> <span class="o">=</span> <span class="n">quantized_value</span><span class="o">.</span><span class="n">scale_name</span>
        <span class="n">zero_point_name</span> <span class="o">=</span> <span class="n">quantized_value</span><span class="o">.</span><span class="n">zp_name</span>

        <span class="c1"># Update packed weight, zero point, and scale initializers</span>
        <span class="n">packed_weight_np_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span>
            <span class="n">weight</span><span class="o">.</span><span class="n">quantized_data</span><span class="p">,</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">onnx</span><span class="o">.</span><span class="n">mapping</span><span class="o">.</span><span class="n">TENSOR_TYPE_TO_NP_TYPE</span><span class="p">[</span><span class="n">weight</span><span class="o">.</span><span class="n">qType</span><span class="p">],</span>
        <span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">weight</span><span class="o">.</span><span class="n">initializer</span><span class="o">.</span><span class="n">dims</span><span class="p">)</span>
        <span class="n">packed_weight_initializer</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">numpy_helper</span><span class="o">.</span><span class="n">from_array</span><span class="p">(</span>
            <span class="n">packed_weight_np_data</span><span class="p">,</span> <span class="n">packed_weight_name</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">weight</span><span class="o">.</span><span class="n">axis</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">zero_scale_shape</span> <span class="o">=</span> <span class="p">[</span><span class="n">weight</span><span class="o">.</span><span class="n">initializer</span><span class="o">.</span><span class="n">dims</span><span class="p">[</span><span class="n">weight</span><span class="o">.</span><span class="n">axis</span><span class="p">]]</span>
        <span class="k">else</span><span class="p">:</span>  <span class="c1"># scale and zero point must be scalar</span>
            <span class="n">zero_scale_shape</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">zero_point_type</span> <span class="o">=</span> <span class="n">weight</span><span class="o">.</span><span class="n">qType</span>
        <span class="n">scale_initializer</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_tensor</span><span class="p">(</span>
            <span class="n">scale_name</span><span class="p">,</span> <span class="n">onnx_proto</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span> <span class="n">zero_scale_shape</span><span class="p">,</span> <span class="n">weight</span><span class="o">.</span><span class="n">scales</span>
        <span class="p">)</span>
        <span class="n">zero_initializer</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_tensor</span><span class="p">(</span>
            <span class="n">zero_point_name</span><span class="p">,</span> <span class="n">zero_point_type</span><span class="p">,</span> <span class="n">zero_scale_shape</span><span class="p">,</span> <span class="n">weight</span><span class="o">.</span><span class="n">zero_points</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">initializer</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span>
            <span class="p">[</span><span class="n">packed_weight_initializer</span><span class="p">,</span> <span class="n">scale_initializer</span><span class="p">,</span> <span class="n">zero_initializer</span><span class="p">]</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_quantized_weights</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">weight</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_get_quantized_weight</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">initializer</span><span class="p">,</span> <span class="n">qType</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :param initializer: TensorProto initializer</span>
<span class="sd">        :param qType: type to quantize to</span>
<span class="sd">        :return: Weight class with quantization information</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">weights_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">find_weight_data</span><span class="p">(</span><span class="n">initializer</span><span class="p">)</span>
        <span class="n">rmin</span><span class="p">,</span> <span class="n">rmax</span><span class="p">,</span> <span class="n">zero_point</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">quantized_weights_data</span> <span class="o">=</span> <span class="n">quantize_data</span><span class="p">(</span>
            <span class="n">weights_data</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span> <span class="n">_get_qrange_for_qType</span><span class="p">(</span><span class="n">qType</span><span class="p">),</span> <span class="n">qType</span>
        <span class="p">)</span>
        <span class="n">weight</span> <span class="o">=</span> <span class="n">QuantizedInitializer</span><span class="p">(</span>
            <span class="n">initializer</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
            <span class="n">initializer</span><span class="p">,</span>
            <span class="p">[</span><span class="n">rmin</span><span class="p">],</span>
            <span class="p">[</span><span class="n">rmax</span><span class="p">],</span>
            <span class="p">[</span><span class="n">zero_point</span><span class="p">],</span>
            <span class="p">[</span><span class="n">scale</span><span class="p">],</span>
            <span class="n">weights_data</span><span class="p">,</span>
            <span class="n">quantized_weights_data</span><span class="p">,</span>
            <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">qType</span><span class="o">=</span><span class="n">qType</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Log entry for this quantized weight</span>
        <span class="k">assert</span> <span class="n">weight</span><span class="o">.</span><span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">quantized_value_map</span>
        <span class="n">quantized_value</span> <span class="o">=</span> <span class="n">QuantizedValue</span><span class="p">(</span>
            <span class="n">weight</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
            <span class="n">weight</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s2">&quot;_quantized&quot;</span><span class="p">,</span>
            <span class="n">weight</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s2">&quot;_scale&quot;</span><span class="p">,</span>
            <span class="n">weight</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s2">&quot;_zero_point&quot;</span><span class="p">,</span>
            <span class="n">QuantizedValueType</span><span class="o">.</span><span class="n">Initializer</span><span class="p">,</span>
            <span class="kc">None</span><span class="p">,</span>
            <span class="n">qType</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">quantized_value_map</span><span class="p">[</span><span class="n">weight</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">quantized_value</span>

        <span class="k">return</span> <span class="n">weight</span>

    <span class="k">def</span> <span class="nf">_get_quantized_weight_convolution</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">initializer</span><span class="p">,</span> <span class="n">qType</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :param initializer: initializer TypeProto to quantize</span>
<span class="sd">        :param qType: type to quantize to</span>
<span class="sd">        :return: Weight class object with quantization information for a given initializer</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">per_channel</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_quantized_weight</span><span class="p">(</span><span class="n">initializer</span><span class="p">,</span> <span class="n">qType</span><span class="p">)</span>

        <span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">find_weight_data</span><span class="p">(</span><span class="n">initializer</span><span class="p">)</span>
        <span class="c1"># Quantize per output channel</span>
        <span class="c1"># Assuming (M x C/group x kH x kW) format where M is number of output channels.</span>
        <span class="n">channel_count</span> <span class="o">=</span> <span class="n">initializer</span><span class="o">.</span><span class="n">dims</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">np_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">initializer</span><span class="o">.</span><span class="n">dims</span><span class="p">)</span>
        <span class="n">rmin_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">rmax_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">zero_point_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">scale_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">quantized_per_channel_data_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">channel_count</span><span class="p">):</span>
            <span class="c1"># for each channel, compute quantization data. Assuming (M x C/group x kH x kW)</span>
            <span class="n">per_channel_data</span> <span class="o">=</span> <span class="n">np_data</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:]</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
            <span class="n">rmin</span><span class="p">,</span> <span class="n">rmax</span><span class="p">,</span> <span class="n">zero_point</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">quantized_per_channel_data</span> <span class="o">=</span> <span class="n">quantize_data</span><span class="p">(</span>
                <span class="n">per_channel_data</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span> <span class="n">_get_qrange_for_qType</span><span class="p">(</span><span class="n">qType</span><span class="p">),</span> <span class="n">qType</span>
            <span class="p">)</span>
            <span class="n">rmin_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rmin</span><span class="p">)</span>
            <span class="n">rmax_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rmax</span><span class="p">)</span>
            <span class="n">zero_point_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">zero_point</span><span class="p">)</span>
            <span class="n">scale_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">scale</span><span class="p">)</span>
            <span class="n">quantized_per_channel_data_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">quantized_per_channel_data</span><span class="p">)</span>
        <span class="n">channel_index</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># (M x C/group x kH x kW)</span>
        <span class="c1"># combine per_channel_data into one</span>
        <span class="n">reshape_dims</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">initializer</span><span class="o">.</span><span class="n">dims</span><span class="p">)</span>  <span class="c1"># deep copy</span>
        <span class="n">reshape_dims</span><span class="p">[</span><span class="n">channel_index</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># only one per channel for reshape</span>
        <span class="n">quantized_weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">quantized_per_channel_data_list</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
            <span class="n">reshape_dims</span>
        <span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">quantized_per_channel_data_list</span><span class="p">)):</span>
            <span class="n">channel_weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">quantized_per_channel_data_list</span><span class="p">[</span><span class="n">i</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
                <span class="n">reshape_dims</span>
            <span class="p">)</span>
            <span class="n">quantized_weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span>
                <span class="p">(</span><span class="n">quantized_weights</span><span class="p">,</span> <span class="n">channel_weights</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span>
            <span class="p">)</span>

        <span class="n">weight</span> <span class="o">=</span> <span class="n">QuantizedInitializer</span><span class="p">(</span>
            <span class="n">initializer</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
            <span class="n">initializer</span><span class="p">,</span>
            <span class="n">rmin_list</span><span class="p">,</span>
            <span class="n">rmax_list</span><span class="p">,</span>
            <span class="n">zero_point_list</span><span class="p">,</span>
            <span class="n">scale_list</span><span class="p">,</span>
            <span class="n">weights</span><span class="p">,</span>
            <span class="n">quantized_weights</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span>
            <span class="n">channel_index</span><span class="p">,</span>
            <span class="n">qType</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Make entry for this quantized weight</span>
        <span class="k">assert</span> <span class="n">weight</span><span class="o">.</span><span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">quantized_value_map</span>
        <span class="n">quantized_value</span> <span class="o">=</span> <span class="n">QuantizedValue</span><span class="p">(</span>
            <span class="n">weight</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
            <span class="n">weight</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s2">&quot;_quantized&quot;</span><span class="p">,</span>
            <span class="n">weight</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s2">&quot;_scale&quot;</span><span class="p">,</span>
            <span class="n">weight</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s2">&quot;_zero_point&quot;</span><span class="p">,</span>
            <span class="n">QuantizedValueType</span><span class="o">.</span><span class="n">Initializer</span><span class="p">,</span>
            <span class="kc">None</span><span class="p">,</span>
            <span class="n">qType</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">quantized_value_map</span><span class="p">[</span><span class="n">weight</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">quantized_value</span>

        <span class="k">return</span> <span class="n">weight</span>

    <span class="k">def</span> <span class="nf">_get_dynamic_input_quantization_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">nodes_list</span><span class="p">,</span> <span class="n">qType</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create nodes for dynamic quantization of input and add them to nodes_list.</span>
<span class="sd">            parameter input_name: Name of the input.</span>
<span class="sd">            parameter nodes_list: new nodes are appended to this list.</span>
<span class="sd">            parameter qType: type to quantize to.</span>
<span class="sd">            return: scale_name, zero_point_name, scale_shape, zero_point_shape.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">qType</span> <span class="o">==</span> <span class="n">onnx_proto</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">INT8</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_dynamic_input_quantization_params_int8</span><span class="p">(</span>
                <span class="n">input_name</span><span class="p">,</span> <span class="n">nodes_list</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_dynamic_input_quantization_params_uint8</span><span class="p">(</span><span class="n">input_name</span><span class="p">,</span> <span class="n">nodes_list</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_get_dynamic_input_quantization_params_int8</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">nodes_list</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create nodes for dynamic quantization of input to int8 and add them to nodes_list</span>
<span class="sd">            parameter input_name: Name of the input.</span>
<span class="sd">            parameter nodes_list: new nodes are appended to this list.</span>
<span class="sd">            return: scale_name, zero_point_name, scale_shape, zero_point_shape.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">qType</span> <span class="o">=</span> <span class="n">onnx_proto</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">INT8</span>

        <span class="c1"># Reduce min and Reduce max</span>
        <span class="n">input_scale_name</span> <span class="o">=</span> <span class="n">input_name</span> <span class="o">+</span> <span class="s2">&quot;_scale&quot;</span>

        <span class="n">reduce_min_name</span> <span class="o">=</span> <span class="n">input_name</span> <span class="o">+</span> <span class="s2">&quot;_ReduceMin&quot;</span>
        <span class="n">reduce_min_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
            <span class="s2">&quot;ReduceMin&quot;</span><span class="p">,</span>
            <span class="p">[</span><span class="n">input_name</span><span class="p">],</span>
            <span class="p">[</span><span class="n">reduce_min_name</span> <span class="o">+</span> <span class="s2">&quot;:0&quot;</span><span class="p">],</span>
            <span class="n">reduce_min_name</span><span class="p">,</span>
            <span class="n">keepdims</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">nodes_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">reduce_min_node</span><span class="p">)</span>

        <span class="n">reduce_max_name</span> <span class="o">=</span> <span class="n">input_name</span> <span class="o">+</span> <span class="s2">&quot;_ReduceMax&quot;</span>
        <span class="n">reduce_max_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
            <span class="s2">&quot;ReduceMax&quot;</span><span class="p">,</span>
            <span class="p">[</span><span class="n">input_name</span><span class="p">],</span>
            <span class="p">[</span><span class="n">reduce_max_name</span> <span class="o">+</span> <span class="s2">&quot;:0&quot;</span><span class="p">],</span>
            <span class="n">reduce_max_name</span><span class="p">,</span>
            <span class="n">keepdims</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">nodes_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">reduce_max_node</span><span class="p">)</span>

        <span class="c1"># Compute scale</span>
        <span class="c1">#   Find abs(rmin)</span>
        <span class="n">reduce_min_abs_name</span> <span class="o">=</span> <span class="n">reduce_min_name</span> <span class="o">+</span> <span class="s2">&quot;_Abs&quot;</span>
        <span class="n">reduce_min_abs_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
            <span class="s2">&quot;Abs&quot;</span><span class="p">,</span>
            <span class="p">[</span><span class="n">reduce_min_node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span>
            <span class="p">[</span><span class="n">reduce_min_abs_name</span> <span class="o">+</span> <span class="s2">&quot;:0&quot;</span><span class="p">],</span>
            <span class="n">reduce_min_abs_name</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">nodes_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">reduce_min_abs_node</span><span class="p">)</span>
        <span class="c1">#   Find abs(rmax)</span>
        <span class="n">reduce_max_abs_name</span> <span class="o">=</span> <span class="n">reduce_max_name</span> <span class="o">+</span> <span class="s2">&quot;_Abs&quot;</span>
        <span class="n">reduce_max_abs_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
            <span class="s2">&quot;Abs&quot;</span><span class="p">,</span>
            <span class="p">[</span><span class="n">reduce_max_node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span>
            <span class="p">[</span><span class="n">reduce_max_abs_name</span> <span class="o">+</span> <span class="s2">&quot;:0&quot;</span><span class="p">],</span>
            <span class="n">reduce_max_abs_name</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">nodes_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">reduce_max_abs_node</span><span class="p">)</span>
        <span class="c1">#   Compute max of abs(rmin) and abs(rmax)</span>
        <span class="n">abs_max_name</span> <span class="o">=</span> <span class="n">input_name</span> <span class="o">+</span> <span class="s2">&quot;_Abs_Max&quot;</span>
        <span class="n">abs_max_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
            <span class="s2">&quot;Max&quot;</span><span class="p">,</span>
            <span class="p">[</span><span class="n">reduce_min_abs_node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">reduce_max_abs_node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span>
            <span class="p">[</span><span class="n">abs_max_name</span> <span class="o">+</span> <span class="s2">&quot;:0&quot;</span><span class="p">],</span>
            <span class="n">abs_max_name</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">nodes_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">abs_max_node</span><span class="p">)</span>
        <span class="c1">#   and divide by (quantize_range/2.0) which will be equal to max(...)*2.0/quantize_range</span>
        <span class="n">_add_initializer_if_not_present</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">graph</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fixed_qrange_int8_name</span><span class="p">,</span>
            <span class="p">[</span><span class="n">_get_qrange_for_qType</span><span class="p">(</span><span class="n">qType</span><span class="p">)</span> <span class="o">/</span> <span class="mf">2.0</span><span class="p">],</span>
            <span class="p">[],</span>
            <span class="n">onnx_proto</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">scale_div_name</span> <span class="o">=</span> <span class="n">input_name</span> <span class="o">+</span> <span class="s2">&quot;scale_Div&quot;</span>
        <span class="n">scale_div_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
            <span class="s2">&quot;Div&quot;</span><span class="p">,</span>
            <span class="p">[</span><span class="n">abs_max_node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">fixed_qrange_int8_name</span><span class="p">],</span>
            <span class="p">[</span><span class="n">input_scale_name</span><span class="p">],</span>
            <span class="n">scale_div_name</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">nodes_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">scale_div_node</span><span class="p">)</span>

        <span class="c1"># Zero point</span>
        <span class="n">_add_initializer_if_not_present</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">graph</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">fixed_zero_zp_name</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[],</span> <span class="n">qType</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">input_scale_name</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">fixed_zero_zp_name</span><span class="p">,</span> <span class="p">[],</span> <span class="p">[]</span>

    <span class="k">def</span> <span class="nf">_get_dynamic_input_quantization_params_uint8</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">nodes_list</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create nodes for dynamic quantization of input to uint8 and add them to nodes_list</span>
<span class="sd">            parameter input_name: Name of the input.</span>
<span class="sd">            parameter nodes_list: new nodes are appended to this list.</span>
<span class="sd">            return: scale_name, zero_point_name, scale_shape, zero_point_shape.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">qType</span> <span class="o">=</span> <span class="n">onnx_proto</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">UINT8</span>
        <span class="c1"># Reduce min and Reduce max</span>
        <span class="n">input_scale_name</span> <span class="o">=</span> <span class="n">input_name</span> <span class="o">+</span> <span class="s2">&quot;_scale&quot;</span>
        <span class="n">input_zp_name</span> <span class="o">=</span> <span class="n">input_name</span> <span class="o">+</span> <span class="s2">&quot;_zero_point&quot;</span>

        <span class="n">reduce_min_name</span> <span class="o">=</span> <span class="n">input_name</span> <span class="o">+</span> <span class="s2">&quot;_ReduceMin&quot;</span>
        <span class="n">reduce_min_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
            <span class="s2">&quot;ReduceMin&quot;</span><span class="p">,</span>
            <span class="p">[</span><span class="n">input_name</span><span class="p">],</span>
            <span class="p">[</span><span class="n">reduce_min_name</span> <span class="o">+</span> <span class="s2">&quot;:0&quot;</span><span class="p">],</span>
            <span class="n">reduce_min_name</span><span class="p">,</span>
            <span class="n">keepdims</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">nodes_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">reduce_min_node</span><span class="p">)</span>

        <span class="n">reduce_max_name</span> <span class="o">=</span> <span class="n">input_name</span> <span class="o">+</span> <span class="s2">&quot;_ReduceMax&quot;</span>
        <span class="n">reduce_max_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
            <span class="s2">&quot;ReduceMax&quot;</span><span class="p">,</span>
            <span class="p">[</span><span class="n">input_name</span><span class="p">],</span>
            <span class="p">[</span><span class="n">reduce_max_name</span> <span class="o">+</span> <span class="s2">&quot;:0&quot;</span><span class="p">],</span>
            <span class="n">reduce_max_name</span><span class="p">,</span>
            <span class="n">keepdims</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">nodes_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">reduce_max_node</span><span class="p">)</span>

        <span class="c1"># Add tensors for quantize range and zero value.</span>
        <span class="n">_add_initializer_if_not_present</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">graph</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fixed_qrange_uint8_name</span><span class="p">,</span>
            <span class="p">[</span><span class="n">_get_qrange_for_qType</span><span class="p">(</span><span class="n">qType</span><span class="p">)],</span>
            <span class="p">[],</span>
            <span class="n">onnx_proto</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">_add_initializer_if_not_present</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">graph</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fixed_zero_name</span><span class="p">,</span>
            <span class="p">[</span><span class="mf">0.0</span><span class="p">],</span>
            <span class="p">[],</span>
            <span class="n">onnx_proto</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Compute Scale</span>
        <span class="c1">#   Subtract rmax and rmin</span>
        <span class="n">scale_sub_name</span> <span class="o">=</span> <span class="n">input_name</span> <span class="o">+</span> <span class="s2">&quot;_scale_Sub&quot;</span>
        <span class="n">scale_sub_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
            <span class="s2">&quot;Sub&quot;</span><span class="p">,</span>
            <span class="p">[</span><span class="n">reduce_max_node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">reduce_min_node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span>
            <span class="p">[</span><span class="n">scale_sub_name</span> <span class="o">+</span> <span class="s2">&quot;:0&quot;</span><span class="p">],</span>
            <span class="n">scale_sub_name</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">nodes_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">scale_sub_node</span><span class="p">)</span>
        <span class="c1">#   and divide by quantize range</span>
        <span class="n">scale_div_name</span> <span class="o">=</span> <span class="n">input_name</span> <span class="o">+</span> <span class="s2">&quot;_scale_Div&quot;</span>
        <span class="n">scale_div_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
            <span class="s2">&quot;Div&quot;</span><span class="p">,</span>
            <span class="p">[</span><span class="n">scale_sub_node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">fixed_qrange_uint8_name</span><span class="p">],</span>
            <span class="p">[</span><span class="n">input_scale_name</span><span class="p">],</span>
            <span class="n">scale_div_name</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">nodes_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">scale_div_node</span><span class="p">)</span>

        <span class="c1"># Compute zero point</span>
        <span class="c1">#   Subtract zero and rmin</span>
        <span class="n">zp_sub_name</span> <span class="o">=</span> <span class="n">input_name</span> <span class="o">+</span> <span class="s2">&quot;_zero_point_Sub&quot;</span>
        <span class="n">zp_sub_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
            <span class="s2">&quot;Sub&quot;</span><span class="p">,</span>
            <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">fixed_zero_name</span><span class="p">,</span> <span class="n">reduce_min_node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span>
            <span class="p">[</span><span class="n">zp_sub_name</span> <span class="o">+</span> <span class="s2">&quot;:0&quot;</span><span class="p">],</span>
            <span class="n">zp_sub_name</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">nodes_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">zp_sub_node</span><span class="p">)</span>
        <span class="c1">#   Divide by scale</span>
        <span class="n">zp_div_name</span> <span class="o">=</span> <span class="n">input_name</span> <span class="o">+</span> <span class="s2">&quot;_zero_point_Div&quot;</span>
        <span class="n">zp_div_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
            <span class="s2">&quot;Div&quot;</span><span class="p">,</span>
            <span class="p">[</span><span class="n">zp_sub_node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">input_scale_name</span><span class="p">],</span>
            <span class="p">[</span><span class="n">zp_div_name</span> <span class="o">+</span> <span class="s2">&quot;:0&quot;</span><span class="p">],</span>
            <span class="n">zp_div_name</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">nodes_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">zp_div_node</span><span class="p">)</span>
        <span class="c1">#   Compute floor</span>
        <span class="n">zp_floor_name</span> <span class="o">=</span> <span class="n">input_name</span> <span class="o">+</span> <span class="s2">&quot;_zero_point_Floor&quot;</span>
        <span class="n">zp_floor_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
            <span class="s2">&quot;Floor&quot;</span><span class="p">,</span> <span class="n">zp_div_node</span><span class="o">.</span><span class="n">output</span><span class="p">,</span> <span class="p">[</span><span class="n">zp_floor_name</span> <span class="o">+</span> <span class="s2">&quot;:0&quot;</span><span class="p">],</span> <span class="n">zp_floor_name</span>
        <span class="p">)</span>
        <span class="n">nodes_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">zp_floor_node</span><span class="p">)</span>
        <span class="c1">#   Cast to integer</span>
        <span class="n">zp_cast_name</span> <span class="o">=</span> <span class="n">input_name</span> <span class="o">+</span> <span class="s2">&quot;_zero_point_Cast&quot;</span>
        <span class="n">zp_cast_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
            <span class="s2">&quot;Cast&quot;</span><span class="p">,</span> <span class="n">zp_floor_node</span><span class="o">.</span><span class="n">output</span><span class="p">,</span> <span class="p">[</span><span class="n">input_zp_name</span><span class="p">],</span> <span class="n">zp_cast_name</span><span class="p">,</span> <span class="n">to</span><span class="o">=</span><span class="n">qType</span>
        <span class="p">)</span>
        <span class="n">nodes_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">zp_cast_node</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">input_scale_name</span><span class="p">,</span> <span class="n">input_zp_name</span><span class="p">,</span> <span class="p">[],</span> <span class="p">[]</span>

    <span class="k">def</span> <span class="nf">_get_quantization_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">param_name</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create initializers and inputs in the graph for zero point and scale of output.</span>
<span class="sd">        Zero point and scale values are obtained from self.quantization_params if specified.</span>
<span class="sd">            parameter param_name: Name of the quantization parameter.</span>
<span class="sd">            return: result, scale_name, zero_point_name, scale_shape, zero_point_shape.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">quantization_params</span> <span class="ow">is</span> <span class="kc">None</span>
            <span class="ow">or</span> <span class="n">param_name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">quantization_params</span>
        <span class="p">):</span>
            <span class="k">return</span> <span class="kc">False</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span>
        <span class="n">params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">quantization_params</span><span class="p">[</span><span class="n">param_name</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">params</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">params</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Quantization parameters should contain zero point and scale. &quot;</span>
                <span class="s2">&quot;Specified values for output </span><span class="si">{}</span><span class="s2">: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">param_name</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">isscalar</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Zero point for param </span><span class="si">{}</span><span class="s2"> should be a scalar value. Value specified: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">param_name</span><span class="p">,</span> <span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">isscalar</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Scale for param </span><span class="si">{}</span><span class="s2"> should be a scalar value. Value specified: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">param_name</span><span class="p">,</span> <span class="n">params</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
                <span class="p">)</span>
            <span class="p">)</span>

        <span class="n">zero_point_values</span> <span class="o">=</span> <span class="p">[</span><span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()]</span>
        <span class="n">zero_point_shape</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">zero_point_name</span> <span class="o">=</span> <span class="n">param_name</span> <span class="o">+</span> <span class="s2">&quot;_zero_point&quot;</span>
        <span class="n">zero_point_type</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">mapping</span><span class="o">.</span><span class="n">NP_TYPE_TO_TENSOR_TYPE</span><span class="p">[</span><span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span><span class="p">]</span>

        <span class="n">scale_values</span> <span class="o">=</span> <span class="p">[</span><span class="n">params</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()]</span>
        <span class="n">scale_shape</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">scale_name</span> <span class="o">=</span> <span class="n">param_name</span> <span class="o">+</span> <span class="s2">&quot;_scale&quot;</span>

        <span class="c1"># Add initializers</span>
        <span class="n">_add_initializer_if_not_present</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">graph</span><span class="p">,</span>
            <span class="n">zero_point_name</span><span class="p">,</span>
            <span class="n">zero_point_values</span><span class="p">,</span>
            <span class="n">zero_point_shape</span><span class="p">,</span>
            <span class="n">zero_point_type</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">_add_initializer_if_not_present</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">graph</span><span class="p">,</span>
            <span class="n">scale_name</span><span class="p">,</span>
            <span class="n">scale_values</span><span class="p">,</span>
            <span class="n">scale_shape</span><span class="p">,</span>
            <span class="n">onnx_proto</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="kc">True</span><span class="p">,</span> <span class="n">scale_name</span><span class="p">,</span> <span class="n">zero_point_name</span><span class="p">,</span> <span class="n">scale_shape</span><span class="p">,</span> <span class="n">zero_point_shape</span>

    <span class="k">def</span> <span class="nf">_get_quantize_input_nodes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node</span><span class="p">,</span> <span class="n">input_index</span><span class="p">,</span> <span class="n">qType</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Given a input for a node (which is not a initializer), this function</span>
<span class="sd">            - add nodes to compute zero point and scale for this input if they don&#39;t exist.</span>
<span class="sd">            - add new QuantizeLinear node to quantize the input.</span>
<span class="sd">            parameter node: node being quantized in NodeProto format.</span>
<span class="sd">            parameter input_index: index of input in node.input.</span>
<span class="sd">            parameter qType: type to quantize to.</span>
<span class="sd">            return: List of newly created nodes in NodeProto format.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">input_name</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="n">input_index</span><span class="p">]</span>
        <span class="n">output_name</span> <span class="o">=</span> <span class="n">input_name</span> <span class="o">+</span> <span class="s2">&quot;_quantized&quot;</span>

        <span class="n">data_found</span><span class="p">,</span> <span class="n">scale_name</span><span class="p">,</span> <span class="n">zp_name</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_quantization_params</span><span class="p">(</span>
            <span class="n">input_name</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">static</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">data_found</span> <span class="o">==</span> <span class="kc">False</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Quantization parameters are not specified for param </span><span class="si">{}</span><span class="s2">.&quot;</span>
                    <span class="s2">&quot;In static mode quantization params for inputs and outputs of nodes to be quantized are required.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                        <span class="n">input_name</span>
                    <span class="p">)</span>
                <span class="p">)</span>

            <span class="n">qlinear_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
                <span class="s2">&quot;QuantizeLinear&quot;</span><span class="p">,</span>
                <span class="p">[</span><span class="n">input_name</span><span class="p">,</span> <span class="n">scale_name</span><span class="p">,</span> <span class="n">zp_name</span><span class="p">],</span>
                <span class="p">[</span><span class="n">output_name</span><span class="p">],</span>
                <span class="n">input_name</span> <span class="o">+</span> <span class="s2">&quot;_QuantizeLinear&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="p">[</span><span class="n">qlinear_node</span><span class="p">]</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">data_found</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>
                <span class="n">qlinear_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
                    <span class="s2">&quot;QuantizeLinear&quot;</span><span class="p">,</span>
                    <span class="p">[</span><span class="n">input_name</span><span class="p">,</span> <span class="n">scale_name</span><span class="p">,</span> <span class="n">zp_name</span><span class="p">],</span>
                    <span class="p">[</span><span class="n">output_name</span><span class="p">],</span>
                    <span class="n">input_name</span> <span class="o">+</span> <span class="s2">&quot;_QuantizeLinear&quot;</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="k">return</span> <span class="p">[</span><span class="n">qlinear_node</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Scale and Zero Points not available for this input. Add nodes to dynamically compute it</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">fuse_dynamic_quant</span> <span class="ow">and</span> <span class="n">qType</span> <span class="o">==</span> <span class="n">onnx_proto</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">UINT8</span><span class="p">:</span>
                    <span class="n">scale_name</span> <span class="o">=</span> <span class="n">input_name</span> <span class="o">+</span> <span class="s2">&quot;_scale&quot;</span>
                    <span class="n">zeropoint_name</span> <span class="o">=</span> <span class="n">input_name</span> <span class="o">+</span> <span class="s2">&quot;_zero_point&quot;</span>
                    <span class="n">qlinear_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
                        <span class="s2">&quot;DynamicQuantizeLinear&quot;</span><span class="p">,</span>
                        <span class="p">[</span><span class="n">input_name</span><span class="p">],</span>
                        <span class="p">[</span><span class="n">output_name</span><span class="p">,</span> <span class="n">scale_name</span><span class="p">,</span> <span class="n">zeropoint_name</span><span class="p">],</span>
                        <span class="n">input_name</span> <span class="o">+</span> <span class="s2">&quot;_QuantizeLinear&quot;</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="k">return</span> <span class="p">[</span><span class="n">qlinear_node</span><span class="p">]</span>

                <span class="k">else</span><span class="p">:</span>
                    <span class="n">nodes</span> <span class="o">=</span> <span class="p">[]</span>
                    <span class="p">(</span>
                        <span class="n">scale_name</span><span class="p">,</span>
                        <span class="n">zp_name</span><span class="p">,</span>
                        <span class="n">scale_shape</span><span class="p">,</span>
                        <span class="n">zp_shape</span><span class="p">,</span>
                    <span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_dynamic_input_quantization_params</span><span class="p">(</span>
                        <span class="n">input_name</span><span class="p">,</span> <span class="n">nodes</span><span class="p">,</span> <span class="n">qType</span>
                    <span class="p">)</span>
                    <span class="n">qlinear_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
                        <span class="s2">&quot;QuantizeLinear&quot;</span><span class="p">,</span>
                        <span class="p">[</span><span class="n">input_name</span><span class="p">,</span> <span class="n">scale_name</span><span class="p">,</span> <span class="n">zp_name</span><span class="p">],</span>
                        <span class="p">[</span><span class="n">output_name</span><span class="p">],</span>
                        <span class="n">input_name</span> <span class="o">+</span> <span class="s2">&quot;_QuantizeLinear&quot;</span><span class="p">,</span>
                    <span class="p">)</span>

                    <span class="k">return</span> <span class="n">nodes</span> <span class="o">+</span> <span class="p">[</span><span class="n">qlinear_node</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">_get_bias_add_nodes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nodes</span><span class="p">,</span> <span class="n">node</span><span class="p">,</span> <span class="n">last_output</span><span class="p">,</span> <span class="n">quantized_bias_name</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Given a node, this function handles bias add by adding a &quot;reshape&quot; node on bias and an &quot;add&quot; node</span>
<span class="sd">            parameter nodes: new nodes would be appended into nodes</span>
<span class="sd">            parameter node: current node (Conv)</span>
<span class="sd">            parameter last_output: output of previous node (input to bias add)</span>
<span class="sd">            return: the name of output</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Add an Add operation for bias</span>
        <span class="c1"># Add reshape for correct broadcase</span>
        <span class="n">reshape_input</span> <span class="o">=</span> <span class="p">[</span><span class="n">quantized_bias_name</span><span class="p">]</span>

        <span class="c1"># Add tensors for the shape to be reshaped to</span>
        <span class="n">_add_initializer_if_not_present</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">graph</span><span class="p">,</span>
            <span class="s2">&quot;reshape_shape&quot;</span><span class="p">,</span>
            <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
            <span class="p">[</span><span class="mi">4</span><span class="p">],</span>
            <span class="n">onnx_proto</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">INT64</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">reshape_input</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;reshape_shape&quot;</span><span class="p">)</span>
        <span class="n">reshape_op_output</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;_reshape&quot;</span>
        <span class="n">reshape_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
            <span class="s2">&quot;Reshape&quot;</span><span class="p">,</span>
            <span class="n">reshape_input</span><span class="p">,</span>
            <span class="p">[</span><span class="n">reshape_op_output</span><span class="p">],</span>
            <span class="n">quantized_bias_name</span> <span class="o">+</span> <span class="s2">&quot;reshape&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">reshape_node</span><span class="p">)</span>

        <span class="n">bias_add_input</span> <span class="o">=</span> <span class="p">[</span><span class="n">last_output</span><span class="p">]</span>
        <span class="n">bias_add_input</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">reshape_op_output</span><span class="p">)</span>
        <span class="n">add_node_output</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;_bias_add&quot;</span>
        <span class="n">add_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
            <span class="s2">&quot;Add&quot;</span><span class="p">,</span> <span class="n">bias_add_input</span><span class="p">,</span> <span class="p">[</span><span class="n">add_node_output</span><span class="p">],</span> <span class="n">quantized_bias_name</span> <span class="o">+</span> <span class="s2">&quot;bias_add&quot;</span>
        <span class="p">)</span>
        <span class="n">nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">add_node</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">add_node_output</span>

    <span class="k">def</span> <span class="nf">_update_unsupported_nodes_using_weight</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">new_nodes_list</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Find all nodes using a weight that do not support quantization and</span>
<span class="sd">        add a DequantizeLinear node before those nodes. This includes all nodes except Conv, MatMul.</span>
<span class="sd">            parameter weight: Weight object</span>
<span class="sd">            parameter new_nodes_list: List of new nodes created before processing current node.</span>
<span class="sd">            return: List of new nodes created.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">nodes_using_weight</span> <span class="o">=</span> <span class="n">_find_nodes_using_initializer</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">graph</span><span class="p">,</span> <span class="n">weight</span><span class="o">.</span><span class="n">initializer</span>
        <span class="p">)</span>
        <span class="n">unsupported_nodes</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">node</span>
            <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">nodes_using_weight</span>
            <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;Conv&quot;</span><span class="p">,</span> <span class="s2">&quot;MatMul&quot;</span><span class="p">,</span> <span class="s2">&quot;Gather&quot;</span><span class="p">,</span> <span class="s2">&quot;Attention&quot;</span><span class="p">]</span>
        <span class="p">]</span>

        <span class="n">nodes_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">dequantize_linear_name</span> <span class="o">=</span> <span class="n">weight</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s2">&quot;_DequantizeLinear&quot;</span>
        <span class="n">output_name</span> <span class="o">=</span> <span class="n">weight</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s2">&quot;_dequantized&quot;</span>

        <span class="c1"># Check if DequantizeLinear node needs to be added to graph.</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="nb">len</span><span class="p">(</span><span class="n">unsupported_nodes</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span>
            <span class="ow">and</span> <span class="n">_find_node_by_name</span><span class="p">(</span>
                <span class="n">dequantize_linear_name</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">graph</span><span class="p">,</span> <span class="n">new_nodes_list</span>
            <span class="p">)</span>
            <span class="ow">is</span> <span class="kc">None</span>
        <span class="p">):</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">weight</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s2">&quot;_quantized&quot;</span><span class="p">,</span>
                <span class="n">weight</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s2">&quot;_scale&quot;</span><span class="p">,</span>
                <span class="n">weight</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s2">&quot;_zero_point&quot;</span><span class="p">,</span>
            <span class="p">]</span>
            <span class="n">node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
                <span class="s2">&quot;DequantizeLinear&quot;</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="p">[</span><span class="n">output_name</span><span class="p">],</span> <span class="n">dequantize_linear_name</span>
            <span class="p">)</span>
            <span class="n">nodes_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>

        <span class="c1"># Update unsupported nodes to take dequantized weight as input.</span>
        <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">unsupported_nodes</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">node_input</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">node_input</span> <span class="o">==</span> <span class="n">weight</span><span class="o">.</span><span class="n">name</span><span class="p">:</span>
                    <span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">output_name</span>

        <span class="k">return</span> <span class="n">nodes_list</span>

    <span class="k">def</span> <span class="nf">_dynamic_quantize_bias</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">input_name</span><span class="p">,</span>
        <span class="n">weight_scale_name</span><span class="p">,</span>
        <span class="n">bias_name</span><span class="p">,</span>
        <span class="n">quantized_bias_name</span><span class="p">,</span>
        <span class="n">new_node_list</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Adds series of nodes required to quantize the bias dynamically.</span>
<span class="sd">            parameter input_name: Input name</span>
<span class="sd">            parameter weight_scale_name: Weight scale.</span>
<span class="sd">            parameter bias_scale_name: Bias to quantize.</span>
<span class="sd">            parameter quantied_bias_name: Output name to use for quantized bias.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">qType</span> <span class="o">=</span> <span class="n">onnx_proto</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">INT32</span>

        <span class="n">input_scale_name</span> <span class="o">=</span> <span class="n">input_name</span> <span class="o">+</span> <span class="s2">&quot;_scale&quot;</span>
        <span class="n">bias_scale_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
            <span class="s2">&quot;Mul&quot;</span><span class="p">,</span>
            <span class="p">[</span><span class="n">input_scale_name</span><span class="p">,</span> <span class="n">weight_scale_name</span><span class="p">],</span>
            <span class="p">[</span><span class="n">bias_name</span> <span class="o">+</span> <span class="s2">&quot;_scale&quot;</span><span class="p">],</span>
            <span class="n">bias_name</span> <span class="o">+</span> <span class="s2">&quot;_scale_node&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">new_node_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bias_scale_node</span><span class="p">)</span>

        <span class="n">quantize_bias_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
            <span class="s2">&quot;Div&quot;</span><span class="p">,</span>
            <span class="p">[</span><span class="n">bias_name</span><span class="p">,</span> <span class="n">bias_scale_node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span>
            <span class="p">[</span><span class="n">bias_name</span> <span class="o">+</span> <span class="s2">&quot;_tmp_quant:0&quot;</span><span class="p">],</span>
            <span class="n">bias_name</span> <span class="o">+</span> <span class="s2">&quot;_tmp_qaunt&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">new_node_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">quantize_bias_node</span><span class="p">)</span>

        <span class="n">bias_rounded_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
            <span class="s2">&quot;Floor&quot;</span><span class="p">,</span>
            <span class="n">quantize_bias_node</span><span class="o">.</span><span class="n">output</span><span class="p">,</span>
            <span class="p">[</span><span class="n">bias_name</span> <span class="o">+</span> <span class="s2">&quot;_quant_rounded:0&quot;</span><span class="p">],</span>
            <span class="n">bias_name</span> <span class="o">+</span> <span class="s2">&quot;_quant_rounded&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">new_node_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bias_rounded_node</span><span class="p">)</span>

        <span class="n">bias_cast_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
            <span class="s2">&quot;Cast&quot;</span><span class="p">,</span>
            <span class="n">bias_rounded_node</span><span class="o">.</span><span class="n">output</span><span class="p">,</span>
            <span class="p">[</span><span class="n">quantized_bias_name</span><span class="p">],</span>
            <span class="n">quantized_bias_name</span> <span class="o">+</span> <span class="s2">&quot;_node&quot;</span><span class="p">,</span>
            <span class="n">to</span><span class="o">=</span><span class="n">qType</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">new_node_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bias_cast_node</span><span class="p">)</span>

        <span class="k">return</span>

    <span class="k">def</span> <span class="nf">_quantize_bias</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node</span><span class="p">,</span> <span class="n">new_node_list</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Quantized the bias. Zero Point == 0 and Scale == Input_Scale * Weight_Scale</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># get scale for weight</span>
        <span class="n">weight_scale_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">quantized_value_map</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span><span class="o">.</span><span class="n">scale_name</span>
        <span class="n">weight_initializer</span> <span class="o">=</span> <span class="n">_find_by_name</span><span class="p">(</span>
            <span class="n">weight_scale_name</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">initializer</span>
        <span class="p">)</span>
        <span class="n">weight_scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">find_weight_data</span><span class="p">(</span><span class="n">weight_initializer</span><span class="p">)</span>

        <span class="c1"># get bias</span>
        <span class="n">bias_name</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
        <span class="n">bias_initializer</span> <span class="o">=</span> <span class="n">_find_by_name</span><span class="p">(</span><span class="n">bias_name</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">initializer</span><span class="p">)</span>
        <span class="n">bias_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">find_weight_data</span><span class="p">(</span><span class="n">bias_initializer</span><span class="p">)</span>
        <span class="n">quantized_bias_name</span> <span class="o">=</span> <span class="n">bias_name</span> <span class="o">+</span> <span class="s2">&quot;_quantized&quot;</span>

        <span class="c1"># input scale is not provided and this input is dynamically quantized so it is not pre-computed at this point</span>
        <span class="c1"># so resort to dynamic quantization for bias</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">quantization_params</span> <span class="ow">is</span> <span class="kc">None</span>
            <span class="ow">or</span> <span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">quantization_params</span>
            <span class="ow">and</span> <span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">quantized_value_map</span>
        <span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_dynamic_quantize_bias</span><span class="p">(</span>
                <span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                <span class="n">weight_scale_name</span><span class="p">,</span>
                <span class="n">bias_name</span><span class="p">,</span>
                <span class="n">quantized_bias_name</span><span class="p">,</span>
                <span class="n">new_node_list</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># get scale for input</span>
            <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">quantized_value_map</span><span class="p">:</span>
                <span class="n">input_scale_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">quantized_value_map</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span><span class="o">.</span><span class="n">scale_name</span>
            <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">quantization_params</span><span class="p">:</span>
                <span class="n">_</span><span class="p">,</span> <span class="n">input_scale_name</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_quantization_params</span><span class="p">(</span>
                    <span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Expected </span><span class="si">{}</span><span class="s2"> to be in quantized value map for static quantization&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                        <span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                    <span class="p">)</span>
                <span class="p">)</span>

            <span class="n">inputscale_initializer</span> <span class="o">=</span> <span class="n">_find_by_name</span><span class="p">(</span>
                <span class="n">input_scale_name</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">initializer</span>
            <span class="p">)</span>
            <span class="n">input_scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">find_weight_data</span><span class="p">(</span><span class="n">inputscale_initializer</span><span class="p">)</span>

            <span class="c1"># calcuate scale for bias</span>

            <span class="n">bias_scale</span> <span class="o">=</span> <span class="n">input_scale</span> <span class="o">*</span> <span class="n">weight_scale</span>

            <span class="c1"># quantize bias</span>
            <span class="n">quantized_data</span> <span class="o">=</span> <span class="p">(</span>
                <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">bias_data</span><span class="p">)</span> <span class="o">/</span> <span class="n">bias_scale</span><span class="p">)</span><span class="o">.</span><span class="n">round</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
            <span class="p">)</span>

            <span class="c1"># update bias initializer</span>
            <span class="n">bias_np_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">quantized_data</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
                <span class="n">bias_initializer</span><span class="o">.</span><span class="n">dims</span>
            <span class="p">)</span>
            <span class="n">packed_bias_initializer</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">numpy_helper</span><span class="o">.</span><span class="n">from_array</span><span class="p">(</span>
                <span class="n">bias_np_data</span><span class="p">,</span> <span class="n">quantized_bias_name</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">initializer</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="n">packed_bias_initializer</span><span class="p">])</span>

            <span class="c1"># log entries for this quantized bias value</span>
            <span class="n">quantized_bias_entry</span> <span class="o">=</span> <span class="n">QuantizedInitializer</span><span class="p">(</span>
                <span class="n">bias_name</span><span class="p">,</span>
                <span class="n">bias_initializer</span><span class="p">,</span>
                <span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                <span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                <span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                <span class="p">[</span><span class="n">bias_scale</span><span class="p">],</span>
                <span class="n">bias_data</span><span class="p">,</span>
                <span class="n">quantized_data</span><span class="p">,</span>
                <span class="n">qType</span><span class="o">=</span><span class="n">onnx_proto</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">INT32</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_quantized_weights</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">quantized_bias_entry</span><span class="p">)</span>

            <span class="k">assert</span> <span class="n">bias_name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">quantized_value_map</span>
            <span class="n">quantized_value</span> <span class="o">=</span> <span class="n">QuantizedValue</span><span class="p">(</span>
                <span class="n">bias_name</span><span class="p">,</span>
                <span class="n">quantized_bias_name</span><span class="p">,</span>
                <span class="s2">&quot;&quot;</span><span class="p">,</span>
                <span class="s2">&quot;&quot;</span><span class="p">,</span>
                <span class="n">QuantizedValueType</span><span class="o">.</span><span class="n">Initializer</span><span class="p">,</span>
                <span class="kc">None</span><span class="p">,</span>
                <span class="n">onnx_proto</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">INT32</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">quantized_value_map</span><span class="p">[</span><span class="n">bias_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">quantized_value</span>

        <span class="k">return</span> <span class="n">quantized_bias_name</span>

    <span class="k">def</span> <span class="nf">_quantize_inputs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">new_nodes_list</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Given a node, this function quantizes the inputs as follows:</span>
<span class="sd">            - If input is a initializer, quantize the initializer data, replace old initializer</span>
<span class="sd">              with new initializer</span>
<span class="sd">            - Else, add QuantizeLinear nodes to perform quantization</span>
<span class="sd">            parameter node: node being quantized in NodeProto format.</span>
<span class="sd">            parameter indices: input indices to quantize.</span>
<span class="sd">            parameter new_nodes_list: List of new nodes created before processing this node. This is used to</span>
<span class="sd">                                      check that two QuantizeLinear nodes are not being added for same input.</span>
<span class="sd">            return: (List of quantized input names,</span>
<span class="sd">                     List of zero point names used for input quantization,</span>
<span class="sd">                     List of scale names used for input quantization,</span>
<span class="sd">                     List of new QuantizeLinear nodes created)</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">quantized_input_names</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">zero_point_names</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">scale_names</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">nodes</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">input_index</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">:</span>
            <span class="n">node_input</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="n">input_index</span><span class="p">]</span>

            <span class="c1"># Find if this input is already quantized</span>
            <span class="k">if</span> <span class="n">node_input</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">quantized_value_map</span><span class="p">:</span>
                <span class="n">quantized_value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">quantized_value_map</span><span class="p">[</span><span class="n">node_input</span><span class="p">]</span>
                <span class="n">qType</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">weight_qType</span>
                    <span class="k">if</span> <span class="n">quantized_value</span><span class="o">.</span><span class="n">value_type</span> <span class="o">==</span> <span class="n">QuantizedValueType</span><span class="o">.</span><span class="n">Initializer</span>
                    <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_qType</span>
                <span class="p">)</span>
                <span class="k">if</span> <span class="n">quantized_value</span><span class="o">.</span><span class="n">qType</span> <span class="o">!=</span> <span class="n">qType</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                        <span class="s2">&quot;</span><span class="si">{}</span><span class="s2"> is being used by multiple nodes which are being quantized to different types. &quot;</span>
                        <span class="s2">&quot;This is not suported.&quot;</span><span class="p">,</span>
                        <span class="n">node_input</span><span class="p">,</span>
                    <span class="p">)</span>

                <span class="n">quantized_input_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">quantized_value</span><span class="o">.</span><span class="n">q_name</span><span class="p">)</span>
                <span class="n">scale_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">quantized_value</span><span class="o">.</span><span class="n">scale_name</span><span class="p">)</span>
                <span class="n">zero_point_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">quantized_value</span><span class="o">.</span><span class="n">zp_name</span><span class="p">)</span>
                <span class="k">continue</span>

            <span class="c1"># Quantize the input</span>
            <span class="n">initializer</span> <span class="o">=</span> <span class="n">_find_by_name</span><span class="p">(</span><span class="n">node_input</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">initializer</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">initializer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;Conv&quot;</span><span class="p">:</span>
                    <span class="n">weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_quantized_weight_convolution</span><span class="p">(</span>
                        <span class="n">initializer</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight_qType</span>
                    <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_quantized_weight</span><span class="p">(</span><span class="n">initializer</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight_qType</span><span class="p">)</span>

                <span class="c1"># Update graph</span>
                <span class="n">nodes</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_update_unsupported_nodes_using_weight</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">new_nodes_list</span><span class="p">)</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_update_graph</span><span class="p">(</span><span class="n">weight</span><span class="p">)</span>

                <span class="n">quantized_input_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">weight</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s2">&quot;_quantized&quot;</span><span class="p">)</span>
                <span class="n">zero_point_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">weight</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s2">&quot;_zero_point&quot;</span><span class="p">)</span>
                <span class="n">scale_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">weight</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s2">&quot;_scale&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Add QuantizeLinear node.</span>
                <span class="n">qlinear_node</span> <span class="o">=</span> <span class="n">_find_node_by_name</span><span class="p">(</span>
                    <span class="n">node_input</span> <span class="o">+</span> <span class="s2">&quot;_QuantizeLinear&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">graph</span><span class="p">,</span> <span class="n">new_nodes_list</span>
                <span class="p">)</span>
                <span class="k">if</span> <span class="n">qlinear_node</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">quantize_input_nodes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_quantize_input_nodes</span><span class="p">(</span>
                        <span class="n">node</span><span class="p">,</span> <span class="n">input_index</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_qType</span>
                    <span class="p">)</span>
                    <span class="n">nodes</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">quantize_input_nodes</span><span class="p">)</span>
                    <span class="n">qlinear_node</span> <span class="o">=</span> <span class="n">quantize_input_nodes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

                <span class="k">if</span> <span class="n">qlinear_node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;QuantizeLinear&quot;</span><span class="p">:</span>
                    <span class="n">quantized_input_names</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">qlinear_node</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>
                    <span class="n">scale_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">qlinear_node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
                    <span class="n">zero_point_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">qlinear_node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">quantized_input_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">qlinear_node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                    <span class="n">scale_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">qlinear_node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
                    <span class="n">zero_point_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">qlinear_node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>

        <span class="k">return</span> <span class="p">(</span><span class="n">quantized_input_names</span><span class="p">,</span> <span class="n">zero_point_names</span><span class="p">,</span> <span class="n">scale_names</span><span class="p">,</span> <span class="n">nodes</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_dequantize_value</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value_name</span><span class="p">,</span> <span class="n">new_nodes_list</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Given a value (input/output) which is quantized, add a DequantizeLinear node to dequantize</span>
<span class="sd">        it back to float32</span>
<span class="sd">            parameter value_name: value to dequantize</span>
<span class="sd">            parameter new_nodes_list: List of new nodes created before processing current node</span>
<span class="sd">            return: None if there is already a DequantizeLinear node that dequantizes it</span>
<span class="sd">                    A DequantizeLinear node otherwise</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">value_name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">quantized_value_map</span><span class="p">:</span>
            <span class="n">quantized_value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">quantized_value_map</span><span class="p">[</span><span class="n">value_name</span><span class="p">]</span>
            <span class="c1"># Add DequantizeLinear Node for this input</span>
            <span class="n">dqlinear_name</span> <span class="o">=</span> <span class="n">value_name</span> <span class="o">+</span> <span class="s2">&quot;_DequantizeLinear&quot;</span>
            <span class="n">dqlinear_node</span> <span class="o">=</span> <span class="n">_find_node_by_name</span><span class="p">(</span>
                <span class="n">dqlinear_name</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">graph</span><span class="p">,</span> <span class="n">new_nodes_list</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">dqlinear_node</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">dqlinear_inputs</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="n">quantized_value</span><span class="o">.</span><span class="n">q_name</span><span class="p">,</span>
                    <span class="n">quantized_value</span><span class="o">.</span><span class="n">scale_name</span><span class="p">,</span>
                    <span class="n">quantized_value</span><span class="o">.</span><span class="n">zp_name</span><span class="p">,</span>
                <span class="p">]</span>
                <span class="n">dequantize_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
                    <span class="s2">&quot;DequantizeLinear&quot;</span><span class="p">,</span> <span class="n">dqlinear_inputs</span><span class="p">,</span> <span class="p">[</span><span class="n">value_name</span><span class="p">],</span> <span class="n">dqlinear_name</span>
                <span class="p">)</span>
                <span class="k">return</span> <span class="n">dequantize_node</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># DQ op is already present, assert it&#39;s output matches the input of current node</span>
                <span class="k">assert</span> <span class="n">value_name</span> <span class="o">==</span> <span class="n">dqlinear_node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">_handle_other_ops</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node</span><span class="p">,</span> <span class="n">new_nodes_list</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Given a node which does not support quantization(Conv, Matmul, Gather), this method</span>
<span class="sd">        checks whether the input to this node is quantized and adds a DequantizeLinear node</span>
<span class="sd">        to dequantize this input back to FP32</span>
<span class="sd">            parameter node: Current node</span>
<span class="sd">            parameter new_nodes_list: List of new nodes created before processing current node</span>
<span class="sd">            return: List of new nodes created</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">nodes</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">node_input</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">):</span>
            <span class="n">dequantize_node</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dequantize_value</span><span class="p">(</span><span class="n">node_input</span><span class="p">,</span> <span class="n">new_nodes_list</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">dequantize_node</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dequantize_node</span><span class="p">)</span>

        <span class="c1"># Append the original node</span>
        <span class="n">nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">nodes</span>

    <span class="k">def</span> <span class="nf">_dequantize_outputs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_nodes_list</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Dequantize output if it is quantized</span>
<span class="sd">            parameter new_nodes_list: List of new nodes created before processing current node</span>
<span class="sd">            return: List of new nodes created</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">nodes</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">output</span><span class="p">:</span>
            <span class="n">dequantize_node</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dequantize_value</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">new_nodes_list</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">dequantize_node</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dequantize_node</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">nodes</span>

    <span class="k">def</span> <span class="nf">_handle_activation_ops</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node</span><span class="p">,</span> <span class="n">new_node_list</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Checks whether the give activation op can be removed from the graph. When mode is QLinearOps,</span>
<span class="sd">        the output quantization params are calculated based on outputs from activation nodes,</span>
<span class="sd">        therefore these nodes can be removed from the graph if they follow a quantized op.</span>
<span class="sd">            parameter node: Current node</span>
<span class="sd">            parameter new_nodes_list: List of new nodes created before processing current node</span>
<span class="sd">            return: List of nodes</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;Relu&quot;</span> <span class="ow">or</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;Clip&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">QuantizationMode</span><span class="o">.</span><span class="n">QLinearOps</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[</span><span class="n">node</span><span class="p">]</span>
        <span class="c1"># When mode is QLinearOps, the output quantization params are calculated based on outputs from</span>
        <span class="c1"># activation nodes, therefore these nodes can be removed from the graph if they follow a quantized op.</span>
        <span class="c1"># If input to this node is not quantized then keep this node</span>
        <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">quantized_value_map</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[</span><span class="n">node</span><span class="p">]</span>

        <span class="c1"># Prepare to remove this node</span>
        <span class="n">quantized_value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">quantized_value_map</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">quantized_value_map</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="n">quantized_value</span>

        <span class="k">return</span> <span class="p">[]</span>

    <span class="k">def</span> <span class="nf">_quantize_binary_math_ops</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node</span><span class="p">,</span> <span class="n">new_nodes_list</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Used when self.mode is QuantizationMode.QLinearOps.</span>
<span class="sd">        Quantize the given binary math op, like Add, Mul, etc, to QLinearAdd, QLinearMul...</span>
<span class="sd">            parameter node: Current binary math node</span>
<span class="sd">            parameter new_nodes_list: List of new nodes created before processing current node</span>
<span class="sd">            return: List of nodes in topological order that represents quantized binary math node</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">QuantizationMode</span><span class="o">.</span><span class="n">QLinearOps</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_handle_other_ops</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">new_nodes_list</span><span class="p">)</span>

        <span class="p">(</span>
            <span class="n">data_found</span><span class="p">,</span>
            <span class="n">output_scale_name</span><span class="p">,</span>
            <span class="n">output_zp_name</span><span class="p">,</span>
            <span class="n">_</span><span class="p">,</span>
            <span class="n">_</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_quantization_params</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="ow">not</span> <span class="n">data_found</span>
        <span class="p">):</span>  <span class="c1"># only try to quantize when given quantization parameters for it</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_handle_other_ops</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">new_nodes_list</span><span class="p">)</span>

        <span class="p">(</span>
            <span class="n">quantized_input_names</span><span class="p">,</span>
            <span class="n">zero_point_names</span><span class="p">,</span>
            <span class="n">scale_names</span><span class="p">,</span>
            <span class="n">nodes</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_quantize_inputs</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">new_nodes_list</span><span class="p">)</span>

        <span class="n">qlinear_binary_math_output</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;_quantized&quot;</span>
        <span class="n">qlinear_binary_math_name</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
        <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">name</span> <span class="o">!=</span> <span class="s2">&quot;&quot;</span><span class="p">:</span>
            <span class="n">qlinear_binary_math_name</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s2">&quot;_quant&quot;</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">attribute</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">attribute</span><span class="p">:</span>
            <span class="n">kwargs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">_attribute_to_kwarg</span><span class="p">(</span><span class="n">attribute</span><span class="p">))</span>
        <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;domain&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">ms_domain</span>

        <span class="n">qlinear_binary_math_inputs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="c1"># Input 0</span>
        <span class="n">qlinear_binary_math_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">quantized_input_names</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">qlinear_binary_math_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">scale_names</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">qlinear_binary_math_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">zero_point_names</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="c1"># Input 1</span>
        <span class="n">qlinear_binary_math_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">quantized_input_names</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">qlinear_binary_math_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">scale_names</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">qlinear_binary_math_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">zero_point_names</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

        <span class="c1"># Output</span>
        <span class="n">qlinear_binary_math_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output_scale_name</span><span class="p">)</span>
        <span class="n">qlinear_binary_math_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output_zp_name</span><span class="p">)</span>

        <span class="n">qlinear_binary_math_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
            <span class="s2">&quot;QLinear&quot;</span> <span class="o">+</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span><span class="p">,</span>
            <span class="n">qlinear_binary_math_inputs</span><span class="p">,</span>
            <span class="p">[</span><span class="n">qlinear_binary_math_output</span><span class="p">],</span>
            <span class="n">qlinear_binary_math_name</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">qlinear_binary_math_node</span><span class="p">)</span>

        <span class="c1"># Create an entry for this quantized value</span>
        <span class="n">q_output</span> <span class="o">=</span> <span class="n">QuantizedValue</span><span class="p">(</span>
            <span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
            <span class="n">qlinear_binary_math_output</span><span class="p">,</span>
            <span class="n">output_scale_name</span><span class="p">,</span>
            <span class="n">output_zp_name</span><span class="p">,</span>
            <span class="n">QuantizedValueType</span><span class="o">.</span><span class="n">Input</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">quantized_value_map</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="n">q_output</span>

        <span class="k">return</span> <span class="n">nodes</span>

    <span class="k">def</span> <span class="nf">_quantize_gather_ops</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node</span><span class="p">,</span> <span class="n">new_nodes_list</span><span class="p">):</span>
        <span class="k">assert</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;Gather&quot;</span>
        <span class="p">(</span>
            <span class="n">quantized_input_names</span><span class="p">,</span>
            <span class="n">zero_point_names</span><span class="p">,</span>
            <span class="n">scale_names</span><span class="p">,</span>
            <span class="n">nodes</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_quantize_inputs</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">new_nodes_list</span><span class="p">)</span>

        <span class="n">gather_new_output</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;_quantized&quot;</span>

        <span class="c1"># Create an entry for this quantized value</span>
        <span class="n">q_output</span> <span class="o">=</span> <span class="n">QuantizedValue</span><span class="p">(</span>
            <span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
            <span class="n">gather_new_output</span><span class="p">,</span>
            <span class="n">scale_names</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
            <span class="n">zero_point_names</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
            <span class="n">QuantizedValueType</span><span class="o">.</span><span class="n">Input</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">quantized_value_map</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="n">q_output</span>

        <span class="n">gather_original_output</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">gather_new_output</span>
        <span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">quantized_input_names</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">nodes</span>

    <span class="k">def</span> <span class="nf">_quantize_convolution_integer_ops</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node</span><span class="p">,</span> <span class="n">new_nodes_list</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Used when self.mode is QuantizationMode.IntegerOps.</span>
<span class="sd">            parameter node: Conv node.</span>
<span class="sd">            parameter new_nodes_list: List of new nodes created before processing this node.</span>
<span class="sd">            return: a list of nodes in topological order that represents quantized Conv node.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;Conv&quot;</span>

        <span class="p">(</span>
            <span class="n">quantized_input_names</span><span class="p">,</span>
            <span class="n">zero_point_names</span><span class="p">,</span>
            <span class="n">scale_names</span><span class="p">,</span>
            <span class="n">nodes</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_quantize_inputs</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">new_nodes_list</span><span class="p">)</span>

        <span class="c1"># quantize bias if exist</span>
        <span class="n">quantized_bias_name</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
        <span class="n">bias_present</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
            <span class="n">quantized_bias_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_quantize_bias</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">nodes</span><span class="p">)</span>
            <span class="n">bias_present</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="n">conv_integer_output</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;_quantized&quot;</span>
        <span class="n">conv_integer_name</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
        <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">name</span> <span class="o">!=</span> <span class="s2">&quot;&quot;</span><span class="p">:</span>
            <span class="n">conv_integer_name</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s2">&quot;_quant&quot;</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">attribute</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">attribute</span><span class="p">:</span>
            <span class="n">kwargs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">_attribute_to_kwarg</span><span class="p">(</span><span class="n">attribute</span><span class="p">))</span>
        <span class="n">conv_integer_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
            <span class="s2">&quot;ConvInteger&quot;</span><span class="p">,</span>
            <span class="n">quantized_input_names</span> <span class="o">+</span> <span class="n">zero_point_names</span><span class="p">,</span>
            <span class="p">[</span><span class="n">conv_integer_output</span><span class="p">],</span>
            <span class="n">conv_integer_name</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">conv_integer_node</span><span class="p">)</span>

        <span class="c1"># Add bias add nodes</span>
        <span class="k">if</span> <span class="n">bias_present</span><span class="p">:</span>
            <span class="n">conv_integer_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_bias_add_nodes</span><span class="p">(</span>
                <span class="n">nodes</span><span class="p">,</span> <span class="n">node</span><span class="p">,</span> <span class="n">conv_integer_output</span><span class="p">,</span> <span class="n">quantized_bias_name</span>
            <span class="p">)</span>

        <span class="c1"># Add cast operation to cast convInteger output to float.</span>
        <span class="n">cast_op_output</span> <span class="o">=</span> <span class="n">conv_integer_output</span> <span class="o">+</span> <span class="s2">&quot;_cast_output&quot;</span>
        <span class="n">cast_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
            <span class="s2">&quot;Cast&quot;</span><span class="p">,</span>
            <span class="p">[</span><span class="n">conv_integer_output</span><span class="p">],</span>
            <span class="p">[</span><span class="n">cast_op_output</span><span class="p">],</span>
            <span class="n">conv_integer_output</span> <span class="o">+</span> <span class="s2">&quot;_cast&quot;</span><span class="p">,</span>
            <span class="n">to</span><span class="o">=</span><span class="n">onnx_proto</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cast_node</span><span class="p">)</span>

        <span class="c1"># Add mul operation to multiply scales of two inputs.</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">scale_names</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span>
        <span class="k">if</span> <span class="n">conv_integer_name</span> <span class="o">!=</span> <span class="s2">&quot;&quot;</span><span class="p">:</span>
            <span class="n">scales_mul_op</span> <span class="o">=</span> <span class="n">conv_integer_name</span> <span class="o">+</span> <span class="s2">&quot;_scales_mul&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">scales_mul_op</span> <span class="o">=</span> <span class="n">scale_names</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;_&quot;</span> <span class="o">+</span> <span class="n">scale_names</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;_mul&quot;</span>

        <span class="n">scales_mul_node</span> <span class="o">=</span> <span class="n">_find_node_by_name</span><span class="p">(</span>
            <span class="n">scales_mul_op</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">graph</span><span class="p">,</span> <span class="n">new_nodes_list</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">scales_mul_node</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">scales_mul_node</span> <span class="o">=</span> <span class="n">_get_mul_node</span><span class="p">(</span>
                <span class="n">scale_names</span><span class="p">,</span> <span class="n">scales_mul_op</span> <span class="o">+</span> <span class="s2">&quot;:0&quot;</span><span class="p">,</span> <span class="n">scales_mul_op</span>
            <span class="p">)</span>
            <span class="n">nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">scales_mul_node</span><span class="p">)</span>

        <span class="n">scales_mul_op_output</span> <span class="o">=</span> <span class="n">scales_mul_node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># Add mul operation to multiply mul_scales_op result with output of ConvInteger</span>
        <span class="c1"># and make the output of this node the same as output of original conv node.</span>
        <span class="n">output_scale_mul_op</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
        <span class="k">if</span> <span class="n">conv_integer_name</span> <span class="o">!=</span> <span class="s2">&quot;&quot;</span><span class="p">:</span>
            <span class="n">output_scale_mul_op</span> <span class="o">=</span> <span class="n">conv_integer_name</span> <span class="o">+</span> <span class="s2">&quot;_output_scale_mul&quot;</span>
        <span class="n">nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">_get_mul_node</span><span class="p">(</span>
                <span class="p">[</span><span class="n">cast_op_output</span><span class="p">,</span> <span class="n">scales_mul_op_output</span><span class="p">],</span>
                <span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                <span class="n">output_scale_mul_op</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">nodes</span>

    <span class="k">def</span> <span class="nf">_quantize_matmul_integer_ops</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node</span><span class="p">,</span> <span class="n">new_nodes_list</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Used when self.mode is QuantizationMode.IntegerOps.</span>
<span class="sd">            parameter node: MatMul node.</span>
<span class="sd">            parameter new_nodes_list: List of new nodes created before processing this node.</span>
<span class="sd">            return: a list of nodes in topological order that represents quantized MatMul node.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;MatMul&quot;</span>

        <span class="p">(</span>
            <span class="n">quantized_input_names</span><span class="p">,</span>
            <span class="n">zero_point_names</span><span class="p">,</span>
            <span class="n">scale_names</span><span class="p">,</span>
            <span class="n">nodes</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_quantize_inputs</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">new_nodes_list</span><span class="p">)</span>

        <span class="n">matmul_integer_output</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;_quantized&quot;</span>
        <span class="n">matmul_integer_name</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
        <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">name</span> <span class="o">!=</span> <span class="s2">&quot;&quot;</span><span class="p">:</span>
            <span class="n">matmul_integer_name</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s2">&quot;_quant&quot;</span>
        <span class="n">matmul_integer_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
            <span class="s2">&quot;MatMulInteger&quot;</span><span class="p">,</span>
            <span class="n">quantized_input_names</span> <span class="o">+</span> <span class="n">zero_point_names</span><span class="p">,</span>
            <span class="p">[</span><span class="n">matmul_integer_output</span><span class="p">],</span>
            <span class="n">matmul_integer_name</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">matmul_integer_node</span><span class="p">)</span>

        <span class="c1"># Add cast operation to cast matmulInteger output to float.</span>
        <span class="n">cast_op_output</span> <span class="o">=</span> <span class="n">matmul_integer_output</span> <span class="o">+</span> <span class="s2">&quot;_cast_output&quot;</span>
        <span class="n">cast_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
            <span class="s2">&quot;Cast&quot;</span><span class="p">,</span>
            <span class="p">[</span><span class="n">matmul_integer_output</span><span class="p">],</span>
            <span class="p">[</span><span class="n">cast_op_output</span><span class="p">],</span>
            <span class="n">matmul_integer_output</span> <span class="o">+</span> <span class="s2">&quot;_cast&quot;</span><span class="p">,</span>
            <span class="n">to</span><span class="o">=</span><span class="n">onnx_proto</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cast_node</span><span class="p">)</span>

        <span class="c1"># Add mul operation to multiply scales of two inputs.</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">scale_names</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span>
        <span class="k">if</span> <span class="n">matmul_integer_name</span> <span class="o">!=</span> <span class="s2">&quot;&quot;</span><span class="p">:</span>
            <span class="n">scales_mul_op</span> <span class="o">=</span> <span class="n">matmul_integer_name</span> <span class="o">+</span> <span class="s2">&quot;_scales_mul&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">scales_mul_op</span> <span class="o">=</span> <span class="n">scale_names</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;_&quot;</span> <span class="o">+</span> <span class="n">scale_names</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;_mul&quot;</span>

        <span class="n">scales_mul_node</span> <span class="o">=</span> <span class="n">_find_node_by_name</span><span class="p">(</span>
            <span class="n">scales_mul_op</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">graph</span><span class="p">,</span> <span class="n">new_nodes_list</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">scales_mul_node</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">scales_mul_node</span> <span class="o">=</span> <span class="n">_get_mul_node</span><span class="p">(</span>
                <span class="n">scale_names</span><span class="p">,</span> <span class="n">scales_mul_op</span> <span class="o">+</span> <span class="s2">&quot;:0&quot;</span><span class="p">,</span> <span class="n">scales_mul_op</span>
            <span class="p">)</span>
            <span class="n">nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">scales_mul_node</span><span class="p">)</span>

        <span class="n">scales_mul_op_output</span> <span class="o">=</span> <span class="n">scales_mul_node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># Add mul operation to multiply mul_scales_op result with output of MatMulInteger</span>
        <span class="c1"># and make the output of this node the same as output of original matmul node.</span>
        <span class="n">output_scale_mul_op</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
        <span class="k">if</span> <span class="n">matmul_integer_name</span> <span class="o">!=</span> <span class="s2">&quot;&quot;</span><span class="p">:</span>
            <span class="n">output_scale_mul_op</span> <span class="o">=</span> <span class="n">matmul_integer_name</span> <span class="o">+</span> <span class="s2">&quot;_output_scale_mul&quot;</span>
        <span class="n">nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">_get_mul_node</span><span class="p">(</span>
                <span class="p">[</span><span class="n">cast_op_output</span><span class="p">,</span> <span class="n">scales_mul_op_output</span><span class="p">],</span>
                <span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                <span class="n">output_scale_mul_op</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">nodes</span>

    <span class="k">def</span> <span class="nf">_quantize_convolution_qlinear_ops</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node</span><span class="p">,</span> <span class="n">new_nodes_list</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Used when self.mode is QuantizationMode.QLinearOps.</span>
<span class="sd">            parameter node: Conv node.</span>
<span class="sd">            parameter new_nodes_list: List of new nodes created before processing this node.</span>
<span class="sd">            return: a list of nodes in topological order that represents quantized Conv node.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;Conv&quot;</span>

        <span class="p">(</span>
            <span class="n">quantized_input_names</span><span class="p">,</span>
            <span class="n">zero_point_names</span><span class="p">,</span>
            <span class="n">scale_names</span><span class="p">,</span>
            <span class="n">nodes</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_quantize_inputs</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">new_nodes_list</span><span class="p">)</span>

        <span class="n">quantized_bias_name</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
        <span class="n">bias_present</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
            <span class="n">quantized_bias_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_quantize_bias</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">nodes</span><span class="p">)</span>
            <span class="n">bias_present</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="p">(</span>
            <span class="n">data_found</span><span class="p">,</span>
            <span class="n">output_scale_name</span><span class="p">,</span>
            <span class="n">output_zp_name</span><span class="p">,</span>
            <span class="n">_</span><span class="p">,</span>
            <span class="n">_</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_quantization_params</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">data_found</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s1">&#39;Quantization parameters for output:&quot;</span><span class="si">{}</span><span class="s1">&quot; of node:&quot;</span><span class="si">{}</span><span class="s1">&quot; not specified&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">node</span><span class="o">.</span><span class="n">name</span>
                <span class="p">)</span>
            <span class="p">)</span>

        <span class="n">qlinear_conv_output</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;_quantized&quot;</span>
        <span class="n">qlinear_conv_name</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
        <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">name</span> <span class="o">!=</span> <span class="s2">&quot;&quot;</span><span class="p">:</span>
            <span class="n">qlinear_conv_name</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s2">&quot;_quant&quot;</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">attribute</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">attribute</span><span class="p">:</span>
            <span class="n">kwargs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">_attribute_to_kwarg</span><span class="p">(</span><span class="n">attribute</span><span class="p">))</span>
        <span class="n">qlinear_conv_inputs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="c1"># Input 0</span>
        <span class="n">qlinear_conv_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">quantized_input_names</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">qlinear_conv_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">scale_names</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">qlinear_conv_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">zero_point_names</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="c1"># Input 1</span>
        <span class="n">qlinear_conv_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">quantized_input_names</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">qlinear_conv_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">scale_names</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">qlinear_conv_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">zero_point_names</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

        <span class="c1"># Output</span>
        <span class="n">qlinear_conv_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output_scale_name</span><span class="p">)</span>
        <span class="n">qlinear_conv_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output_zp_name</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">bias_present</span><span class="p">:</span>
            <span class="n">qlinear_conv_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">quantized_bias_name</span><span class="p">)</span>

        <span class="n">qlinear_conv_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
            <span class="s2">&quot;QLinearConv&quot;</span><span class="p">,</span>
            <span class="n">qlinear_conv_inputs</span><span class="p">,</span>
            <span class="p">[</span><span class="n">qlinear_conv_output</span><span class="p">],</span>
            <span class="n">qlinear_conv_name</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">qlinear_conv_node</span><span class="p">)</span>

        <span class="c1"># Create an entry for this quantized value</span>
        <span class="n">q_output</span> <span class="o">=</span> <span class="n">QuantizedValue</span><span class="p">(</span>
            <span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
            <span class="n">qlinear_conv_output</span><span class="p">,</span>
            <span class="n">output_scale_name</span><span class="p">,</span>
            <span class="n">output_zp_name</span><span class="p">,</span>
            <span class="n">QuantizedValueType</span><span class="o">.</span><span class="n">Input</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">quantized_value_map</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="n">q_output</span>

        <span class="k">return</span> <span class="n">nodes</span>

    <span class="k">def</span> <span class="nf">_quantize_matmul_qlinear_ops</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node</span><span class="p">,</span> <span class="n">new_nodes_list</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Used when self.mode is QuantizationMode.QLinearOps.</span>
<span class="sd">            parameter node: MatMul node.</span>
<span class="sd">            parameter new_nodes_list: List of new nodes created before processing this node.</span>
<span class="sd">            return: a list of nodes in topological order that represents quantized Conv node.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;MatMul&quot;</span>

        <span class="p">(</span>
            <span class="n">quantized_input_names</span><span class="p">,</span>
            <span class="n">zero_point_names</span><span class="p">,</span>
            <span class="n">scale_names</span><span class="p">,</span>
            <span class="n">nodes</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_quantize_inputs</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">new_nodes_list</span><span class="p">)</span>

        <span class="p">(</span>
            <span class="n">data_found</span><span class="p">,</span>
            <span class="n">output_scale_name</span><span class="p">,</span>
            <span class="n">output_zp_name</span><span class="p">,</span>
            <span class="n">_</span><span class="p">,</span>
            <span class="n">_</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_quantization_params</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="k">assert</span> <span class="n">data_found</span>

        <span class="n">qlinear_matmul_output</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;_quantized&quot;</span>
        <span class="n">qlinear_matmul_name</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
        <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">name</span> <span class="o">!=</span> <span class="s2">&quot;&quot;</span><span class="p">:</span>
            <span class="n">qlinear_matmul_name</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s2">&quot;_quant&quot;</span>

        <span class="n">qlinear_matmul_inputs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="c1"># Input 0</span>
        <span class="n">qlinear_matmul_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">quantized_input_names</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">qlinear_matmul_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">scale_names</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">qlinear_matmul_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">zero_point_names</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="c1"># Input 1</span>
        <span class="n">qlinear_matmul_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">quantized_input_names</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">qlinear_matmul_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">scale_names</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">qlinear_matmul_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">zero_point_names</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="c1"># Output</span>
        <span class="n">qlinear_matmul_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output_scale_name</span><span class="p">)</span>
        <span class="n">qlinear_matmul_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output_zp_name</span><span class="p">)</span>

        <span class="n">qlinear_matmul_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
            <span class="s2">&quot;QLinearMatMul&quot;</span><span class="p">,</span>
            <span class="n">qlinear_matmul_inputs</span><span class="p">,</span>
            <span class="p">[</span><span class="n">qlinear_matmul_output</span><span class="p">],</span>
            <span class="n">qlinear_matmul_name</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">qlinear_matmul_node</span><span class="p">)</span>

        <span class="c1"># Create an entry for this quantized value</span>
        <span class="n">q_output</span> <span class="o">=</span> <span class="n">QuantizedValue</span><span class="p">(</span>
            <span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
            <span class="n">qlinear_matmul_output</span><span class="p">,</span>
            <span class="n">output_scale_name</span><span class="p">,</span>
            <span class="n">output_zp_name</span><span class="p">,</span>
            <span class="n">QuantizedValueType</span><span class="o">.</span><span class="n">Input</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">quantized_value_map</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="n">q_output</span>

        <span class="k">return</span> <span class="n">nodes</span>

    <span class="k">def</span> <span class="nf">_quantize_convolution</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node</span><span class="p">,</span> <span class="n">new_nodes_list</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        https://github.com/onnx/onnx/blob/master/docs/Operators.md#Conv</span>
<span class="sd">        :param node: Conv node</span>
<span class="sd">        :param new_nodes_list: List of new nodes created before processing this node.</span>
<span class="sd">        :return: a list of nodes in topological order that represents quantized Conv node</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;Conv&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">==</span> <span class="n">QuantizationMode</span><span class="o">.</span><span class="n">IntegerOps</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_quantize_convolution_integer_ops</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">new_nodes_list</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">==</span> <span class="n">QuantizationMode</span><span class="o">.</span><span class="n">QLinearOps</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_quantize_convolution_qlinear_ops</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">new_nodes_list</span><span class="p">)</span>

        <span class="k">return</span> <span class="p">[</span><span class="n">node</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">_quantize_matmul</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node</span><span class="p">,</span> <span class="n">new_nodes_list</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        https://github.com/onnx/onnx/blob/master/docs/Operators.md#MatMul</span>
<span class="sd">        :param node: MatMul node</span>
<span class="sd">        :param new_nodes_list: List of new nodes created before processing this node.</span>
<span class="sd">        :return: a list of nodes in topological order that represents quantized MatMul node</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;MatMul&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">==</span> <span class="n">QuantizationMode</span><span class="o">.</span><span class="n">IntegerOps</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_quantize_matmul_integer_ops</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">new_nodes_list</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">==</span> <span class="n">QuantizationMode</span><span class="o">.</span><span class="n">QLinearOps</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_quantize_matmul_qlinear_ops</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">new_nodes_list</span><span class="p">)</span>

        <span class="k">return</span> <span class="p">[</span><span class="n">node</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">_quantize_attention</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node</span><span class="p">,</span> <span class="n">new_nodes_list</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        parameter node: Attention node.</span>
<span class="sd">        parameter new_nodes_list: List of new nodes created before processing this node.</span>
<span class="sd">        return: a list of nodes in topological order that represents quantized Attention node.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="n">node</span><span class="o">.</span><span class="n">op_type</span> <span class="o">==</span> <span class="s2">&quot;Attention&quot;</span>

        <span class="p">(</span>
            <span class="n">quantized_input_names</span><span class="p">,</span>
            <span class="n">zero_point_names</span><span class="p">,</span>
            <span class="n">scale_names</span><span class="p">,</span>
            <span class="n">nodes</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_quantize_inputs</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">new_nodes_list</span><span class="p">)</span>

        <span class="n">qattention_name</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
        <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">name</span> <span class="o">!=</span> <span class="s2">&quot;&quot;</span><span class="p">:</span>
            <span class="n">qattention_name</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s2">&quot;_quant&quot;</span>

        <span class="n">inputs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">inputs</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">quantized_input_names</span><span class="p">)</span>
        <span class="n">inputs</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">2</span><span class="p">]])</span>
        <span class="n">inputs</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">scale_names</span><span class="p">)</span>
        <span class="n">inputs</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">3</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span><span class="p">])</span>
        <span class="n">inputs</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">zero_point_names</span><span class="p">)</span>
        <span class="n">inputs</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">4</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span><span class="p">])</span>

        <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">attribute</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">attribute</span><span class="p">:</span>
            <span class="n">kwargs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">_attribute_to_kwarg</span><span class="p">(</span><span class="n">attribute</span><span class="p">))</span>
        <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;domain&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">ms_domain</span>
        <span class="n">qattention_node</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
            <span class="s2">&quot;QAttention&quot;</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">,</span> <span class="n">qattention_name</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
        <span class="p">)</span>
        <span class="n">nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">qattention_node</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">nodes</span></div>


<div class="viewcode-block" id="check_opset_version"><a class="viewcode-back" href="../../../../../api/sparseml.onnx.optim.quantization.html#sparseml.onnx.optim.quantization.quantize.check_opset_version">[docs]</a><span class="k">def</span> <span class="nf">check_opset_version</span><span class="p">(</span><span class="n">org_model</span><span class="p">,</span> <span class="n">force_fusions</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Check opset version of original model and set opset version and fuse_dynamic_quant accordingly.</span>
<span class="sd">    If opset version &lt; 10, set quantized model opset version to 10.</span>
<span class="sd">    If opset version == 10, do quantization without using dynamicQuantizeLinear operator.</span>
<span class="sd">    If opset version == 11, do quantization using dynamicQuantizeLinear operator.</span>
<span class="sd">    :return: fuse_dynamic_quant boolean value.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">global</span> <span class="n">onnx_op_set_version</span>
    <span class="n">opset_version</span> <span class="o">=</span> <span class="n">org_model</span><span class="o">.</span><span class="n">opset_import</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">version</span>
    <span class="n">fuse_dynamic_quant</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">if</span> <span class="n">opset_version</span> <span class="o">&lt;</span> <span class="mi">11</span> <span class="ow">and</span> <span class="n">force_fusions</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span>
            <span class="s2">&quot;Warning: The original model opset version is </span><span class="si">{}</span><span class="s2">, which does not support node fusions.</span><span class="se">\n\</span>
<span class="s2">            Forcing fusions can break other nodes in the model.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">opset_version</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="n">onnx_op_set_version</span> <span class="o">=</span> <span class="mi">11</span>
        <span class="n">fuse_dynamic_quant</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">return</span> <span class="n">fuse_dynamic_quant</span>

    <span class="k">if</span> <span class="n">opset_version</span> <span class="o">&lt;</span> <span class="mi">10</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span>
            <span class="s2">&quot;Warning: The original model opset version is </span><span class="si">{}</span><span class="s2">, which does not support quantized operators.</span><span class="se">\n\</span>
<span class="s2">            The opset version of quantized model will be set to 10. Use onnx model checker to verify model after quantization.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">opset_version</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="n">onnx_op_set_version</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="k">elif</span> <span class="n">opset_version</span> <span class="o">==</span> <span class="mi">10</span><span class="p">:</span>
        <span class="n">onnx_op_set_version</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">fuse_dynamic_quant</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">return</span> <span class="n">fuse_dynamic_quant</span></div>


<div class="viewcode-block" id="quantize"><a class="viewcode-back" href="../../../../../api/sparseml.onnx.optim.quantization.html#sparseml.onnx.optim.quantization.quantize.quantize">[docs]</a><span class="k">def</span> <span class="nf">quantize</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">per_channel</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">nbits</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
    <span class="n">quantization_mode</span><span class="o">=</span><span class="n">QuantizationMode</span><span class="o">.</span><span class="n">IntegerOps</span><span class="p">,</span>
    <span class="n">static</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">force_fusions</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">symmetric_activation</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">symmetric_weight</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">quantization_params</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">nodes_to_quantize</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">nodes_to_exclude</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Given an onnx model, create a quantized onnx model and save it into a file</span>
<span class="sd">    :param model: ModelProto to quantize</span>
<span class="sd">    :param per_channel: quantize weights per channel</span>
<span class="sd">    :param nbits: number of bits to represent quantized data. Currently only supporting 8-bit types</span>
<span class="sd">    :param quantization_mode: Can be one of the QuantizationMode types.</span>
<span class="sd">        IntegerOps:</span>
<span class="sd">            the function will use integer ops. Only ConvInteger and MatMulInteger ops are supported now.</span>
<span class="sd">        QLinearOps:</span>
<span class="sd">            the function will use QLinear ops. Only QLinearConv and QLinearMatMul ops are supported now.</span>
<span class="sd">    :param static:</span>
<span class="sd">        True: The inputs/activations are quantized using static scale and zero point values</span>
<span class="sd">              specified through quantization_params.</span>
<span class="sd">        False: The inputs/activations are quantized using dynamic scale and zero point values</span>
<span class="sd">               computed while running the model.</span>
<span class="sd">    :param force_fusions:</span>
<span class="sd">        True: Fuses nodes added for dynamic quantization</span>
<span class="sd">        False: No fusion is applied for nodes which are added for dynamic quantization.</span>
<span class="sd">        Should be only used in cases where backends want to apply special fusion routines</span>
<span class="sd">    :param symmetric_activation:</span>
<span class="sd">        True: activations are quantized into signed integers.</span>
<span class="sd">        False: activations are quantized into unsigned integers.</span>
<span class="sd">    :param symmetric_weight:</span>
<span class="sd">        True: weights are quantized into signed integers.</span>
<span class="sd">        False: weights are quantized into unsigned integers.</span>
<span class="sd">    :param quantization_params:</span>
<span class="sd">        Dictionary to specify the zero point and scale values for inputs to conv and matmul nodes.</span>
<span class="sd">        Should be specified when static is set to True.</span>
<span class="sd">        The quantization_params should be specified in the following format:</span>
<span class="sd">            {</span>
<span class="sd">                &quot;input_name&quot;: [zero_point, scale]</span>
<span class="sd">            }.</span>
<span class="sd">        zero_point should be of type np.uint8 and scale should be of type np.float32.</span>
<span class="sd">        example:</span>
<span class="sd">            {</span>
<span class="sd">                &#39;resnet_model/Relu_1:0&#39;: [np.uint8(0), np.float32(0.019539741799235344)],</span>
<span class="sd">                &#39;resnet_model/Relu_2:0&#39;: [np.uint8(0), np.float32(0.011359662748873234)]</span>
<span class="sd">            }</span>
<span class="sd">    :return: ModelProto with quantization</span>
<span class="sd">    :param nodes_to_quantize:</span>
<span class="sd">        List of nodes names to quantize. When this list is not None only the nodes in this list</span>
<span class="sd">        are quantized.</span>
<span class="sd">        example:</span>
<span class="sd">        [</span>
<span class="sd">            &#39;Conv__224&#39;,</span>
<span class="sd">            &#39;Conv__252&#39;</span>
<span class="sd">        ]</span>
<span class="sd">    :param nodes_to_exclude:</span>
<span class="sd">        List of nodes names to exclude. The nodes in this list will be excluded from quantization</span>
<span class="sd">        when it is not None.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">nbits</span> <span class="o">==</span> <span class="mi">8</span><span class="p">:</span>
        <span class="n">input_qType</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">onnx_proto</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">INT8</span>
            <span class="k">if</span> <span class="n">symmetric_activation</span>
            <span class="k">else</span> <span class="n">onnx_proto</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">UINT8</span>
        <span class="p">)</span>
        <span class="n">weight_qType</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">onnx_proto</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">INT8</span>
            <span class="k">if</span> <span class="n">symmetric_weight</span>
            <span class="k">else</span> <span class="n">onnx_proto</span><span class="o">.</span><span class="n">TensorProto</span><span class="o">.</span><span class="n">UINT8</span>
        <span class="p">)</span>
        <span class="n">mode</span> <span class="o">=</span> <span class="n">quantization_mode</span>
        <span class="n">copy_model</span> <span class="o">=</span> <span class="n">onnx_proto</span><span class="o">.</span><span class="n">ModelProto</span><span class="p">()</span>
        <span class="n">copy_model</span><span class="o">.</span><span class="n">CopyFrom</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
        <span class="n">fuse_dynamic_quant</span> <span class="o">=</span> <span class="n">check_opset_version</span><span class="p">(</span><span class="n">copy_model</span><span class="p">,</span> <span class="n">force_fusions</span><span class="p">)</span>
        <span class="n">quantizer</span> <span class="o">=</span> <span class="n">ONNXQuantizer</span><span class="p">(</span>
            <span class="n">copy_model</span><span class="p">,</span>
            <span class="n">per_channel</span><span class="p">,</span>
            <span class="n">mode</span><span class="p">,</span>
            <span class="n">static</span><span class="p">,</span>
            <span class="n">fuse_dynamic_quant</span><span class="p">,</span>
            <span class="n">weight_qType</span><span class="p">,</span>
            <span class="n">input_qType</span><span class="p">,</span>
            <span class="n">quantization_params</span><span class="p">,</span>
            <span class="n">nodes_to_quantize</span><span class="p">,</span>
            <span class="n">nodes_to_exclude</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">quantizer</span><span class="o">.</span><span class="n">quantize_model</span><span class="p">()</span>
        <span class="n">quantizer</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">producer_name</span> <span class="o">=</span> <span class="n">__producer__</span>
        <span class="n">quantizer</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">producer_version</span> <span class="o">=</span> <span class="n">__version__</span>
        <span class="k">return</span> <span class="n">quantizer</span><span class="o">.</span><span class="n">model</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Only 8 bit quantization is currently supported&quot;</span><span class="p">)</span></div>
</pre></div>

           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021 - present / Neuralmagic, Inc. All Rights Reserved. Licensed under the Apache License, Version 2.0 (the &#34;License&#34;).

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-128364174-1', 'auto');
    
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>