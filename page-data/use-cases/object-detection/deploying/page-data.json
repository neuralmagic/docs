{"componentChunkName":"component---src-root-jsx","path":"/use-cases/object-detection/deploying","result":{"data":{"site":{"siteMetadata":{"title":null,"docsLocation":"https://docs.neuralmagic.com"}},"mdx":{"fields":{"id":"d1d7a8f3-9061-539a-aff8-d3957da959c6","title":"Deploying","slug":"/use-cases/object-detection/deploying","githubURL":"https://github.com/neuralmagic/docs/blob/main/src/content/use-cases/object-detection/deploying.mdx"},"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"Deploying\",\n  \"metaTitle\": \"Object Detection Deployments With DeepSparse\",\n  \"metaDescription\": \"Object Detection deployments with Ultralytics YOLOv5 and DeepSparse to create cheaper and more performant models\",\n  \"index\": 2000\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", null, \"Deploying an Object Detection Model With Ultralytics YOLOv5 and DeepSparse\"), mdx(\"p\", null, \"This page explains how to deploy an object detection model with DeepSparse.\"), mdx(\"p\", null, \"DeepSparse allows accelerated inference, serving, and benchmarking of sparsified \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/ultralytics/yolo\"\n  }, \"Ultralytics YOLOv5\"), \" models.\\nThe Ultralytics integration enables you to easily deploy sparsified YOLOv5 with DeepSparse for GPU-class performance directly on the CPU.\"), mdx(\"p\", null, \"This integration currently supports the original YOLOv5 and updated V6.1 architectures.\"), mdx(\"h2\", null, \"Installation Requirements\"), mdx(\"p\", null, \"This use case requires the installation of \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/get-started/install/deepsparse\"\n  }, \"DeepSparse Server+YOLO\"), \".\"), mdx(\"h2\", null, \"Getting Started\"), mdx(\"p\", null, \"Before you start using DeepSparse, confirm your machine is\\ncompatible with our \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/user-guides/deepsparse-engine/hardware-support\"\n  }, \"hardware requirements\"), \".\"), mdx(\"h3\", null, \"Model Format\"), mdx(\"p\", null, \"To deploy an image classification model using DeepSparse, pass the model in the ONNX format.\\nThis grants the DeepSparse the flexibility to serve any model in a framework-agnostic environment.\"), mdx(\"p\", null, \"Below we describe two possibilities to obtain the required ONNX model.\"), mdx(\"details\", null, mdx(\"summary\", null, mdx(\"b\", null, \"Exporting the ONNX File From SparseML\")), mdx(\"p\", null, \"This pathway is relevant if you intend to deploy a model created using the SparseML library.\"), mdx(\"p\", null, \"After training your model with SparseML, locate the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \".pt\"), \" file for the model you'd like to export and run the ONNX export script below.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-bash\"\n  }, \"sparseml.yolov5.export_onnx \\\\\\n    --weights path/to/your/model \\\\\\n    --dynamic #Allows for dynamic input shape\\n\")), mdx(\"p\", null, \"This creates a \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"model.onnx\"), \" file in the local filesystem in the directory of your \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"weights\"), \".\"), mdx(\"p\", null, \"The examples below use SparseZoo stubs, but simply pass the path to \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"model.onnx\"), \" in place of the stubs to use the local model.\")), mdx(\"details\", null, mdx(\"summary\", null, mdx(\"b\", null, \"Using the ONNX File in the SparseZoo\")), mdx(\"p\", null, \"This pathway is relevant if you plan to use an off-the-shelf model from the SparseZoo.\"), mdx(\"p\", null, \"When a SparseZoo stub is passed to the model, DeepSparse downloads the appropriate ONNX and other configuration files\\nfrom the SparseZoo repository. For example, the SparseZoo stub for the pruned (not quantized) YOLOv5 is:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"zoo:cv/detection/yolov5-l/pytorch/ultralytics/coco/pruned-aggressive_98\\n\"))), mdx(\"p\", null, \"The deployment API examples use SparseZoo stubs to highlight this pathway.\"), mdx(\"h2\", null, \"Deployment APIs\"), mdx(\"p\", null, \"DeepSparse provides both a Python \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"Pipeline\"), \" API and an out-of-the-box model server\\nthat can be used for end-to-end inference in either Python workflows or as an HTTP endpoint.\\nBoth options provide similar specifications for configurations and support annotation serving for all\\nYOLOv5 models.\"), mdx(\"h3\", null, \"Python API\"), mdx(\"p\", null, mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"Pipelines\"), \" is the default interface for running inference with DeepSparse.\"), mdx(\"p\", null, \"Once a model is obtained, either through SparseML training or directly from SparseZoo, \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"Pipeline\"), \" can be used to easily facilitate end-to-end inference and deployment of the sparsified neural networks.\"), mdx(\"p\", null, \"If no model is specified to the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"Pipeline\"), \" for a given task, the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"Pipeline\"), \" will automatically select a pruned and quantized model for the task from the SparseZoo that can be used for accelerated inference. Note that other models in the SparseZoo will have different tradeoffs between speed, size, and accuracy.\"), mdx(\"h3\", null, \"HTTP Server\"), mdx(\"p\", null, \"As an alternative to the Python API, DeepSparse Server allows you to serve ONNX models and pipelines in HTTP.\\nConfiguring the server uses the same parameters and schemas as the\\n\", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"Pipelines\"), \", enabling simple deployment.  Once launched, a \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"/docs\"), \" endpoint is created with full\\nendpoint descriptions and support for making sample requests.\"), mdx(\"p\", null, \"An example of starting and requesting a DeepSparse Server for YOLOv5 is given below.\"), mdx(\"h2\", null, \"Deployment Examples\"), mdx(\"p\", null, \"The following section includes example usage of the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"Pipeline\"), \" and server APIs for\\nvarious image classification models. Each example uses a SparseZoo stub to pull down the model,\\nbut a local path to an ONNX file can also be passed as the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"model_path\"), \".\"), mdx(\"h3\", null, \"Python API\"), mdx(\"p\", null, \"If you don't have an image ready, pull a sample image down with:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-bash\"\n  }, \"wget -O basilica.jpg https://raw.githubusercontent.com/neuralmagic/deepsparse/main/src/deepsparse/yolo/sample_images/basilica.jpg\\n\")), mdx(\"p\", null, \"Create a \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"Pipeline\"), \" and run inference with the following.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"from deepsparse import Pipeline\\n\\nmodel_stub = \\\"zoo:cv/detection/yolov5-l/pytorch/ultralytics/coco/pruned-aggressive_98\\\"\\nimages = [\\\"basilica.jpg\\\"]\\n\\nyolo_pipeline = Pipeline.create(\\n    task=\\\"yolo\\\",\\n    model_path=model_stub,\\n)\\n\\npipeline_outputs = yolo_pipeline(images=images, iou_thres=0.6, conf_thres=0.001)\\n\")), mdx(\"h3\", null, \"Annotate CLI\"), mdx(\"p\", null, \"You can also use the annotate command to have the Engine save an annotated photo on disk.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-bash\"\n  }, \"deepsparse.object_detection.annotate --source basilica.jpg #Try --source 0 to annotate your live webcam feed\\n\")), mdx(\"p\", null, \"Running the above command will create an \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"annotation-results\"), \" folder and save the annotated image inside.\"), mdx(\"p\", null, \"If a \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"--model_filepath\"), \" argument is not provided, \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"zoo:cv/detection/yolov5-s/pytorch/ultralytics/coco/pruned-aggressive_96\"), \" will be used by default.\"), mdx(\"h3\", null, \"HTTP Server\"), mdx(\"p\", null, \"Spinning up:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-bash\"\n  }, \"deepsparse.server \\\\\\n    task yolo \\\\\\n    --model_path \\\"zoo:cv/detection/yolov5-s/pytorch/ultralytics/coco/pruned_quant-aggressive_94\\\"\\n\")), mdx(\"p\", null, \"Making a request:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"import requests\\nimport json\\n\\nurl = 'http://0.0.0.0:5543/predict/from_files'\\npath = ['basilica.jpg'] # list of images for inference\\nfiles = [('request', open(img, 'rb')) for img in path]\\nresp = requests.post(url=url, files=files)\\nannotations = json.loads(resp.text) # dictionary of annotation results\\nbounding_boxes = annotations[\\\"boxes\\\"]\\nlabels = annotations[\\\"labels\\\"]\\n\")), mdx(\"h2\", null, \"Benchmarking\"), mdx(\"p\", null, \"The mission of Neural Magic is to enable GPU-class inference performance on commodity CPUs. Want to find out how fast our sparse YOLOv5 ONNX models perform inference?\\nYou can quickly do benchmarking tests on your own with a single CLI command!\"), mdx(\"p\", null, \"You only need to provide the model path of a SparseZoo ONNX model or your own local ONNX model to get started:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-bash\"\n  }, \"deepsparse.benchmark \\\\\\n    zoo:cv/detection/yolov5-s/pytorch/ultralytics/coco/pruned_quant-aggressive_94 \\\\\\n    --scenario sync\\n\\n> Original Model Path: zoo:cv/detection/yolov5-s/pytorch/ultralytics/coco/pruned_quant-aggressive_94\\n> Batch Size: 1\\n> Scenario: sync\\n> Throughput (items/sec): 74.0355\\n> Latency Mean (ms/batch): 13.4924\\n> Latency Median (ms/batch): 13.4177\\n> Latency Std (ms/batch): 0.2166\\n> Iterations: 741\\n\")), mdx(\"p\", null, \"To learn more about benchmarking, refer to the appropriate documentation.\\nAlso, check out our \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/neuralmagic/deepsparse/tree/main/src/deepsparse/benchmark\"\n  }, \"Benchmarking Tutorial on GitHub\"), \".\"));\n}\n;\nMDXContent.isMDXComponent = true;","tableOfContents":{"items":[{"url":"#deploying-an-object-detection-model-with-ultralytics-yolov5-and-deepsparse","title":"Deploying an Object Detection Model With Ultralytics YOLOv5 and DeepSparse","items":[{"url":"#installation-requirements","title":"Installation Requirements"},{"url":"#getting-started","title":"Getting Started","items":[{"url":"#model-format","title":"Model Format"}]},{"url":"#deployment-apis","title":"Deployment APIs","items":[{"url":"#python-api","title":"Python API"},{"url":"#http-server","title":"HTTP Server"}]},{"url":"#deployment-examples","title":"Deployment Examples","items":[{"url":"#python-api-1","title":"Python API"},{"url":"#annotate-cli","title":"Annotate CLI"},{"url":"#http-server-1","title":"HTTP Server"}]},{"url":"#benchmarking","title":"Benchmarking"}]}]},"parent":{"relativePath":"use-cases/object-detection/deploying.mdx"},"frontmatter":{"metaTitle":"Object Detection Deployments With DeepSparse","metaDescription":"Object Detection deployments with Ultralytics YOLOv5 and DeepSparse to create cheaper and more performant models","index":2000,"skipToChild":null}},"allMdx":{"edges":[{"node":{"fields":{"id":"220abd27-24cf-5408-9402-3e7b0591a7ec","slug":"/details","title":"Details"},"frontmatter":{"index":5000,"targetURL":null,"skipToChild":true,"metaTitle":"Details","metaDescription":"Details"}}},{"node":{"fields":{"id":"bfcfecba-6eb1-59e8-8379-9c6d0c7a6a46","slug":"/get-started","title":"Get Started"},"frontmatter":{"index":1000,"targetURL":null,"skipToChild":true,"metaTitle":"Get Started","metaDescription":"Getting started with the Neural Magic Platform"}}},{"node":{"fields":{"id":"ee9f8c1f-d776-5134-89e6-b60f31e11b65","slug":"/products","title":"Products"},"frontmatter":{"index":4000,"targetURL":null,"skipToChild":true,"metaTitle":"Products","metaDescription":"Products"}}},{"node":{"fields":{"id":"0a2bc29c-0df2-59e5-a94c-bce091e6dc6d","slug":"/use-cases","title":"Use Cases"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":true,"metaTitle":"Use Cases","metaDescription":"Use Cases for the Neural Magic Platform"}}},{"node":{"fields":{"id":"c1d1d524-e761-5294-a8e7-e21f3164f48a","slug":"/","title":"Home"},"frontmatter":{"index":0,"targetURL":null,"skipToChild":null,"metaTitle":"Neural Magic Documentation","metaDescription":"Documentation for the Neural Magic Platform"}}},{"node":{"fields":{"id":"a500248d-7a7d-5be6-9c51-ffab9753b5e0","slug":"/user-guides","title":"User Guides"},"frontmatter":{"index":3000,"targetURL":null,"skipToChild":true,"metaTitle":"User Guides","metaDescription":"User Guides"}}},{"node":{"fields":{"id":"cba43102-b32f-5b1a-9c69-f46222a36403","slug":"/user-guides/deepsparse-engine","title":"DeepSparse"},"frontmatter":{"index":4000,"targetURL":null,"skipToChild":null,"metaTitle":"User Guides for DeepSparse Engine","metaDescription":"User Guides for DeepSparse Engine"}}},{"node":{"fields":{"id":"ceb703c1-4adc-510d-95bd-fb316521b486","slug":"/user-guides/deploying-deepsparse","title":"Deploying DeepSparse"},"frontmatter":{"index":5000,"targetURL":null,"skipToChild":null,"metaTitle":"Deploying DeepSparse","metaDescription":"Deploying Deepsparse"}}},{"node":{"fields":{"id":"36031f98-c9cf-5658-b606-b28762ed208f","slug":"/user-guides/onnx-export","title":"ONNX Export"},"frontmatter":{"index":3000,"targetURL":null,"skipToChild":null,"metaTitle":"Exporting to the ONNX Format","metaDescription":"Exporting to the ONNX Format"}}},{"node":{"fields":{"id":"e0110db2-2460-5fd1-8cf7-16533e4ce767","slug":"/user-guides/recipes","title":"Recipes"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":null,"metaTitle":"What are Sparsification Recipes?","metaDescription":"Description of sparsification recipes enabling smaller and more performant neural networks in deep learning"}}},{"node":{"fields":{"id":"d098532a-4bc3-5224-91ca-b51b42b779e7","slug":"/user-guides/sparsification","title":"Sparsification"},"frontmatter":{"index":1000,"targetURL":null,"skipToChild":null,"metaTitle":"What is Sparsification?","metaDescription":"Description of model sparsification enabling smaller and more performant neural networks in deep learning"}}},{"node":{"fields":{"id":"b16b5557-b4f4-5f6a-8c4d-ee3673781d7f","slug":"/user-guides/recipes/enabling","title":"Enabling Pipelines"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":null,"metaTitle":"Enabling Pipelines to Work with SparseML Recipes","metaDescription":"Enabling Pipelines to work with SparseML Recipess"}}},{"node":{"fields":{"id":"b35e8125-4431-5427-bd08-6b379e810c9b","slug":"/user-guides/deploying-deepsparse/aws-lambda","title":"AWS Lambda"},"frontmatter":{"index":3000,"targetURL":null,"skipToChild":null,"metaTitle":"Using DeepSparse on AWS Lambda","metaDescription":"Deploy DeepSparse in a Serverless framework with AWS Lambda"}}},{"node":{"fields":{"id":"2b874d9c-9c67-549d-8c79-b9b261359734","slug":"/user-guides/recipes/creating","title":"Creating"},"frontmatter":{"index":1000,"targetURL":null,"skipToChild":null,"metaTitle":"Creating Sparsification Recipes","metaDescription":"Creating Sparsification Recipes"}}},{"node":{"fields":{"id":"49f60901-1870-5d76-9fcc-12408f802b71","slug":"/user-guides/deploying-deepsparse/amazon-sagemaker","title":"Amazon SageMaker"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":null,"metaTitle":"Deploying With DeepSparse on Amazon SageMaker","metaDescription":"Deploying with DeepSparse on Amazon SageMaker for faster and cheaper model deployments behind an HTTP API"}}},{"node":{"fields":{"id":"5c89e3b2-04e2-59ed-9b42-1c5df17a2df4","slug":"/user-guides/deploying-deepsparse/google-cloud-run","title":"Google Cloud Run"},"frontmatter":{"index":4000,"targetURL":null,"skipToChild":null,"metaTitle":"Using DeepSparse on Google Cloud Run","metaDescription":"Deploy DeepSparse in a Serverless framework with Google Cloud Run"}}},{"node":{"fields":{"id":"115b6c49-fc7b-5dc6-9872-5a690e2b4a25","slug":"/user-guides/deepsparse-engine/benchmarking","title":"Benchmarking"},"frontmatter":{"index":3000,"targetURL":null,"skipToChild":null,"metaTitle":"Benchmarking ONNX Models With DeepSparse","metaDescription":"Benchmarking ONNX models with DeepSparse"}}},{"node":{"fields":{"id":"6085e38d-6a1d-58ac-a6c2-052f8208cf6e","slug":"/user-guides/deepsparse-engine/diagnostics-debugging","title":"Diagnostics/Debugging"},"frontmatter":{"index":4000,"targetURL":null,"skipToChild":null,"metaTitle":"Logging Guidance for Diagnostics and Debugging","metaDescription":"Logging Guidance for Diagnostics and Debugging"}}},{"node":{"fields":{"id":"88604204-656d-5710-a23b-b7cc05eca1de","slug":"/user-guides/deepsparse-engine/hardware-support","title":"Supported Hardware"},"frontmatter":{"index":1000,"targetURL":null,"skipToChild":null,"metaTitle":"Supported Hardware for DeepSparse","metaDescription":"Supported hardware for DeepSparse including CPU types and instruction sets"}}},{"node":{"fields":{"id":"8da43520-8b07-5bcc-a88f-f328137a2270","slug":"/user-guides/deepsparse-engine/logging","title":"DeepSparse Logging"},"frontmatter":{"index":6000,"targetURL":null,"skipToChild":null,"metaTitle":"DeepSparse Logging","metaDescription":"System and Data Logging with DeepSparse"}}},{"node":{"fields":{"id":"86938249-6f57-5091-84c8-9ad393d417b1","slug":"/user-guides/deepsparse-engine/numactl-utility","title":"numactl Utility"},"frontmatter":{"index":5000,"targetURL":null,"skipToChild":null,"metaTitle":"Using the numactl Utility to Control Resource Utilization With DeepSparse","metaDescription":"Using the numactl Utility to Control Resource Utilization With DeepSparse"}}},{"node":{"fields":{"id":"ddada45f-c6b9-5146-91e4-f56c28e31284","slug":"/user-guides/deepsparse-engine/scheduler","title":"Inference Types"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":null,"metaTitle":"Inference Types With DeepSparse Scheduler","metaDescription":"Inference Types with DeepSparse Scheduler"}}},{"node":{"fields":{"id":"113c5c42-984c-53b3-8392-7058bdd946cb","slug":"/use-cases/embedding-extraction","title":"Embedding Extraction"},"frontmatter":{"index":5000,"targetURL":null,"skipToChild":null,"metaTitle":"Embedding Extraction Deployment","metaDescription":"Generalized Embedding Extraction Deployment"}}},{"node":{"fields":{"id":"b7365467-d2b2-5dad-be10-a3aaa773d3a3","slug":"/use-cases/natural-language-processing","title":"Natural Language Processing"},"frontmatter":{"index":1000,"targetURL":null,"skipToChild":true,"metaTitle":"Natural Language Processing","metaDescription":"NLP with HuggingFace Transformers"}}},{"node":{"fields":{"id":"2b513d53-228c-5cf7-9d36-42d82e22cc0b","slug":"/user-guides/deploying-deepsparse/deepsparse-server","title":"DeepSparse Server"},"frontmatter":{"index":1000,"targetURL":null,"skipToChild":null,"metaTitle":"Deploying With DeepSparse Server","metaDescription":"Deploying With DeepSparse Server for faster and cheaper model deployments behind an HTTP API"}}},{"node":{"fields":{"id":"baad04ad-efd7-5e85-8645-6455fce34324","slug":"/use-cases/image-classification","title":"Image Classification"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":true,"metaTitle":"Image Classification","metaDescription":"Image Classification with PyTorch Torchvision"}}},{"node":{"fields":{"id":"1ef7c7c8-073e-5abf-b57a-af03628c0714","slug":"/use-cases/object-detection","title":"Object Detection"},"frontmatter":{"index":3000,"targetURL":null,"skipToChild":true,"metaTitle":"Object Detection","metaDescription":"Object Detection with Ultralytics YOLOv5"}}},{"node":{"fields":{"id":"d1d7a8f3-9061-539a-aff8-d3957da959c6","slug":"/use-cases/object-detection/deploying","title":"Deploying"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":null,"metaTitle":"Object Detection Deployments With DeepSparse","metaDescription":"Object Detection deployments with Ultralytics YOLOv5 and DeepSparse to create cheaper and more performant models"}}},{"node":{"fields":{"id":"d363f68d-8b46-5da1-a1ef-fc14776d0a03","slug":"/use-cases/natural-language-processing/deploying","title":"Deploying"},"frontmatter":{"index":5000,"targetURL":null,"skipToChild":null,"metaTitle":"NLP Deployments with DeepSparse","metaDescription":"NLP deployments with Hugging Face Transformers and DeepSparse to create cheaper and more performant NLP models"}}},{"node":{"fields":{"id":"bd363f12-8b17-5aac-af39-0ae0e7b0b829","slug":"/use-cases/natural-language-processing/question-answering","title":"Question Answering"},"frontmatter":{"index":1000,"targetURL":null,"skipToChild":null,"metaTitle":"NLP Question Answering","metaDescription":"Question Answering with Hugging Face Transformers and SparseML to create cheaper and more performant NLP models"}}},{"node":{"fields":{"id":"3f751c96-1e87-5f4a-a0cb-d277724c2a0b","slug":"/use-cases/object-detection/sparsifying","title":"Sparsifying"},"frontmatter":{"index":1000,"targetURL":null,"skipToChild":null,"metaTitle":"Sparsifying Object Detection With Ultralytics YOLOv5 and SparseML","metaDescription":"Sparsifying Object Detection with Ultralytics YOLOv5 and SparseML to create cheaper and more performant models"}}},{"node":{"fields":{"id":"ae7d3726-718a-5be3-91a4-2559a2445fc4","slug":"/use-cases/natural-language-processing/text-classification","title":"Text Classification"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":null,"metaTitle":"NLP Text Classification","metaDescription":"Text Classification with Hugging Face Transformers and SparseML to create cheaper and more performant NLP models"}}},{"node":{"fields":{"id":"ecaebb25-0fd8-572a-9d98-52302d0a0e4e","slug":"/use-cases/image-classification/sparsifying","title":"Sparsifying"},"frontmatter":{"index":1000,"targetURL":null,"skipToChild":null,"metaTitle":"Sparsifying Image Classification Models With SparseML","metaDescription":"Sparsifying Image Classification models with SparseML to create cheaper and more performant models"}}},{"node":{"fields":{"id":"c3c4bea9-f7cd-5044-9f34-8e33c8d2b36d","slug":"/use-cases/natural-language-processing/token-classification","title":"Token Classification"},"frontmatter":{"index":3000,"targetURL":null,"skipToChild":null,"metaTitle":"NLP Token Classification","metaDescription":"Token Classification with Hugging Face Transformers and SparseML to create cheaper and more performant NLP models"}}},{"node":{"fields":{"id":"3b06a681-3381-5cdc-9dad-827cdc6f60ac","slug":"/use-cases/deploying-deepsparse/docker","title":"Docker"},"frontmatter":{"index":3000,"targetURL":null,"skipToChild":null,"metaTitle":"Using/Creating a DeepSparse Docker Image","metaDescription":"Using/Creating a DeepSparse Docker Image for repeatable build processes"}}},{"node":{"fields":{"id":"4ba00f44-34e5-5677-a8c6-862b44d48e7f","slug":"/products/deepsparse","title":"DeepSparse"},"frontmatter":{"index":0,"targetURL":null,"skipToChild":null,"metaTitle":"DeepSparse","metaDescription":"An inference runtime offering GPU-class performance on CPUs and APIs to integrate ML into your application"}}},{"node":{"fields":{"id":"76657780-4f8a-5f37-8f3c-1c6c04637503","slug":"/products/sparseml","title":"SparseML"},"frontmatter":{"index":1000,"targetURL":null,"skipToChild":null,"metaTitle":"SparseML","metaDescription":"Sparsity-aware neural network inference engine for GPU-class performance on CPUs"}}},{"node":{"fields":{"id":"08d07abb-4c37-5f58-8bdd-277facdeaf05","slug":"/products/sparsezoo/cli","title":"CLI"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":null,"metaTitle":"SparseML CLI","metaDescription":"Documentation for the CLI commands installed with SparseZoo enabling use of SOTA sparsified models and recipes"}}},{"node":{"fields":{"id":"0d031520-ee95-58db-bdb3-86689d6a0941","slug":"/use-cases/image-classification/deploying","title":"Deploying"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":null,"metaTitle":"Image Classification Deployments With DeepSparse","metaDescription":"Image classification deployments with DeepSparse to create cheaper and more performant models"}}},{"node":{"fields":{"id":"aafbc5b1-5291-5291-ab86-da09c479a4c1","slug":"/products/sparsezoo/python-api","title":"Python API"},"frontmatter":{"index":3000,"targetURL":null,"skipToChild":null,"metaTitle":"SparseML Python API","metaDescription":"Documentation for the Python APIs available with SparseZoo enabling use of SOTA sparsified models and recipes"}}},{"node":{"fields":{"id":"97cb8313-bc03-5a24-bf92-015086fc9071","slug":"/products/sparsezoo/models","title":"Models"},"frontmatter":{"index":1000,"targetURL":"https://sparsezoo.neuralmagic.com/","skipToChild":null,"metaTitle":"Models","metaDescription":"Models"}}},{"node":{"fields":{"id":"b6a850d0-afc3-5418-ae82-146d2cb68706","slug":"/products/sparseml/cli","title":"CLI"},"frontmatter":{"index":1000,"targetURL":null,"skipToChild":null,"metaTitle":"SparseML CLI","metaDescription":"Documentation for the CLI commands installed with SparseML enabling SOTA model sparsification"}}},{"node":{"fields":{"id":"018cd1d6-6542-547d-ac3b-2743f179ac04","slug":"/products/sparseml/python-api","title":"Python API"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":null,"metaTitle":"SparseML Python API","metaDescription":"Documentation for the Python APIs available with SparseML enabling SOTA model sparsification"}}},{"node":{"fields":{"id":"233b31f0-deac-5b52-9101-caf3e3474595","slug":"/products/deepsparse/community","title":"DeepSparse Community"},"frontmatter":{"index":1000,"targetURL":null,"skipToChild":null,"metaTitle":"DeepSparse Community","metaDescription":"An inference runtime offering GPU-class performance on CPUs and APIs to integrate ML into your application"}}},{"node":{"fields":{"id":"d79d91ee-f596-5f3a-aafd-02c85a389909","slug":"/products/deepsparse/enterprise","title":"DeepSparse Enterprise"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":null,"metaTitle":"DeepSparse Enterprise","metaDescription":"An inference runtime offering GPU-class performance on CPUs and APIs to integrate ML into your application"}}},{"node":{"fields":{"id":"e3c4460c-c09f-5838-8047-fea6cf8f0511","slug":"/products/deepsparse/enterprise/cli","title":"CLI"},"frontmatter":{"index":1000,"targetURL":null,"skipToChild":null,"metaTitle":"DeepSparse CLI","metaDescription":"Documentation for the CLI commands installed with DeepSparse enabling GPU-class performance on CPUs"}}},{"node":{"fields":{"id":"d6bf031b-89e2-5374-9997-1676f340f25a","slug":"/products/deepsparse/enterprise/cpp-api","title":"C++ API"},"frontmatter":{"index":3000,"targetURL":null,"skipToChild":null,"metaTitle":"DeepSparse C++ API","metaDescription":"Documentation for the C++ APIs available with DeepSparse enabling GPU-class performance on CPUs"}}},{"node":{"fields":{"id":"5e0531ff-a237-587a-a318-72f000810bb0","slug":"/products/deepsparse/enterprise/python-api","title":"Python API"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":null,"metaTitle":"DeepSparse Python API","metaDescription":"Documentation for the Python APIs available with DeepSparse enabling GPU-class performance on CPUs"}}},{"node":{"fields":{"id":"b386abe1-47d1-5b57-aa77-a3f73f3ebe21","slug":"/products/deepsparse/community/cli","title":"CLI"},"frontmatter":{"index":1000,"targetURL":null,"skipToChild":null,"metaTitle":"DeepSparse CLI","metaDescription":"Documentation for the CLI commands installed with DeepSparse enabling GPU-class performance on CPUs"}}},{"node":{"fields":{"id":"f92e631d-dc67-592a-b7c2-dd4bb5e7a3fe","slug":"/products/deepsparse/community/cpp-api","title":"C++ API"},"frontmatter":{"index":3000,"targetURL":null,"skipToChild":null,"metaTitle":"DeepSparse C++ API","metaDescription":"Documentation for the C++ APIs available with DeepSparse enabling GPU-class performance on CPUs"}}},{"node":{"fields":{"id":"0d2bd4a5-a7f1-508a-8652-91e3eed40ceb","slug":"/products/deepsparse/community/python-api","title":"Python API"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":null,"metaTitle":"DeepSparse Python API","metaDescription":"Documentation for the Python APIs available with DeepSparse enabling GPU-class performance on CPUs"}}},{"node":{"fields":{"id":"4491ba6b-e373-50e3-a8b5-e8e173ecba81","slug":"/index/deploy-workflow","title":"Deploy on CPUs"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":null,"metaTitle":"Deploy on CPUs","metaDescription":"Overview of deployment capabilities in the Neural Magic Platform"}}},{"node":{"fields":{"id":"27a0b7a5-09e0-56ab-9ee5-68f45d8795fd","slug":"/index/optimize-workflow","title":"Optimize for Inference"},"frontmatter":{"index":1000,"targetURL":null,"skipToChild":null,"metaTitle":"Optimize for Inference","metaDescription":"Overview of deployment capabilities in the Neural Magic Platform"}}},{"node":{"fields":{"id":"478d6817-c021-5181-922d-2689a65470c5","slug":"/index/quick-tour","title":"Quick Tour"},"frontmatter":{"index":3000,"targetURL":null,"skipToChild":null,"metaTitle":"Quick Tour","metaDescription":"Quick tour of the available functionality"}}},{"node":{"fields":{"id":"665dac23-0ae5-5037-a151-d359bad8f8c2","slug":"/get-started/deploy-a-model","title":"Deploy a Model"},"frontmatter":{"index":5000,"targetURL":null,"skipToChild":null,"metaTitle":"Deploy a Model","metaDescription":"Deploy a model with DeepSparse Server for easy and performant ML deployments"}}},{"node":{"fields":{"id":"cc2c9b73-3a5b-5764-ad54-38c919cb3e78","slug":"/get-started/install","title":"Installation"},"frontmatter":{"index":0,"targetURL":null,"skipToChild":null,"metaTitle":"Install Neural Magic Platform","metaDescription":"Installation instructions for the Neural Magic Platform including DeepSparse, SparseML, SparseZoo"}}},{"node":{"fields":{"id":"43a5dd03-4ffe-5c02-ac47-7ee94de63602","slug":"/get-started/sparsify-a-model","title":"Sparsify a Model"},"frontmatter":{"index":4000,"targetURL":null,"skipToChild":null,"metaTitle":"Sparsify a Model","metaDescription":"Sparsify a model with SparseML and recipes for smaller, faster, and cheaper model inferences in deployment"}}},{"node":{"fields":{"id":"fb19b2bb-688f-5f4e-98e0-d1dbf478a015","slug":"/get-started/transfer-a-sparsified-model","title":"Transfer a Sparsified Model"},"frontmatter":{"index":3000,"targetURL":null,"skipToChild":null,"metaTitle":"Transfer a Sparsified Model","metaDescription":"Transfer a Sparsified Model to your dataset, enabling performant deep learning deployments with limited training"}}},{"node":{"fields":{"id":"5ba330af-8819-52cd-8818-2374113da636","slug":"/get-started/use-a-model","title":"Use a Model"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":null,"metaTitle":"Use a Model","metaDescription":"Use a Model with DeepSparse to deploy for faster and cheaper inference on CPUs"}}},{"node":{"fields":{"id":"00c56759-713b-5731-92b9-027dab853257","slug":"/get-started/use-a-model/custom-use-case","title":"Custom Use Case"},"frontmatter":{"index":3000,"targetURL":null,"skipToChild":null,"metaTitle":"Use a Custom Use Case","metaDescription":"Use a Custom Use Case and Model with DeepSparse to deploy for faster and cheaper inference on CPUs"}}},{"node":{"fields":{"id":"5689a5f7-7564-5b91-b21d-0f6aed1218a9","slug":"/get-started/use-a-model/cv-object-detection","title":"CV Object Detection"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":null,"metaTitle":"Use an Object Detection Model","metaDescription":"Use an Object Detection Model with DeepSparse to deploy for faster and cheaper inference on CPUs"}}},{"node":{"fields":{"id":"3bd4ca0d-2d04-5d9f-9037-06f9ae7dfb73","slug":"/get-started/transfer-a-sparsified-model/cv-object-detection","title":"CV Object Detection"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":null,"metaTitle":"Transfer a Sparsified Model for Object Detection","metaDescription":"Transfer a Sparsified Object Detection Model to your dataset enabling performant deep learning deployments in a faster amount of time"}}},{"node":{"fields":{"id":"4ac6dd90-ac18-5c3c-8c85-06021527df5e","slug":"/get-started/use-a-model/nlp-text-classification","title":"NLP Text Classification"},"frontmatter":{"index":1000,"targetURL":null,"skipToChild":null,"metaTitle":"Use a Text Classification Model","metaDescription":"Use a NLP Text Classification Model with DeepSparse for faster and cheaper inference on CPUs"}}},{"node":{"fields":{"id":"c32bcbda-4c9f-5b2a-b18d-5083b0003aef","slug":"/get-started/transfer-a-sparsified-model/nlp-text-classification","title":"NLP Text Classification"},"frontmatter":{"index":1000,"targetURL":null,"skipToChild":null,"metaTitle":"Transfer a Sparsified Model for Text Classification","metaDescription":"Transfer a Sparsified NLP Model to your sentiment analysis dataset enabling performant deep learning deployments with limited training"}}},{"node":{"fields":{"id":"6662f291-f43f-5616-8f60-dea883911f57","slug":"/get-started/sparsify-a-model/custom-integrations","title":"Custom Integrations"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":null,"metaTitle":"Creating a Custom Integration for Sparsifying Models","metaDescription":"Creating a Custom Integration for Sparsifying Models with SparseML for smaller, faster, and cheaper model inferences in deployment"}}},{"node":{"fields":{"id":"8323781e-a7b4-5bb5-a453-86e2c472d6cf","slug":"/get-started/install/deepsparse-ent","title":"DeepSparse Enterprise"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":null,"metaTitle":"DeepSparse Enterprise Installation","metaDescription":"Installation instructions for DeepSparse enabling performant neural network deployments"}}},{"node":{"fields":{"id":"8efaf662-8889-5bc3-bcae-9868aaa8aa53","slug":"/get-started/sparsify-a-model/supported-integrations","title":"Supported Integrations"},"frontmatter":{"index":1000,"targetURL":null,"skipToChild":null,"metaTitle":"Sparsifying a Model for SparseML Integrations","metaDescription":"Sparsify a model with SparseML and recipes for smaller, faster, and cheaper model inferences in deployment"}}},{"node":{"fields":{"id":"be1fa4d5-bae3-5c19-9da5-f56a08f2fa40","slug":"/products/sparsezoo","title":"SparseZoo"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":null,"metaTitle":"SparseZoo","metaDescription":"Neural network model repository for highly sparse and sparse-quantized models with matching sparsification recipes"}}},{"node":{"fields":{"id":"ac411c38-91fa-56bf-8dfd-c00cab6602ad","slug":"/get-started/install/sparsezoo","title":"SparseZoo"},"frontmatter":{"index":4000,"targetURL":null,"skipToChild":null,"metaTitle":"SparseZoo Installation","metaDescription":"Installation instructions for the SparseZoo sparse model repository"}}},{"node":{"fields":{"id":"5cebfec6-69f9-59bb-9a47-58bd80ce5b29","slug":"/get-started/install/deepsparse","title":"DeepSparse Community"},"frontmatter":{"index":1000,"targetURL":null,"skipToChild":null,"metaTitle":"DeepSparse Community Installation","metaDescription":"Installation instructions for DeepSparse enabling performant neural network deployments"}}},{"node":{"fields":{"id":"dc9f9ab1-1fb3-57b4-910a-fa3200519b0d","slug":"/get-started/install/sparseml","title":"SparseML"},"frontmatter":{"index":3000,"targetURL":null,"skipToChild":null,"metaTitle":"SparseML Installation","metaDescription":"Installation instructions for SparseML neural network optimization, training, and sparsification"}}},{"node":{"fields":{"id":"a597113f-8c9b-5620-baaa-95555edb534c","slug":"/details/faqs","title":"FAQs"},"frontmatter":{"index":4000,"targetURL":null,"skipToChild":null,"metaTitle":"FAQs","metaDescription":"FAQs for the Neural Magic Platform"}}},{"node":{"fields":{"id":"7d12ac36-8c45-565c-9b28-6472fdeb4a99","slug":"/get-started/deploy-a-model/nlp-text-classification","title":"NLP Text Classification"},"frontmatter":{"index":1000,"targetURL":null,"skipToChild":null,"metaTitle":"Deploy a Text Classification Model","metaDescription":"Deploy a text classification model with DeepSparse Server for easier, faster, and cheaper inference on CPUs"}}},{"node":{"fields":{"id":"f2d385fc-cb79-5c11-8873-f4e6f6d6da23","slug":"/details/glossary","title":"Glossary"},"frontmatter":{"index":3000,"targetURL":null,"skipToChild":null,"metaTitle":"Glossary","metaDescription":"Glossary for the Neural Magic product"}}},{"node":{"fields":{"id":"02f4ebab-32cf-58e1-a39b-db269f740d8b","slug":"/get-started/deploy-a-model/cv-object-detection","title":"CV Object Detection"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":null,"metaTitle":"Deploy an Object Detection Model","metaDescription":"Deploy an object detection model with DeepSparse Server for easier, faster, and cheaper inference on CPUs"}}},{"node":{"fields":{"id":"e5f9763e-9c0a-5d84-9f65-550685441793","slug":"/details/research-papers","title":"Research Papers"},"frontmatter":{"index":1000,"targetURL":"https://neuralmagic.com/resources/technical-papers/","skipToChild":null,"metaTitle":"Research Papers","metaDescription":"Research Papers"}}}]}},"pageContext":{"id":"d1d7a8f3-9061-539a-aff8-d3957da959c6","pageType":"docs"}},"staticQueryHashes":[]}