{"componentChunkName":"component---src-root-jsx","path":"/products/sparseml","result":{"data":{"site":{"siteMetadata":{"title":null,"docsLocation":"https://docs.neuralmagic.com"}},"mdx":{"fields":{"id":"76657780-4f8a-5f37-8f3c-1c6c04637503","title":"SparseML","slug":"/products/sparseml","githubURL":"https://github.com/neuralmagic/docs/blob/main/src/content/products/sparseml.mdx"},"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"SparseML\",\n  \"metaTitle\": \"SparseML\",\n  \"metaDescription\": \"Sparsity-aware neural network inference engine for GPU-class performance on CPUs\",\n  \"index\": 1000\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", null, \"SparseML\"), mdx(\"h3\", null, \"Libraries enabling creation of sparse deep-neural networks trained on your data with just a few lines of code\"), mdx(\"p\", null, \"\\n  \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://docs.neuralmagic.com/sparseml/\"\n  }, \"\\n    \", mdx(\"img\", {\n    parentName: \"a\",\n    \"alt\": \"Documentation\",\n    \"src\": \"https://img.shields.io/badge/documentation-darkred?&style=for-the-badge&logo=read-the-docs\",\n    \"height\": \"{25}\"\n  }), \"\\n  \"), \"\\n  \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://join.slack.com/t/discuss-neuralmagic/shared_invite/zt-q1a1cnvo-YBoICSIw3L1dmQpjBeDurQ/\"\n  }, \"\\n    \", mdx(\"img\", {\n    parentName: \"a\",\n    \"src\": \"https://img.shields.io/badge/slack-purple?style=for-the-badge&logo=slack\",\n    \"height\": \"{25}\"\n  }), \"\\n  \"), \"\\n  \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/issues\"\n  }, \"\\n    \", mdx(\"img\", {\n    parentName: \"a\",\n    \"src\": \"https://img.shields.io/badge/support%20forums-navy?style=for-the-badge&logo=github\",\n    \"height\": \"{25}\"\n  }), \"\\n  \"), \"\\n  \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/actions/workflows/test-check.yaml\"\n  }, \"\\n    \", mdx(\"img\", {\n    parentName: \"a\",\n    \"alt\": \"Main\",\n    \"src\": \"https://img.shields.io/github/workflow/status/neuralmagic/sparseml/Test%20Checks/main?label=build&style=for-the-badge\",\n    \"height\": \"{25}\"\n  }), \"\\n  \"), \"\\n  \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/releases\"\n  }, \"\\n    \", mdx(\"img\", {\n    parentName: \"a\",\n    \"alt\": \"GitHub release\",\n    \"src\": \"https://img.shields.io/github/release/neuralmagic/sparseml.svg?style=for-the-badge\",\n    \"height\": \"{25}\"\n  }), \"\\n  \"), \"\\n  \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/blob/main/LICENSE\"\n  }, \"\\n    \", mdx(\"img\", {\n    parentName: \"a\",\n    \"alt\": \"GitHub\",\n    \"src\": \"https://img.shields.io/github/license/neuralmagic/sparseml.svg?color=lightgray&style=for-the-badge\",\n    \"height\": \"{25}\"\n  }), \"\\n  \"), \"\\n  \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/blob/main/CODE_OF_CONDUCT.md\"\n  }, \"\\n    \", mdx(\"img\", {\n    parentName: \"a\",\n    \"alt\": \"Contributor Covenant\",\n    \"src\": \"https://img.shields.io/badge/Contributor%20Covenant-v2.1%20adopted-ff69b4.svg?color=yellow&style=for-the-badge\",\n    \"height\": \"{25}\"\n  }), \"\\n  \"), \"\\n  \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.youtube.com/channel/UCo8dO_WMGYbWCRnj_Dxr4EA\"\n  }, \"\\n    \", mdx(\"img\", {\n    parentName: \"a\",\n    \"src\": \"https://img.shields.io/badge/-YouTube-red?&style=for-the-badge&logo=youtube&logoColor=white\",\n    \"height\": \"{25}\"\n  }), \"\\n  \"), \"\\n  \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://medium.com/limitlessai\"\n  }, \"\\n    \", mdx(\"img\", {\n    parentName: \"a\",\n    \"src\": \"https://img.shields.io/badge/medium-%2312100E.svg?&style=for-the-badge&logo=medium&logoColor=white\",\n    \"height\": \"{25}\"\n  }), \"\\n  \"), \"\\n  \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://twitter.com/neuralmagic\"\n  }, \"\\n    \", mdx(\"img\", {\n    parentName: \"a\",\n    \"src\": \"https://img.shields.io/twitter/follow/neuralmagic?color=darkgreen&label=Follow&style=social\",\n    \"height\": \"{25}\"\n  }), \"\\n  \"), \"\\n\"), mdx(\"h2\", null, \"Overview\"), mdx(\"p\", null, \"SparseML is an open-source model optimization toolkit that enables you to create inference-optimized sparse models using pruning, quantization, and distillation algorithms. Models optimized with SparseML can then be exported to the ONNX and deployed with \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/neuralmagic/deepsparse/\"\n  }, \"DeepSparse\"), \" for GPU-class performance on CPU hardware.\"), mdx(\"h2\", null, \"Workflows\"), mdx(\"p\", null, \"SparseML enables you to create a sparse model trained on your dataset in two ways:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Sparse Transfer Learning\"), \" enables you to fine-tune a pre-sparsified model from \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://sparsezoo.neuralmagic.com/\"\n  }, \"SparseZoo\"), \" (an open-source repository of sparse models such as BERT, YOLOv5, and ResNet-50) onto your dataset, while maintaining sparsity. This pathway works just like typical fine-tuning you are used to in training CV and NLP models, and is strongly preferred for if your model architecture is availble in SparseZoo.\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Sparsification from Scratch\"), \" enables you to apply state-of-the-art pruning (like gradual magnitude pruning or OBS pruning) and quantization (like quantization aware training) algorithms to arbitrary PyTorch and Hugging Face models. This pathway requires more experimentation, but allows you to create a sparse version of any model. \"))), mdx(\"h2\", null, \"Integrations\"), mdx(\"p\", null, \"\\n    \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/blob/main/integrations/torchvision\"\n  }, \"\\n        \", mdx(\"img\", {\n    parentName: \"a\",\n    \"src\": \"https://docs.neuralmagic.com/docs/source/highlights/sparseml/pytorch-torchvision.png\",\n    \"width\": \"136px\"\n  }), \"\\n    \"), \"\\n    \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/blob/main/integrations/ultralytics-yolov5\"\n  }, \"\\n        \", mdx(\"img\", {\n    parentName: \"a\",\n    \"src\": \"https://docs.neuralmagic.com/docs/source/highlights/sparseml/ultralytics-yolov5.png\",\n    \"width\": \"136px\"\n  }), \"\\n    \"), \"\\n    \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/blob/main/integrations/huggingface-transformers\"\n  }, \"\\n        \", mdx(\"img\", {\n    parentName: \"a\",\n    \"src\": \"https://docs.neuralmagic.com/docs/source/highlights/sparseml/huggingface-transformers.png\",\n    \"width\": \"136px\"\n  }), \"\\n    \"), \"\\n\"), mdx(\"h2\", null, \"Tutorials\"), mdx(\"h3\", null, \"PyTorch\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/blob/main/integrations/torchvision/tutorials/sparse-transfer-learning.md\"\n  }, \"Sparse Transfer Learning with the CLI\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/blob/main/integrations/torchvision/tutorials/docs-torchvision-python-transfer-imagenette.ipynb\"\n  }, \"Sparse Transfer Learning with the Python API\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/blob/main/integrations/torchvision/tutorials/docs-torchvision-sparsify-from-scratch-resnet50-beans.ipynb\"\n  }, \"Sparsify From Scratch with the Python API\"))), mdx(\"h3\", null, \"Hugging Face Transformers\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/blob/main/integrations/huggingface-transformers/tutorials/sparse-transfer-learning-bert-python.md\"\n  }, \"Sparse Transfer Learning Overview with the Python API\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/blob/main/integrations/huggingface-transformers/tutorials/sparse-transfer-learning-bert.md\"\n  }, \"Sparse Transfer Learning Overview with the CLI\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/blob/main/integrations/huggingface-transformers/tutorials/sentiment-analysis/sentiment-analysis-cli.md\"\n  }, \"Sparse Transfer Learning for Sentiment Analysis\"), \", \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/blob/main/integrations/huggingface-transformers/tutorials/text-classification/text-classification-cli.md\"\n  }, \"for Text Classification\"), \", \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/blob/main/integrations/huggingface-transformers/tutorials/token-classification/token-classification-cli.md\"\n  }, \"for Token Classification\"), \", \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/blob/main/integrations/huggingface-transformers/tutorials/question-answering/question-answering-cli.md\"\n  }, \"for Question Answering\"))), mdx(\"h3\", null, \"Ultralytics YOLOv5\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/blob/main/integrations/ultralytics-yolov5/tutorials/sparse-transfer-learning.md\"\n  }, \"Sparse Transfer Learning with the CLI\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/blob/main/integrations/ultralytics-yolov5/tutorials/sparsify-from-scratch.md\"\n  }, \"Sparsify From Scatch with the CLI\"))), mdx(\"h3\", null, \"Links to Additional Examples\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/blob/main/integrations/torchvision#tutorials\"\n  }, \"PyTorch\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/blob/main/integrations/huggingface-transformers#tutorials\"\n  }, \"Hugging Face Transformers\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/blob/main/integrations/ultralytics-yolov5#tutorials\"\n  }, \"Ultralytics YOLOv5\"))), mdx(\"h2\", null, \"Installation Requirements\"), mdx(\"p\", null, \"This repository is tested on Python 3.7-3.10, and Linux/Debian systems.\"), mdx(\"p\", null, \"It is recommended to install in a \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://docs.python.org/3/library/venv.html\"\n  }, \"virtual environment\"), \" to keep your system in order.\\nCurrently supported ML Frameworks are the following: \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"torch>=1.1.0,<=1.12.1\"), \", excluding \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"1.10\"), \" and \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"1.11\"), \".\"), mdx(\"p\", null, \"Install with pip using:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-bash\"\n  }, \"pip install sparseml\\n\")), mdx(\"p\", null, \"More information on installation such as optional dependencies and requirements can be found \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://docs.neuralmagic.com/get-started/install/sparseml\"\n  }, \"here\"), \".\"), mdx(\"h2\", null, \"Quick Tour\"), mdx(\"h3\", null, \"Recipes\"), mdx(\"p\", null, \"To enable flexibility, ease of use, and repeatability, SparseML uses a declarative interface called \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"recipes\"), \" for specifying the sparsity-related algorithms and hyperparamters that should be applied by SparseML.\"), mdx(\"p\", null, mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"Recipes\"), \" are YAML-files formatted as a list of \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"modifiers\"), \", which encode the instructions for SparseML. Example \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"modifiers\"), \" can be anything from setting the learning rate to encoding the hyperparameters of the gradual magnitude pruning algorithm. The SparseML system parses the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"recipes\"), \" into a native format for each framework and applies the modifications to the model and training pipeline.\"), mdx(\"h3\", null, \"Python API\"), mdx(\"p\", null, \"Because of the declarative, recipe-based approach, you can add SparseML to your existing PyTorch traing pipelines. The \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"ScheduleModifierManager\"), \" class is responsible for parsing the YAML \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"recipes\"), \" and overriding standard PyTorch model and optimizer objects, encoding the logic of the sparsity algorithms from the recipe. Once you call \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"manager.modify\"), \", you can then use the model and optimizer as usual, as SparseML abstracts away the complexity of the sparsification algorithms.\"), mdx(\"p\", null, \"The workflow looks like this:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"model = Model()            # model definition\\noptimizer = Optimizer()    # optimizer definition\\ntrain_data = TrainData()   # train data definition\\nbatch_size = BATCH_SIZE    # training batch size\\nsteps_per_epoch = len(train_data) # batch_size\\n\\nfrom sparseml.pytorch.optim import ScheduledModifierManager\\nmanager = ScheduledModifierManager.from_yaml(PATH_TO_RECIPE)\\noptimizer = manager.modify(model, optimizer, steps_per_epoch)\\n\\n# typical PyTorch training loop, using your model/optimizer as usual\\n\\nmanager.finalize(model)\\n\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Check out the \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/blob/main/integrations/torchvision\"\n  }, \"PyTorch integration docs\"), \" for full usage examples of the Python API.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Check out the \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/blob/main/integrations/huggingface-transformers\"\n  }, \"Hugging Face integration docs\"), \" for details of using SparseML with the Hugging Face \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"Trainer\"), \".\")), mdx(\"h3\", null, \"SparseML CLI\"), mdx(\"p\", null, \"In addition to the code-level API, SparseML offers pre-made training pipelines for common NLP and CV tasks via the CLI interface. The CLI enables you to kick-off training runs with various utilities like dataset loading and pre-processing, checkpoint saving, metric reporting, and logging handled for you. This makes it easy to get up and running in common training pathways.\"), mdx(\"p\", null, \"For instance, we can use the following to kick off a YOLOv5 sparse transfer learning run onto the VOC dataset (using SparseZoo stubs to pull down a sparse model checkpoint and transfer learning recipe):\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-bash\"\n  }, \"sparseml.yolov5.train \\\\\\n  --weights zoo:cv/detection/yolov5-s/pytorch/ultralytics/coco/pruned85_quant-none?recipe_type=transfer_learn \\\\\\n  --recipe zoo:cv/detection/yolov5-s/pytorch/ultralytics/coco/pruned85_quant-none?recipe_type=transfer_learn \\\\\\n  --data VOC.yaml \\\\\\n  --hyp hyps/hyp.finetune.yaml --cfg yolov5s.yaml --patience 0\\n\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Check out the \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/blob/main/integrations/ultralytics-yolov5/tutorials/sparse-transfer-learning.md\"\n  }, \"YOLOv5 CLI example\"), \" for more details on the YOLOv5 training pipeline\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Check out the \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/blob/main/integrations/huggingface-transformers/tutorials/sparse-transfer-learning-bert.md\"\n  }, \"Hugging Face CLI example\"), \" for more details on the available NLP training pipelines\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Check out the \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/blob/main/integrations/torchvision/tutorials/sparse-transfer-learning.md\"\n  }, \"Torchvision CLI example\"), \" for more details on the image classification training pipelines\")), mdx(\"h3\", null, \"Additional Resources\"), mdx(\"p\", null, \"More information on the code base and contained processes can be found in the SparseML documentation:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/get-started/transfer-a-sparsified-model\"\n  }, \"Sparse Transfer Learning\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/get-started/sparsify-a-model\"\n  }, \"Sparsification Code\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/user-guides/recipes\"\n  }, \"Sparsification Recipes\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/user-guides/sparsification\"\n  }, \"Exporting to ONNX\"))), mdx(\"h2\", null, \"Resources\"), mdx(\"h3\", null, \"Learning More\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Documentation: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://docs.neuralmagic.com/sparseml/\"\n  }, \"SparseML,\"), \" \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://docs.neuralmagic.com/sparsezoo/\"\n  }, \"SparseZoo,\"), \" \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://docs.neuralmagic.com/sparsify/\"\n  }, \"Sparsify,\"), \" \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://docs.neuralmagic.com/deepsparse/\"\n  }, \"DeepSparse\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Neural Magic: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.neuralmagic.com/blog/\"\n  }, \"Blog,\"), \" \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.neuralmagic.com/resources/\"\n  }, \"Resources\"))), mdx(\"h3\", null, \"Release History\"), mdx(\"p\", null, \"Official builds are hosted on PyPI\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"stable: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://pypi.org/project/sparseml/\"\n  }, \"sparseml\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"nightly (dev): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://pypi.org/project/sparseml-nightly/\"\n  }, \"sparseml-nightly\"))), mdx(\"p\", null, \"Additionally, more information can be found via \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/releases\"\n  }, \"GitHub Releases.\")), mdx(\"h3\", null, \"License\"), mdx(\"p\", null, \"The project is licensed under the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/blob/main/LICENSE\"\n  }, \"Apache License Version 2.0.\")), mdx(\"h2\", null, \"Community\"), mdx(\"h3\", null, \"Contribute\"), mdx(\"p\", null, \"We appreciate contributions to the code, examples, integrations, and documentation as well as bug reports and feature requests! \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/blob/main/CONTRIBUTING.md\"\n  }, \"Learn how here.\")), mdx(\"h3\", null, \"Join\"), mdx(\"p\", null, \"For user help or questions about SparseML, sign up or log in to our \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://join.slack.com/t/discuss-neuralmagic/shared_invite/zt-q1a1cnvo-YBoICSIw3L1dmQpjBeDurQ\"\n  }, mdx(\"strong\", {\n    parentName: \"a\"\n  }, \"Neural Magic Community Slack\")), \". We are growing the community member by member and happy to see you there. Bugs, feature requests, or additional questions can also be posted to our \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/issues\"\n  }, \"GitHub Issue Queue.\")), mdx(\"p\", null, \"You can get the latest news, webinar and event invites, research papers, and other ML Performance tidbits by \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://neuralmagic.com/subscribe/\"\n  }, \"subscribing\"), \" to the Neural Magic community.\"), mdx(\"p\", null, \"For more general questions about Neural Magic, please fill out this \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://neuralmagic.com/contact/\"\n  }, \"form.\")), mdx(\"h3\", null, \"Cite\"), mdx(\"p\", null, \"Find this project useful in your research or other communications? Please consider citing:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-bibtex\"\n  }, \"@InProceedings{\\n    pmlr-v119-kurtz20a, \\n    title = {Inducing and Exploiting Activation Sparsity for Fast Inference on Deep Neural Networks}, \\n    author = {Kurtz, Mark and Kopinsky, Justin and Gelashvili, Rati and Matveev, Alexander and Carr, John and Goin, Michael and Leiserson, William and Moore, Sage and Nell, Bill and Shavit, Nir and Alistarh, Dan}, \\n    booktitle = {Proceedings of the 37th International Conference on Machine Learning}, \\n    pages = {5533--5543}, \\n    year = {2020}, \\n    editor = {Hal Daum\\xE9 III and Aarti Singh}, \\n    volume = {119}, \\n    series = {Proceedings of Machine Learning Research}, \\n    address = {Virtual}, \\n    month = {13--18 Jul}, \\n    publisher = {PMLR}, \\n    pdf = {http://proceedings.mlr.press/v119/kurtz20a/kurtz20a.pdf},\\n    url = {http://proceedings.mlr.press/v119/kurtz20a.html}, \\n    abstract = {Optimizing convolutional neural networks for fast inference has recently become an extremely active area of research. One of the go-to solutions in this context is weight pruning, which aims to reduce computational and memory footprint by removing large subsets of the connections in a neural network. Surprisingly, much less attention has been given to exploiting sparsity in the activation maps, which tend to be naturally sparse in many settings thanks to the structure of rectified linear (ReLU) activation functions. In this paper, we present an in-depth analysis of methods for maximizing the sparsity of the activations in a trained neural network, and show that, when coupled with an efficient sparse-input convolution algorithm, we can leverage this sparsity for significant performance gains. To induce highly sparse activation maps without accuracy loss, we introduce a new regularization technique, coupled with a new threshold-based sparsification method based on a parameterized activation function called Forced-Activation-Threshold Rectified Linear Unit (FATReLU). We examine the impact of our methods on popular image classification models, showing that most architectures can adapt to significantly sparser activation maps without any accuracy loss. Our second contribution is showing that these these compression gains can be translated into inference speedups: we provide a new algorithm to enable fast convolution operations over networks with sparse activations, and show that it can enable significant speedups for end-to-end inference on a range of popular models on the large-scale ImageNet image classification task on modern Intel CPUs, with little or no retraining cost.} \\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-bibtex\"\n  }, \"@misc{\\n    singh2020woodfisher,\\n    title={WoodFisher: Efficient Second-Order Approximation for Neural Network Compression}, \\n    author={Sidak Pal Singh and Dan Alistarh},\\n    year={2020},\\n    eprint={2004.14340},\\n    archivePrefix={arXiv},\\n    primaryClass={cs.LG}\\n}\\n\")));\n}\n;\nMDXContent.isMDXComponent = true;","tableOfContents":{"items":[{"url":"#sparseml","title":"SparseML","items":[{"items":[{"url":"#libraries-enabling-creation-of-sparse-deep-neural-networks-trained-on-your-data-with-just-a-few-lines-of-code","title":"Libraries enabling creation of sparse deep-neural networks trained on your data with just a few lines of code"}]},{"url":"#overview","title":"Overview"},{"url":"#workflows","title":"Workflows"},{"url":"#integrations","title":"Integrations"},{"url":"#tutorials","title":"Tutorials","items":[{"url":"#pytorch","title":"PyTorch"},{"url":"#hugging-face-transformers","title":"Hugging Face Transformers"},{"url":"#ultralytics-yolov5","title":"Ultralytics YOLOv5"},{"url":"#links-to-additional-examples","title":"Links to Additional Examples"}]},{"url":"#installation-requirements","title":"Installation Requirements"},{"url":"#quick-tour","title":"Quick Tour","items":[{"url":"#recipes","title":"Recipes"},{"url":"#python-api","title":"Python API"},{"url":"#sparseml-cli","title":"SparseML CLI"},{"url":"#additional-resources","title":"Additional Resources"}]},{"url":"#resources","title":"Resources","items":[{"url":"#learning-more","title":"Learning More"},{"url":"#release-history","title":"Release History"},{"url":"#license","title":"License"}]},{"url":"#community","title":"Community","items":[{"url":"#contribute","title":"Contribute"},{"url":"#join","title":"Join"},{"url":"#cite","title":"Cite"}]}]}]},"parent":{"relativePath":"products/sparseml.mdx"},"frontmatter":{"metaTitle":"SparseML","metaDescription":"Sparsity-aware neural network inference engine for GPU-class performance on CPUs","index":1000,"skipToChild":null}},"allMdx":{"edges":[{"node":{"fields":{"id":"220abd27-24cf-5408-9402-3e7b0591a7ec","slug":"/details","title":"Details"},"frontmatter":{"index":5000,"targetURL":null,"skipToChild":true,"metaTitle":"Details","metaDescription":"Details"}}},{"node":{"fields":{"id":"bfcfecba-6eb1-59e8-8379-9c6d0c7a6a46","slug":"/get-started","title":"Get Started"},"frontmatter":{"index":1000,"targetURL":null,"skipToChild":true,"metaTitle":"Get Started","metaDescription":"Getting started with the Neural Magic Platform"}}},{"node":{"fields":{"id":"ee9f8c1f-d776-5134-89e6-b60f31e11b65","slug":"/products","title":"Products"},"frontmatter":{"index":4000,"targetURL":null,"skipToChild":true,"metaTitle":"Products","metaDescription":"Products"}}},{"node":{"fields":{"id":"0a2bc29c-0df2-59e5-a94c-bce091e6dc6d","slug":"/use-cases","title":"Use Cases"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":true,"metaTitle":"Use Cases","metaDescription":"Use Cases for the Neural Magic Platform"}}},{"node":{"fields":{"id":"c1d1d524-e761-5294-a8e7-e21f3164f48a","slug":"/","title":"Home"},"frontmatter":{"index":0,"targetURL":null,"skipToChild":null,"metaTitle":"Neural Magic Documentation","metaDescription":"Documentation for the Neural Magic Platform"}}},{"node":{"fields":{"id":"a500248d-7a7d-5be6-9c51-ffab9753b5e0","slug":"/user-guides","title":"User Guides"},"frontmatter":{"index":3000,"targetURL":null,"skipToChild":true,"metaTitle":"User Guides","metaDescription":"User Guides"}}},{"node":{"fields":{"id":"cba43102-b32f-5b1a-9c69-f46222a36403","slug":"/user-guides/deepsparse-engine","title":"DeepSparse"},"frontmatter":{"index":4000,"targetURL":null,"skipToChild":null,"metaTitle":"User Guides for DeepSparse Engine","metaDescription":"User Guides for DeepSparse Engine"}}},{"node":{"fields":{"id":"ceb703c1-4adc-510d-95bd-fb316521b486","slug":"/user-guides/deploying-deepsparse","title":"Deploying DeepSparse"},"frontmatter":{"index":5000,"targetURL":null,"skipToChild":null,"metaTitle":"Deploying DeepSparse","metaDescription":"Deploying Deepsparse"}}},{"node":{"fields":{"id":"36031f98-c9cf-5658-b606-b28762ed208f","slug":"/user-guides/onnx-export","title":"ONNX Export"},"frontmatter":{"index":3000,"targetURL":null,"skipToChild":null,"metaTitle":"Exporting to the ONNX Format","metaDescription":"Exporting to the ONNX Format"}}},{"node":{"fields":{"id":"e0110db2-2460-5fd1-8cf7-16533e4ce767","slug":"/user-guides/recipes","title":"Recipes"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":null,"metaTitle":"What are Sparsification Recipes?","metaDescription":"Description of sparsification recipes enabling smaller and more performant neural networks in deep learning"}}},{"node":{"fields":{"id":"d098532a-4bc3-5224-91ca-b51b42b779e7","slug":"/user-guides/sparsification","title":"Sparsification"},"frontmatter":{"index":1000,"targetURL":null,"skipToChild":null,"metaTitle":"What is Sparsification?","metaDescription":"Description of model sparsification enabling smaller and more performant neural networks in deep learning"}}},{"node":{"fields":{"id":"b16b5557-b4f4-5f6a-8c4d-ee3673781d7f","slug":"/user-guides/recipes/enabling","title":"Enabling Pipelines"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":null,"metaTitle":"Enabling Pipelines to Work with SparseML Recipes","metaDescription":"Enabling Pipelines to work with SparseML Recipess"}}},{"node":{"fields":{"id":"b35e8125-4431-5427-bd08-6b379e810c9b","slug":"/user-guides/deploying-deepsparse/aws-lambda","title":"AWS Lambda"},"frontmatter":{"index":3000,"targetURL":null,"skipToChild":null,"metaTitle":"Using DeepSparse on AWS Lambda","metaDescription":"Deploy DeepSparse in a Serverless framework with AWS Lambda"}}},{"node":{"fields":{"id":"2b874d9c-9c67-549d-8c79-b9b261359734","slug":"/user-guides/recipes/creating","title":"Creating"},"frontmatter":{"index":1000,"targetURL":null,"skipToChild":null,"metaTitle":"Creating Sparsification Recipes","metaDescription":"Creating Sparsification Recipes"}}},{"node":{"fields":{"id":"49f60901-1870-5d76-9fcc-12408f802b71","slug":"/user-guides/deploying-deepsparse/amazon-sagemaker","title":"Amazon SageMaker"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":null,"metaTitle":"Deploying With DeepSparse on Amazon SageMaker","metaDescription":"Deploying with DeepSparse on Amazon SageMaker for faster and cheaper model deployments behind an HTTP API"}}},{"node":{"fields":{"id":"5c89e3b2-04e2-59ed-9b42-1c5df17a2df4","slug":"/user-guides/deploying-deepsparse/google-cloud-run","title":"Google Cloud Run"},"frontmatter":{"index":4000,"targetURL":null,"skipToChild":null,"metaTitle":"Using DeepSparse on Google Cloud Run","metaDescription":"Deploy DeepSparse in a Serverless framework with Google Cloud Run"}}},{"node":{"fields":{"id":"115b6c49-fc7b-5dc6-9872-5a690e2b4a25","slug":"/user-guides/deepsparse-engine/benchmarking","title":"Benchmarking"},"frontmatter":{"index":3000,"targetURL":null,"skipToChild":null,"metaTitle":"Benchmarking ONNX Models With DeepSparse","metaDescription":"Benchmarking ONNX models with DeepSparse"}}},{"node":{"fields":{"id":"6085e38d-6a1d-58ac-a6c2-052f8208cf6e","slug":"/user-guides/deepsparse-engine/diagnostics-debugging","title":"Diagnostics/Debugging"},"frontmatter":{"index":4000,"targetURL":null,"skipToChild":null,"metaTitle":"Logging Guidance for Diagnostics and Debugging","metaDescription":"Logging Guidance for Diagnostics and Debugging"}}},{"node":{"fields":{"id":"88604204-656d-5710-a23b-b7cc05eca1de","slug":"/user-guides/deepsparse-engine/hardware-support","title":"Supported Hardware"},"frontmatter":{"index":1000,"targetURL":null,"skipToChild":null,"metaTitle":"Supported Hardware for DeepSparse","metaDescription":"Supported hardware for DeepSparse including CPU types and instruction sets"}}},{"node":{"fields":{"id":"8da43520-8b07-5bcc-a88f-f328137a2270","slug":"/user-guides/deepsparse-engine/logging","title":"DeepSparse Logging"},"frontmatter":{"index":6000,"targetURL":null,"skipToChild":null,"metaTitle":"DeepSparse Logging","metaDescription":"System and Data Logging with DeepSparse"}}},{"node":{"fields":{"id":"86938249-6f57-5091-84c8-9ad393d417b1","slug":"/user-guides/deepsparse-engine/numactl-utility","title":"numactl Utility"},"frontmatter":{"index":5000,"targetURL":null,"skipToChild":null,"metaTitle":"Using the numactl Utility to Control Resource Utilization With DeepSparse","metaDescription":"Using the numactl Utility to Control Resource Utilization With DeepSparse"}}},{"node":{"fields":{"id":"ddada45f-c6b9-5146-91e4-f56c28e31284","slug":"/user-guides/deepsparse-engine/scheduler","title":"Inference Types"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":null,"metaTitle":"Inference Types With DeepSparse Scheduler","metaDescription":"Inference Types with DeepSparse Scheduler"}}},{"node":{"fields":{"id":"113c5c42-984c-53b3-8392-7058bdd946cb","slug":"/use-cases/embedding-extraction","title":"Embedding Extraction"},"frontmatter":{"index":5000,"targetURL":null,"skipToChild":null,"metaTitle":"Embedding Extraction Deployment","metaDescription":"Generalized Embedding Extraction Deployment"}}},{"node":{"fields":{"id":"b7365467-d2b2-5dad-be10-a3aaa773d3a3","slug":"/use-cases/natural-language-processing","title":"Natural Language Processing"},"frontmatter":{"index":1000,"targetURL":null,"skipToChild":true,"metaTitle":"Natural Language Processing","metaDescription":"NLP with HuggingFace Transformers"}}},{"node":{"fields":{"id":"2b513d53-228c-5cf7-9d36-42d82e22cc0b","slug":"/user-guides/deploying-deepsparse/deepsparse-server","title":"DeepSparse Server"},"frontmatter":{"index":1000,"targetURL":null,"skipToChild":null,"metaTitle":"Deploying With DeepSparse Server","metaDescription":"Deploying With DeepSparse Server for faster and cheaper model deployments behind an HTTP API"}}},{"node":{"fields":{"id":"baad04ad-efd7-5e85-8645-6455fce34324","slug":"/use-cases/image-classification","title":"Image Classification"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":true,"metaTitle":"Image Classification","metaDescription":"Image Classification with PyTorch Torchvision"}}},{"node":{"fields":{"id":"1ef7c7c8-073e-5abf-b57a-af03628c0714","slug":"/use-cases/object-detection","title":"Object Detection"},"frontmatter":{"index":3000,"targetURL":null,"skipToChild":true,"metaTitle":"Object Detection","metaDescription":"Object Detection with Ultralytics YOLOv5"}}},{"node":{"fields":{"id":"d1d7a8f3-9061-539a-aff8-d3957da959c6","slug":"/use-cases/object-detection/deploying","title":"Deploying"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":null,"metaTitle":"Object Detection Deployments With DeepSparse","metaDescription":"Object Detection deployments with Ultralytics YOLOv5 and DeepSparse to create cheaper and more performant models"}}},{"node":{"fields":{"id":"d363f68d-8b46-5da1-a1ef-fc14776d0a03","slug":"/use-cases/natural-language-processing/deploying","title":"Deploying"},"frontmatter":{"index":5000,"targetURL":null,"skipToChild":null,"metaTitle":"NLP Deployments with DeepSparse","metaDescription":"NLP deployments with Hugging Face Transformers and DeepSparse to create cheaper and more performant NLP models"}}},{"node":{"fields":{"id":"bd363f12-8b17-5aac-af39-0ae0e7b0b829","slug":"/use-cases/natural-language-processing/question-answering","title":"Question Answering"},"frontmatter":{"index":1000,"targetURL":null,"skipToChild":null,"metaTitle":"NLP Question Answering","metaDescription":"Question Answering with Hugging Face Transformers and SparseML to create cheaper and more performant NLP models"}}},{"node":{"fields":{"id":"3f751c96-1e87-5f4a-a0cb-d277724c2a0b","slug":"/use-cases/object-detection/sparsifying","title":"Sparsifying"},"frontmatter":{"index":1000,"targetURL":null,"skipToChild":null,"metaTitle":"Sparsifying Object Detection With Ultralytics YOLOv5 and SparseML","metaDescription":"Sparsifying Object Detection with Ultralytics YOLOv5 and SparseML to create cheaper and more performant models"}}},{"node":{"fields":{"id":"ae7d3726-718a-5be3-91a4-2559a2445fc4","slug":"/use-cases/natural-language-processing/text-classification","title":"Text Classification"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":null,"metaTitle":"NLP Text Classification","metaDescription":"Text Classification with Hugging Face Transformers and SparseML to create cheaper and more performant NLP models"}}},{"node":{"fields":{"id":"ecaebb25-0fd8-572a-9d98-52302d0a0e4e","slug":"/use-cases/image-classification/sparsifying","title":"Sparsifying"},"frontmatter":{"index":1000,"targetURL":null,"skipToChild":null,"metaTitle":"Sparsifying Image Classification Models With SparseML","metaDescription":"Sparsifying Image Classification models with SparseML to create cheaper and more performant models"}}},{"node":{"fields":{"id":"c3c4bea9-f7cd-5044-9f34-8e33c8d2b36d","slug":"/use-cases/natural-language-processing/token-classification","title":"Token Classification"},"frontmatter":{"index":3000,"targetURL":null,"skipToChild":null,"metaTitle":"NLP Token Classification","metaDescription":"Token Classification with Hugging Face Transformers and SparseML to create cheaper and more performant NLP models"}}},{"node":{"fields":{"id":"3b06a681-3381-5cdc-9dad-827cdc6f60ac","slug":"/use-cases/deploying-deepsparse/docker","title":"Docker"},"frontmatter":{"index":3000,"targetURL":null,"skipToChild":null,"metaTitle":"Using/Creating a DeepSparse Docker Image","metaDescription":"Using/Creating a DeepSparse Docker Image for repeatable build processes"}}},{"node":{"fields":{"id":"4ba00f44-34e5-5677-a8c6-862b44d48e7f","slug":"/products/deepsparse","title":"DeepSparse"},"frontmatter":{"index":0,"targetURL":null,"skipToChild":null,"metaTitle":"DeepSparse","metaDescription":"An inference runtime offering GPU-class performance on CPUs and APIs to integrate ML into your application"}}},{"node":{"fields":{"id":"76657780-4f8a-5f37-8f3c-1c6c04637503","slug":"/products/sparseml","title":"SparseML"},"frontmatter":{"index":1000,"targetURL":null,"skipToChild":null,"metaTitle":"SparseML","metaDescription":"Sparsity-aware neural network inference engine for GPU-class performance on CPUs"}}},{"node":{"fields":{"id":"08d07abb-4c37-5f58-8bdd-277facdeaf05","slug":"/products/sparsezoo/cli","title":"CLI"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":null,"metaTitle":"SparseML CLI","metaDescription":"Documentation for the CLI commands installed with SparseZoo enabling use of SOTA sparsified models and recipes"}}},{"node":{"fields":{"id":"0d031520-ee95-58db-bdb3-86689d6a0941","slug":"/use-cases/image-classification/deploying","title":"Deploying"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":null,"metaTitle":"Image Classification Deployments With DeepSparse","metaDescription":"Image classification deployments with DeepSparse to create cheaper and more performant models"}}},{"node":{"fields":{"id":"aafbc5b1-5291-5291-ab86-da09c479a4c1","slug":"/products/sparsezoo/python-api","title":"Python API"},"frontmatter":{"index":3000,"targetURL":null,"skipToChild":null,"metaTitle":"SparseML Python API","metaDescription":"Documentation for the Python APIs available with SparseZoo enabling use of SOTA sparsified models and recipes"}}},{"node":{"fields":{"id":"97cb8313-bc03-5a24-bf92-015086fc9071","slug":"/products/sparsezoo/models","title":"Models"},"frontmatter":{"index":1000,"targetURL":"https://sparsezoo.neuralmagic.com/","skipToChild":null,"metaTitle":"Models","metaDescription":"Models"}}},{"node":{"fields":{"id":"b6a850d0-afc3-5418-ae82-146d2cb68706","slug":"/products/sparseml/cli","title":"CLI"},"frontmatter":{"index":1000,"targetURL":null,"skipToChild":null,"metaTitle":"SparseML CLI","metaDescription":"Documentation for the CLI commands installed with SparseML enabling SOTA model sparsification"}}},{"node":{"fields":{"id":"018cd1d6-6542-547d-ac3b-2743f179ac04","slug":"/products/sparseml/python-api","title":"Python API"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":null,"metaTitle":"SparseML Python API","metaDescription":"Documentation for the Python APIs available with SparseML enabling SOTA model sparsification"}}},{"node":{"fields":{"id":"233b31f0-deac-5b52-9101-caf3e3474595","slug":"/products/deepsparse/community","title":"DeepSparse Community"},"frontmatter":{"index":1000,"targetURL":null,"skipToChild":null,"metaTitle":"DeepSparse Community","metaDescription":"An inference runtime offering GPU-class performance on CPUs and APIs to integrate ML into your application"}}},{"node":{"fields":{"id":"d79d91ee-f596-5f3a-aafd-02c85a389909","slug":"/products/deepsparse/enterprise","title":"DeepSparse Enterprise"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":null,"metaTitle":"DeepSparse Enterprise","metaDescription":"An inference runtime offering GPU-class performance on CPUs and APIs to integrate ML into your application"}}},{"node":{"fields":{"id":"e3c4460c-c09f-5838-8047-fea6cf8f0511","slug":"/products/deepsparse/enterprise/cli","title":"CLI"},"frontmatter":{"index":1000,"targetURL":null,"skipToChild":null,"metaTitle":"DeepSparse CLI","metaDescription":"Documentation for the CLI commands installed with DeepSparse enabling GPU-class performance on CPUs"}}},{"node":{"fields":{"id":"d6bf031b-89e2-5374-9997-1676f340f25a","slug":"/products/deepsparse/enterprise/cpp-api","title":"C++ API"},"frontmatter":{"index":3000,"targetURL":null,"skipToChild":null,"metaTitle":"DeepSparse C++ API","metaDescription":"Documentation for the C++ APIs available with DeepSparse enabling GPU-class performance on CPUs"}}},{"node":{"fields":{"id":"5e0531ff-a237-587a-a318-72f000810bb0","slug":"/products/deepsparse/enterprise/python-api","title":"Python API"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":null,"metaTitle":"DeepSparse Python API","metaDescription":"Documentation for the Python APIs available with DeepSparse enabling GPU-class performance on CPUs"}}},{"node":{"fields":{"id":"b386abe1-47d1-5b57-aa77-a3f73f3ebe21","slug":"/products/deepsparse/community/cli","title":"CLI"},"frontmatter":{"index":1000,"targetURL":null,"skipToChild":null,"metaTitle":"DeepSparse CLI","metaDescription":"Documentation for the CLI commands installed with DeepSparse enabling GPU-class performance on CPUs"}}},{"node":{"fields":{"id":"f92e631d-dc67-592a-b7c2-dd4bb5e7a3fe","slug":"/products/deepsparse/community/cpp-api","title":"C++ API"},"frontmatter":{"index":3000,"targetURL":null,"skipToChild":null,"metaTitle":"DeepSparse C++ API","metaDescription":"Documentation for the C++ APIs available with DeepSparse enabling GPU-class performance on CPUs"}}},{"node":{"fields":{"id":"0d2bd4a5-a7f1-508a-8652-91e3eed40ceb","slug":"/products/deepsparse/community/python-api","title":"Python API"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":null,"metaTitle":"DeepSparse Python API","metaDescription":"Documentation for the Python APIs available with DeepSparse enabling GPU-class performance on CPUs"}}},{"node":{"fields":{"id":"4491ba6b-e373-50e3-a8b5-e8e173ecba81","slug":"/index/deploy-workflow","title":"Deploy on CPUs"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":null,"metaTitle":"Deploy on CPUs","metaDescription":"Overview of deployment capabilities in the Neural Magic Platform"}}},{"node":{"fields":{"id":"27a0b7a5-09e0-56ab-9ee5-68f45d8795fd","slug":"/index/optimize-workflow","title":"Optimize for Inference"},"frontmatter":{"index":1000,"targetURL":null,"skipToChild":null,"metaTitle":"Optimize for Inference","metaDescription":"Overview of deployment capabilities in the Neural Magic Platform"}}},{"node":{"fields":{"id":"478d6817-c021-5181-922d-2689a65470c5","slug":"/index/quick-tour","title":"Quick Tour"},"frontmatter":{"index":3000,"targetURL":null,"skipToChild":null,"metaTitle":"Quick Tour","metaDescription":"Quick tour of the available functionality"}}},{"node":{"fields":{"id":"665dac23-0ae5-5037-a151-d359bad8f8c2","slug":"/get-started/deploy-a-model","title":"Deploy a Model"},"frontmatter":{"index":5000,"targetURL":null,"skipToChild":null,"metaTitle":"Deploy a Model","metaDescription":"Deploy a model with DeepSparse Server for easy and performant ML deployments"}}},{"node":{"fields":{"id":"cc2c9b73-3a5b-5764-ad54-38c919cb3e78","slug":"/get-started/install","title":"Installation"},"frontmatter":{"index":0,"targetURL":null,"skipToChild":null,"metaTitle":"Install Neural Magic Platform","metaDescription":"Installation instructions for the Neural Magic Platform including DeepSparse, SparseML, SparseZoo"}}},{"node":{"fields":{"id":"43a5dd03-4ffe-5c02-ac47-7ee94de63602","slug":"/get-started/sparsify-a-model","title":"Sparsify a Model"},"frontmatter":{"index":4000,"targetURL":null,"skipToChild":null,"metaTitle":"Sparsify a Model","metaDescription":"Sparsify a model with SparseML and recipes for smaller, faster, and cheaper model inferences in deployment"}}},{"node":{"fields":{"id":"fb19b2bb-688f-5f4e-98e0-d1dbf478a015","slug":"/get-started/transfer-a-sparsified-model","title":"Transfer a Sparsified Model"},"frontmatter":{"index":3000,"targetURL":null,"skipToChild":null,"metaTitle":"Transfer a Sparsified Model","metaDescription":"Transfer a Sparsified Model to your dataset, enabling performant deep learning deployments with limited training"}}},{"node":{"fields":{"id":"5ba330af-8819-52cd-8818-2374113da636","slug":"/get-started/use-a-model","title":"Use a Model"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":null,"metaTitle":"Use a Model","metaDescription":"Use a Model with DeepSparse to deploy for faster and cheaper inference on CPUs"}}},{"node":{"fields":{"id":"00c56759-713b-5731-92b9-027dab853257","slug":"/get-started/use-a-model/custom-use-case","title":"Custom Use Case"},"frontmatter":{"index":3000,"targetURL":null,"skipToChild":null,"metaTitle":"Use a Custom Use Case","metaDescription":"Use a Custom Use Case and Model with DeepSparse to deploy for faster and cheaper inference on CPUs"}}},{"node":{"fields":{"id":"5689a5f7-7564-5b91-b21d-0f6aed1218a9","slug":"/get-started/use-a-model/cv-object-detection","title":"CV Object Detection"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":null,"metaTitle":"Use an Object Detection Model","metaDescription":"Use an Object Detection Model with DeepSparse to deploy for faster and cheaper inference on CPUs"}}},{"node":{"fields":{"id":"3bd4ca0d-2d04-5d9f-9037-06f9ae7dfb73","slug":"/get-started/transfer-a-sparsified-model/cv-object-detection","title":"CV Object Detection"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":null,"metaTitle":"Transfer a Sparsified Model for Object Detection","metaDescription":"Transfer a Sparsified Object Detection Model to your dataset enabling performant deep learning deployments in a faster amount of time"}}},{"node":{"fields":{"id":"4ac6dd90-ac18-5c3c-8c85-06021527df5e","slug":"/get-started/use-a-model/nlp-text-classification","title":"NLP Text Classification"},"frontmatter":{"index":1000,"targetURL":null,"skipToChild":null,"metaTitle":"Use a Text Classification Model","metaDescription":"Use a NLP Text Classification Model with DeepSparse for faster and cheaper inference on CPUs"}}},{"node":{"fields":{"id":"c32bcbda-4c9f-5b2a-b18d-5083b0003aef","slug":"/get-started/transfer-a-sparsified-model/nlp-text-classification","title":"NLP Text Classification"},"frontmatter":{"index":1000,"targetURL":null,"skipToChild":null,"metaTitle":"Transfer a Sparsified Model for Text Classification","metaDescription":"Transfer a Sparsified NLP Model to your sentiment analysis dataset enabling performant deep learning deployments with limited training"}}},{"node":{"fields":{"id":"6662f291-f43f-5616-8f60-dea883911f57","slug":"/get-started/sparsify-a-model/custom-integrations","title":"Custom Integrations"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":null,"metaTitle":"Creating a Custom Integration for Sparsifying Models","metaDescription":"Creating a Custom Integration for Sparsifying Models with SparseML for smaller, faster, and cheaper model inferences in deployment"}}},{"node":{"fields":{"id":"8323781e-a7b4-5bb5-a453-86e2c472d6cf","slug":"/get-started/install/deepsparse-ent","title":"DeepSparse Enterprise"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":null,"metaTitle":"DeepSparse Enterprise Installation","metaDescription":"Installation instructions for DeepSparse enabling performant neural network deployments"}}},{"node":{"fields":{"id":"8efaf662-8889-5bc3-bcae-9868aaa8aa53","slug":"/get-started/sparsify-a-model/supported-integrations","title":"Supported Integrations"},"frontmatter":{"index":1000,"targetURL":null,"skipToChild":null,"metaTitle":"Sparsifying a Model for SparseML Integrations","metaDescription":"Sparsify a model with SparseML and recipes for smaller, faster, and cheaper model inferences in deployment"}}},{"node":{"fields":{"id":"be1fa4d5-bae3-5c19-9da5-f56a08f2fa40","slug":"/products/sparsezoo","title":"SparseZoo"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":null,"metaTitle":"SparseZoo","metaDescription":"Neural network model repository for highly sparse and sparse-quantized models with matching sparsification recipes"}}},{"node":{"fields":{"id":"ac411c38-91fa-56bf-8dfd-c00cab6602ad","slug":"/get-started/install/sparsezoo","title":"SparseZoo"},"frontmatter":{"index":4000,"targetURL":null,"skipToChild":null,"metaTitle":"SparseZoo Installation","metaDescription":"Installation instructions for the SparseZoo sparse model repository"}}},{"node":{"fields":{"id":"5cebfec6-69f9-59bb-9a47-58bd80ce5b29","slug":"/get-started/install/deepsparse","title":"DeepSparse Community"},"frontmatter":{"index":1000,"targetURL":null,"skipToChild":null,"metaTitle":"DeepSparse Community Installation","metaDescription":"Installation instructions for DeepSparse enabling performant neural network deployments"}}},{"node":{"fields":{"id":"dc9f9ab1-1fb3-57b4-910a-fa3200519b0d","slug":"/get-started/install/sparseml","title":"SparseML"},"frontmatter":{"index":3000,"targetURL":null,"skipToChild":null,"metaTitle":"SparseML Installation","metaDescription":"Installation instructions for SparseML neural network optimization, training, and sparsification"}}},{"node":{"fields":{"id":"a597113f-8c9b-5620-baaa-95555edb534c","slug":"/details/faqs","title":"FAQs"},"frontmatter":{"index":4000,"targetURL":null,"skipToChild":null,"metaTitle":"FAQs","metaDescription":"FAQs for the Neural Magic Platform"}}},{"node":{"fields":{"id":"7d12ac36-8c45-565c-9b28-6472fdeb4a99","slug":"/get-started/deploy-a-model/nlp-text-classification","title":"NLP Text Classification"},"frontmatter":{"index":1000,"targetURL":null,"skipToChild":null,"metaTitle":"Deploy a Text Classification Model","metaDescription":"Deploy a text classification model with DeepSparse Server for easier, faster, and cheaper inference on CPUs"}}},{"node":{"fields":{"id":"f2d385fc-cb79-5c11-8873-f4e6f6d6da23","slug":"/details/glossary","title":"Glossary"},"frontmatter":{"index":3000,"targetURL":null,"skipToChild":null,"metaTitle":"Glossary","metaDescription":"Glossary for the Neural Magic product"}}},{"node":{"fields":{"id":"02f4ebab-32cf-58e1-a39b-db269f740d8b","slug":"/get-started/deploy-a-model/cv-object-detection","title":"CV Object Detection"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":null,"metaTitle":"Deploy an Object Detection Model","metaDescription":"Deploy an object detection model with DeepSparse Server for easier, faster, and cheaper inference on CPUs"}}},{"node":{"fields":{"id":"e5f9763e-9c0a-5d84-9f65-550685441793","slug":"/details/research-papers","title":"Research Papers"},"frontmatter":{"index":1000,"targetURL":"https://neuralmagic.com/resources/technical-papers/","skipToChild":null,"metaTitle":"Research Papers","metaDescription":"Research Papers"}}}]}},"pageContext":{"id":"76657780-4f8a-5f37-8f3c-1c6c04637503","pageType":"docs"}},"staticQueryHashes":[]}