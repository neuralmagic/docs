{"componentChunkName":"component---src-root-jsx","path":"/products/sparseml","result":{"data":{"site":{"siteMetadata":{"title":null,"docsLocation":"https://docs.neuralmagic.com"}},"mdx":{"fields":{"id":"76657780-4f8a-5f37-8f3c-1c6c04637503","title":"SparseML","slug":"/products/sparseml","githubURL":"https://github.com/neuralmagic/docs/blob/main/src/content/products/sparseml.mdx"},"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"SparseML\",\n  \"metaTitle\": \"SparseML\",\n  \"metaDescription\": \"Sparsity-aware neural network inference engine for GPU-class performance on CPUs\",\n  \"index\": 1000\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", null, \"SparseML\"), mdx(\"h3\", null, \"Libraries enabling creation of sparse deep-neural networks trained on your data with just a few lines of code\"), mdx(\"p\", null, \"\\n  \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://docs.neuralmagic.com/sparseml/\"\n  }, \"\\n    \", mdx(\"img\", {\n    parentName: \"a\",\n    \"alt\": \"Documentation\",\n    \"src\": \"https://img.shields.io/badge/documentation-darkred?&style=for-the-badge&logo=read-the-docs\",\n    \"height\": \"{25}\"\n  }), \"\\n  \"), \"\\n  \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://join.slack.com/t/discuss-neuralmagic/shared_invite/zt-q1a1cnvo-YBoICSIw3L1dmQpjBeDurQ/\"\n  }, \"\\n    \", mdx(\"img\", {\n    parentName: \"a\",\n    \"src\": \"https://img.shields.io/badge/slack-purple?style=for-the-badge&logo=slack\",\n    \"height\": \"{25}\"\n  }), \"\\n  \"), \"\\n  \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/issues\"\n  }, \"\\n    \", mdx(\"img\", {\n    parentName: \"a\",\n    \"src\": \"https://img.shields.io/badge/support%20forums-navy?style=for-the-badge&logo=github\",\n    \"height\": \"{25}\"\n  }), \"\\n  \"), \"\\n  \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/actions/workflows/test-check.yaml\"\n  }, \"\\n    \", mdx(\"img\", {\n    parentName: \"a\",\n    \"alt\": \"Main\",\n    \"src\": \"https://img.shields.io/github/workflow/status/neuralmagic/sparseml/Test%20Checks/main?label=build&style=for-the-badge\",\n    \"height\": \"{25}\"\n  }), \"\\n  \"), \"\\n  \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/releases\"\n  }, \"\\n    \", mdx(\"img\", {\n    parentName: \"a\",\n    \"alt\": \"GitHub release\",\n    \"src\": \"https://img.shields.io/github/release/neuralmagic/sparseml.svg?style=for-the-badge\",\n    \"height\": \"{25}\"\n  }), \"\\n  \"), \"\\n  \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/blob/main/LICENSE\"\n  }, \"\\n    \", mdx(\"img\", {\n    parentName: \"a\",\n    \"alt\": \"GitHub\",\n    \"src\": \"https://img.shields.io/github/license/neuralmagic/sparseml.svg?color=lightgray&style=for-the-badge\",\n    \"height\": \"{25}\"\n  }), \"\\n  \"), \"\\n  \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/blob/main/CODE_OF_CONDUCT.md\"\n  }, \"\\n    \", mdx(\"img\", {\n    parentName: \"a\",\n    \"alt\": \"Contributor Covenant\",\n    \"src\": \"https://img.shields.io/badge/Contributor%20Covenant-v2.1%20adopted-ff69b4.svg?color=yellow&style=for-the-badge\",\n    \"height\": \"{25}\"\n  }), \"\\n  \"), \"\\n  \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.youtube.com/channel/UCo8dO_WMGYbWCRnj_Dxr4EA\"\n  }, \"\\n    \", mdx(\"img\", {\n    parentName: \"a\",\n    \"src\": \"https://img.shields.io/badge/-YouTube-red?&style=for-the-badge&logo=youtube&logoColor=white\",\n    \"height\": \"{25}\"\n  }), \"\\n  \"), \"\\n  \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://medium.com/limitlessai\"\n  }, \"\\n    \", mdx(\"img\", {\n    parentName: \"a\",\n    \"src\": \"https://img.shields.io/badge/medium-%2312100E.svg?&style=for-the-badge&logo=medium&logoColor=white\",\n    \"height\": \"{25}\"\n  }), \"\\n  \"), \"\\n  \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://twitter.com/neuralmagic\"\n  }, \"\\n    \", mdx(\"img\", {\n    parentName: \"a\",\n    \"src\": \"https://img.shields.io/twitter/follow/neuralmagic?color=darkgreen&label=Follow&style=social\",\n    \"height\": \"{25}\"\n  }), \"\\n  \"), \"\\n\"), mdx(\"p\", null, \"SparseML is a toolkit that includes APIs, CLIs, scripts and libraries that enable you to create sparse models trained on your data.\"), mdx(\"p\", null, \"SparseML provides two options to accomplish this goal. Each option is useful for different situations:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Sparse Transfer Learning\"), \"\\u2014\", \"Fine-tune state-of-the-art pre-sparsified models from the SparseZoo onto your dataset while preserving sparsity. This is the easiest path to creating a sparse model trained on your data. Pull down a sparse model from SparseZoo and point our training scripts at your data without any hyperparameter search. This is the recommended pathway for supported use cases like Image Classification, Object Detection, and several NLP tasks.\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Sparsifying from Scratch\"), \"\\u2014\", \"Apply state-of-the-art \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/user-guides/sparsification\"\n  }, \"sparsification\"), \" algorithms such as pruning and quantization to any neural network. This gives you the flexibility to prune any neural network for any use case, but requires more training epochs and hand-tuning hyperparameters.\"))), mdx(\"p\", null, \"Each of these avenues uses YAML-based \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"recipes\"), \" that simplify integration with popular deep learning libraries and framrworks.\"), mdx(\"undefined\", null, mdx(\"img\", {\n    \"src\": \"https://docs.neuralmagic.com/docs/source/infographics/sparseml.png\",\n    \"alt\": \"SparseML Flow\",\n    \"width\": \"600px\"\n  }), \"\\n \\n## Highlights\"), mdx(\"h3\", null, \"Integrations\"), mdx(\"p\", null, \"\\n  \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/tree/main/integrations/pytorch\"\n  }, \"\\n    \", mdx(\"img\", {\n    parentName: \"a\",\n    \"src\": \"https://docs.neuralmagic.com/docs/source/highlights/sparseml/pytorch-torchvision.png\",\n    \"alt\": \"Integration - PyTorch: MobileNetV1, ResNet-50\",\n    \"width\": \"136px\"\n  }), \"\\n  \"), \"\\n  \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/tree/main/integrations/ultralytics-yolov3\"\n  }, \"\\n    \", mdx(\"img\", {\n    parentName: \"a\",\n    \"src\": \"https://docs.neuralmagic.com/docs/source/highlights/sparseml/ultralytics-yolov3.png\",\n    \"alt\": \"Integration - Ultralytics: YOLOv3\",\n    \"width\": \"136px\"\n  }), \"\\n  \"), \"\\n  \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/tree/main/integrations/ultralytics-yolov5\"\n  }, \"\\n    \", mdx(\"img\", {\n    parentName: \"a\",\n    \"src\": \"https://docs.neuralmagic.com/docs/source/highlights/sparseml/ultralytics-yolov5.png\",\n    \"alt\": \"Integration - Ultralytics: YOLOv5\",\n    \"width\": \"136px\"\n  }), \"\\n  \"), \"\\n  \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/tree/main/integrations/huggingface-transformers\"\n  }, \"\\n    \", mdx(\"img\", {\n    parentName: \"a\",\n    \"src\": \"https://docs.neuralmagic.com/docs/source/highlights/sparseml/huggingface-transformers.png\",\n    \"alt\": \"Integration - Hugging Face: BERT\",\n    \"width\": \"136px\"\n  }), \"\\n  \"), \"\\n  \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/tree/main/integrations/rwightman-timm\"\n  }, \"\\n    \", mdx(\"img\", {\n    parentName: \"a\",\n    \"src\": \"https://docs.neuralmagic.com/docs/source/highlights/sparseml/rwightman-timm.png\",\n    \"alt\": \"Integration - rwightman: ResNet-50\",\n    \"width\": \"136px\"\n  }), \"\\n  \"), \"\\n\"), mdx(\"h3\", null, \"Creating Sparse Models\"), mdx(\"p\", null, \"\\n  \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/tree/main/integrations/pytorch/notebooks/classification.ipynb\"\n  }, \"\\n    \", mdx(\"img\", {\n    parentName: \"a\",\n    \"src\": \"https://docs.neuralmagic.com/docs/source/tutorials/classification_resnet-50.png\",\n    \"alt\": \"Creating Sparse ResNet-50\",\n    \"width\": \"136px\"\n  }), \"\\n  \"), \"\\n  \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/tree/main/integrations/ultralytics-yolov3/tutorials/sparsifying_yolov3_using_recipes.md\"\n  }, \"\\n    \", mdx(\"img\", {\n    parentName: \"a\",\n    \"src\": \"https://docs.neuralmagic.com/docs/source/tutorials/detection_yolov3.png\",\n    \"alt\": \"Creating Sparse YOLOv3\",\n    \"width\": \"136px\"\n  }), \"\\n  \"), \"\\n  \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/tree/main/integrations/ultralytics-yolov5/tutorials/sparsifying_yolov5_using_recipes.md\"\n  }, \"\\n    \", mdx(\"img\", {\n    parentName: \"a\",\n    \"src\": \"https://docs.neuralmagic.com/docs/source/tutorials/detection_yolov5.png\",\n    \"alt\": \"Creating Sparse YOLOv5\",\n    \"width\": \"136px\"\n  }), \"\\n  \"), \"\\n  \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/tree/main/integrations/huggingface-transformers/tutorials/sparsifying_bert_using_recipes.md\"\n  }, \"\\n    \", mdx(\"img\", {\n    parentName: \"a\",\n    \"src\": \"https://docs.neuralmagic.com/docs/source/tutorials/nlp_bert.png\",\n    \"alt\": \"Creating Sparse BERT\",\n    \"width\": \"136px\"\n  }), \"\\n  \"), \"\\n\"), mdx(\"h3\", null, \"Transfer Learning from Sparse Models\"), mdx(\"p\", null, \"\\n  \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/tree/main/integrations/pytorch/notebooks/sparse_quantized_transfer_learning.ipynb\"\n  }, \"\\n    \", mdx(\"img\", {\n    parentName: \"a\",\n    \"src\": \"https://docs.neuralmagic.com/docs/source/tutorials/classification_resnet-50.png\",\n    \"alt\": \"Transfer Learn - ResNet-50\",\n    \"width\": \"136px\"\n  }), \"\\n  \"), \"\\n  \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/blob/main/integrations/ultralytics-yolov3/tutorials/yolov3_sparse_transfer_learning.md\"\n  }, \"\\n    \", mdx(\"img\", {\n    parentName: \"a\",\n    \"src\": \"https://docs.neuralmagic.com/docs/source/tutorials/detection_yolov3.png\",\n    \"alt\": \"Transfer Learn - YOLOv3\",\n    \"width\": \"136px\"\n  }), \"\\n  \"), \"\\n  \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/blob/main/integrations/ultralytics-yolov5/tutorials/yolov5_sparse_transfer_learning.md\"\n  }, \"\\n    \", mdx(\"img\", {\n    parentName: \"a\",\n    \"src\": \"https://docs.neuralmagic.com/docs/source/tutorials/detection_yolov5.png\",\n    \"alt\": \"Transfer Learn - YOLOv5\",\n    \"width\": \"136px\"\n  }), \"\\n  \"), \"\\n\"), mdx(\"h2\", null, \"Tutorials\"), mdx(\"h3\", null, \"Computer Vision\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/blob/main/integrations/pytorch/tutorials/sparsifying_pytorch_models_using_recipes.md\"\n  }, \"Sparsifying PyTorch Models Using Recipes\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/blob/main/integrations/ultralytics-yolov3/tutorials/sparsifying_yolov3_using_recipes.md\"\n  }, \"Sparsifying YOLOv3 Using Recipes\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/blob/main/integrations/ultralytics-yolov5/tutorials/sparsifying_yolov5_using_recipes.md\"\n  }, \"Sparsifying YOLOv5 Using Recipes\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/blob/main/integrations/dbolya-yolact/tutorials/sparsifying_yolact_using_recipes.md\"\n  }, \"Sparsifying YOLACT Using Recipes\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/blob/main/integrations/pytorch/tutorials/classification_sparse_transfer_learning_tutorial.md\"\n  }, \"Sparse Transfer Learning for Image Classification\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/blob/main/integrations/ultralytics-yolov3/tutorials/yolov3_sparse_transfer_learning.md\"\n  }, \"Sparse Transfer Learning With YOLOv3\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/blob/main/integrations/ultralytics-yolov5/tutorials/yolov5_sparse_transfer_learning.md\"\n  }, \"Sparse Transfer Learning With YOLOv5\"))), mdx(\"p\", null, \"\\u2003\", \" \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Notebooks\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/blob/main/integrations/keras/notebooks/classification.ipynb\"\n  }, \"Keras Image Classification Model Pruning Using SparseML\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/blob/main/integrations/pytorch/notebooks/classification.ipynb\"\n  }, \"PyTorch Image Classification Model Pruning Using SparseML\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/blob/main/integrations/pytorch/notebooks/detection.ipynb\"\n  }, \"PyTorch Image Detection Model Pruning Using SparseML\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/blob/main/integrations/pytorch/notebooks/sparse_quantized_transfer_learning.ipynb\"\n  }, \"Sparse-Quantized Transfer Learning in PyTorch Using SparseML\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/blob/main/integrations/pytorch/notebooks/torchvision.ipynb\"\n  }, \"Torchvision Classification Model Pruning Using SparseML\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/blob/main/integrations/tensorflow_v1/notebooks/classification.ipynb\"\n  }, \"TensorFlow v1 Classification Model Pruning Using SparseML\"))), mdx(\"h3\", null, \"NLP\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/blob/main/integrations/huggingface-transformers/tutorials/sparsifying_bert_using_recipes.md\"\n  }, \"Sparsifying BERT Models Using Recipes\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/blob/main/integrations/huggingface-transformers/tutorials/bert_sparse_transfer_learning.md\"\n  }, \"Sparse Transfer Learning With BERT\"))), mdx(\"h2\", null, \"Installation Requirements\"), mdx(\"p\", null, \"See the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/get-started/install/sparseml\"\n  }, \"SparseML Installation page\"), \" for installation instructions.\"), mdx(\"h2\", null, \"Quick Tour\"), mdx(\"p\", null, \"SparseML enables you to create a sparse model with \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Sparse Transfer Learning\"), \" and \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Sparsification from Scratch\"), \".\"), mdx(\"p\", null, \"To enable flexibility, ease of use, and repeatability, each piece of functionality is accomplished via recipes.\\nThe recipes encode the instructions needed for modifying the model and/or training process as a list of modifiers.\\nExample modifiers can be anything from setting the learning rate for the optimizer to gradual magnitude pruning.\\nThe files are written in \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://yaml.org/\"\n  }, \"YAML\"), \" and stored in YAML or \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.markdownguide.org/\"\n  }, \"Markdown\"), \" files using \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://assemble.io/docs/YAML-front-matter.html\"\n  }, \"YAML front matter.\"), \" The rest of the SparseML system is coded to parse the recipes into a native format for the desired framework and apply the modifications to the model and training pipeline.\"), mdx(\"p\", null, \"To give a sense of the flavor of what recipes encode, some examples are:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"Recipes for \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Sparse Transfer Learning\"), \" usually include the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"!ConstantPruningModifier\"), \", which instructs SparseML to maintian the starting level of sparsity while fine-tuning.\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"Recipes for \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Sparsification from Scratch\"), \" usually include the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"!GMPruningModifier\"), \", which instructs SparseML to iteratively prune the layers of the model to certain levels (e.g., 80%) over which epochs.\"))), mdx(\"p\", null, \"Recipes are then integrated into deep learning training workflows in one of two ways:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"For supported use cases: CLI\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"For custom use cases / supported use cases: Python integration\")), mdx(\"h4\", null, \"Supported Use Cases: CLI\"), mdx(\"p\", null, \"SparseML provides command line scripts that accept recipes as arguments and perform sparse transfer learning and sparsification from scratch. We highly\\nreccomended using the command line scripts. Appending \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"--help\"), \" to the commands demonstrates the full list of arguments.\"), mdx(\"p\", null, \"For example, the following command kicks off \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Sparse Transfer Learning\"), \" from pre-sparsified YOLOv5 onto the VOC dataset using the pre-made recipes in the SparseZoo:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-bash\"\n  }, \"$ sparseml.yolov5.train \\\\\\n    --data VOC.yaml \\\\\\n    --cfg models_v5.0/yolov5l.yaml \\\\\\n    --weights zoo:cv/detection/yolov5-l/pytorch/ultralytics/coco/pruned_quant-aggressive_95?recipe_type=transfer \\\\\\n    --hyp data/hyps/hyp.finetune.yaml \\\\\\n    --recipe zoo:cv/detection/yolov5-l/pytorch/ultralytics/coco/pruned_quant-aggressive_95?recipe_type=transfer\\n\")), mdx(\"p\", null, \"In the next example, the command kicks off \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Sparsification of a dense YOLOv5 model from scratch\"), \" using the pre-made recipes in the SparseZoo:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-bash\"\n  }, \"$ sparseml.yolov5.train \\\\\\n    --cfg models_v5.0/yolov5l.yaml \\\\\\n    --weights yolov5l.pt \\\\\\n    --data coco.yaml \\\\\\n    --hyp data/hyps/hyp.scratch.yaml \\\\\\n    --recipe zoo:cv/detection/yolov5-l/pytorch/ultralytics/coco/pruned_quant-aggressive_95\\n\")), mdx(\"p\", null, \"See \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/use-cases/natural-language-processing/question-answering\"\n  }, \"more details\"), \" on the above as well as examples for more supported use cases.\"), mdx(\"h4\", null, \"Custom Use Cases / Supported Use Cases: Python Integration\"), mdx(\"p\", null, \"The \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"ScheduledModifierManager\"), \" class is used to modify the standard training workflows for both sparse transfer learning\\nand sparsification from scratch. It can be used in PyTorch and TensorFlow/Keras.\"), mdx(\"p\", null, \"The manager classes work by overriding the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"model\"), \" and \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"optimizers\"), \" to encode sparsity logic.\\nManagers can apply recipes in one-shot or training-aware ways.\\nOne-shot is invoked by calling \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \".apply(...)\"), \" on the manager while training-aware requires calls into \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"initialize(...)\"), \" (optional), \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"modify(...)\"), \", and \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"finalize(...)\"), \".\\nThis means only a few lines of code need to be added to begin transfer learning or sparsifying from scratch with pruning and quantization.\"), mdx(\"p\", null, \"For example, the following applies a recipe in a training-aware manner:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"model = Model()  # model definition\\noptimizer = Optimizer()  # optimizer definition\\ntrain_data = TrainData()  # train data definition\\nbatch_size = BATCH_SIZE  # training batch size\\nsteps_per_epoch = len(train_data) // batch_size\\n\\nfrom sparseml.pytorch.optim import ScheduledModifierManager\\nmanager = ScheduledModifierManager.from_yaml(PATH_TO_RECIPE)\\noptimizer = manager.modify(model, optimizer, steps_per_epoch)\\n\\n# ... PyTorch training loop as usual ...\\n\\nmanager.finalize(model)\\n\")), mdx(\"p\", null, \"Instead of training-aware, the following example code shows how to execute a recipe in a one-shot manner:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"model = Model()  # model definition\\n\\nfrom sparseml.pytorch.optim import ScheduledModifierManager\\nmanager = ScheduledModifierManager.from_yaml(PATH_TO_RECIPE)\\nmanager.apply(model)\\n\")), mdx(\"p\", null, \"More information on the code base and contained processes can be found in the SparseML documentation:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/get-started/transfer-a-sparsified-model\"\n  }, \"Sparse Transfer Learning\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/get-started/sparsify-a-model\"\n  }, \"Sparsification Code\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/user-guides/recipes\"\n  }, \"Sparsification Recipes\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/user-guides/sparsification\"\n  }, \"Exporting to ONNX\"))), mdx(\"h2\", null, \"Resources\"), mdx(\"h3\", null, \"Learning More\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Documentation: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://docs.neuralmagic.com/sparseml/\"\n  }, \"SparseML,\"), \" \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://docs.neuralmagic.com/sparsezoo/\"\n  }, \"SparseZoo,\"), \" \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://docs.neuralmagic.com/sparsify/\"\n  }, \"Sparsify,\"), \" \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://docs.neuralmagic.com/deepsparse/\"\n  }, \"DeepSparse\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Neural Magic: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.neuralmagic.com/blog/\"\n  }, \"Blog,\"), \" \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.neuralmagic.com/resources/\"\n  }, \"Resources\"))), mdx(\"h3\", null, \"Release History\"), mdx(\"p\", null, \"Official builds are hosted on PyPI\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Stable: \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://pypi.org/project/sparseml/\"\n  }, \"sparseml\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Nightly (dev): \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://pypi.org/project/sparseml-nightly/\"\n  }, \"sparseml-nightly\"))), mdx(\"p\", null, \"Additionally, more information can be found via \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/releases\"\n  }, \"GitHub Releases.\")), mdx(\"h3\", null, \"License\"), mdx(\"p\", null, \"The project is licensed under the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/blob/main/LICENSE\"\n  }, \"Apache License Version 2.0.\")), mdx(\"h2\", null, \"Community\"), mdx(\"h3\", null, \"Contribute\"), mdx(\"p\", null, \"We appreciate contributions to the code, examples, integrations, and documentation as well as bug reports and feature requests! \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/blob/main/CONTRIBUTING.md\"\n  }, \"Learn how here.\")), mdx(\"h3\", null, \"Join\"), mdx(\"p\", null, \"For user help or questions about SparseML, sign up or log into our \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://join.slack.com/t/discuss-neuralmagic/shared_invite/zt-q1a1cnvo-YBoICSIw3L1dmQpjBeDurQ\"\n  }, \"Neural Magic Community Slack\"), \". We are growing the community member by member and happy to see you there. Bugs, feature requests, or additional questions can also be posted to our \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/neuralmagic/sparseml/issues\"\n  }, \"GitHub Issue Queue.\")), mdx(\"p\", null, \"You can get the latest news, webinar and event invites, research papers, and other ML performance tidbits by \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://neuralmagic.com/subscribe/\"\n  }, \"subscribing\"), \" to the Neural Magic community.\"), mdx(\"p\", null, \"For more general questions about Neural Magic, please fill out this \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://neuralmagic.com/contact/\"\n  }, \"form.\")), mdx(\"h3\", null, \"Cite\"), mdx(\"p\", null, \"Find this project useful in your research or other communications? Please consider citing:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-bibtex\"\n  }, \"@InProceedings{\\n    pmlr-v119-kurtz20a,\\n    title = {Inducing and Exploiting Activation Sparsity for Fast Inference on Deep Neural Networks},\\n    author = {Kurtz, Mark and Kopinsky, Justin and Gelashvili, Rati and Matveev, Alexander and Carr, John and Goin, Michael and Leiserson, William and Moore, Sage and Nell, Bill and Shavit, Nir and Alistarh, Dan},\\n    booktitle = {Proceedings of the 37th International Conference on Machine Learning},\\n    pages = {5533--5543},\\n    year = {2020},\\n    editor = {Hal Daum\\xE9 III and Aarti Singh},\\n    volume = {119},\\n    series = {Proceedings of Machine Learning Research},\\n    address = {Virtual},\\n    month = {13--18 Jul},\\n    publisher = {PMLR},\\n    pdf = {http://proceedings.mlr.press/v119/kurtz20a/kurtz20a.pdf},\\n    url = {http://proceedings.mlr.press/v119/kurtz20a.html},\\n    abstract = {Optimizing convolutional neural networks for fast inference has recently become an extremely active area of research. One of the go-to solutions in this context is weight pruning, which aims to reduce computational and memory footprint by removing large subsets of the connections in a neural network. Surprisingly, much less attention has been given to exploiting sparsity in the activation maps, which tend to be naturally sparse in many settings thanks to the structure of rectified linear (ReLU) activation functions. In this paper, we present an in-depth analysis of methods for maximizing the sparsity of the activations in a trained neural network, and show that, when coupled with an efficient sparse-input convolution algorithm, we can leverage this sparsity for significant performance gains. To induce highly sparse activation maps without accuracy loss, we introduce a new regularization technique, coupled with a new threshold-based sparsification method based on a parameterized activation function called Forced-Activation-Threshold Rectified Linear Unit (FATReLU). We examine the impact of our methods on popular image classification models, showing that most architectures can adapt to significantly sparser activation maps without any accuracy loss. Our second contribution is showing that these these compression gains can be translated into inference speedups: we provide a new algorithm to enable fast convolution operations over networks with sparse activations, and show that it can enable significant speedups for end-to-end inference on a range of popular models on the large-scale ImageNet image classification task on modern Intel CPUs, with little or no retraining cost.}\\n}\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-bibtex\"\n  }, \"@misc{\\n    singh2020woodfisher,\\n    title={WoodFisher: Efficient Second-Order Approximation for Neural Network Compression},\\n    author={Sidak Pal Singh and Dan Alistarh},\\n    year={2020},\\n    eprint={2004.14340},\\n    archivePrefix={arXiv},\\n    primaryClass={cs.LG}\\n}\\n\")));\n}\n;\nMDXContent.isMDXComponent = true;","tableOfContents":{"items":[{"url":"#sparseml","title":"SparseML","items":[{"items":[{"url":"#libraries-enabling-creation-of-sparse-deep-neural-networks-trained-on-your-data-with-just-a-few-lines-of-code","title":"Libraries enabling creation of sparse deep-neural networks trained on your data with just a few lines of code"},{"url":"#integrations","title":"Integrations"},{"url":"#creating-sparse-models","title":"Creating Sparse Models"},{"url":"#transfer-learning-from-sparse-models","title":"Transfer Learning from Sparse Models"}]},{"url":"#tutorials","title":"Tutorials","items":[{"url":"#computer-vision","title":"Computer Vision"},{"url":"#nlp","title":"NLP"}]},{"url":"#installation-requirements","title":"Installation Requirements"},{"url":"#quick-tour","title":"Quick Tour","items":[{"items":[{"url":"#supported-use-cases-cli","title":"Supported Use Cases: CLI"},{"url":"#custom-use-cases--supported-use-cases-python-integration","title":"Custom Use Cases / Supported Use Cases: Python Integration"}]}]},{"url":"#resources","title":"Resources","items":[{"url":"#learning-more","title":"Learning More"},{"url":"#release-history","title":"Release History"},{"url":"#license","title":"License"}]},{"url":"#community","title":"Community","items":[{"url":"#contribute","title":"Contribute"},{"url":"#join","title":"Join"},{"url":"#cite","title":"Cite"}]}]}]},"parent":{"relativePath":"products/sparseml.mdx"},"frontmatter":{"metaTitle":"SparseML","metaDescription":"Sparsity-aware neural network inference engine for GPU-class performance on CPUs","index":1000,"skipToChild":null}},"allMdx":{"edges":[{"node":{"fields":{"id":"220abd27-24cf-5408-9402-3e7b0591a7ec","slug":"/details","title":"Details"},"frontmatter":{"index":5000,"targetURL":null,"skipToChild":true,"metaTitle":"Details","metaDescription":"Details"}}},{"node":{"fields":{"id":"c1d1d524-e761-5294-a8e7-e21f3164f48a","slug":"/","title":"Home"},"frontmatter":{"index":0,"targetURL":null,"skipToChild":null,"metaTitle":"Neural Magic Documentation","metaDescription":"Documentation for the Neural Magic Platform"}}},{"node":{"fields":{"id":"bfcfecba-6eb1-59e8-8379-9c6d0c7a6a46","slug":"/get-started","title":"Get Started"},"frontmatter":{"index":1000,"targetURL":null,"skipToChild":true,"metaTitle":"Get Started","metaDescription":"Getting started with the Neural Magic Platform"}}},{"node":{"fields":{"id":"ee9f8c1f-d776-5134-89e6-b60f31e11b65","slug":"/products","title":"Products"},"frontmatter":{"index":4000,"targetURL":null,"skipToChild":true,"metaTitle":"Products","metaDescription":"Products"}}},{"node":{"fields":{"id":"0a2bc29c-0df2-59e5-a94c-bce091e6dc6d","slug":"/use-cases","title":"Use Cases"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":true,"metaTitle":"Use Cases","metaDescription":"Use Cases for the Neural Magic Platform"}}},{"node":{"fields":{"id":"a500248d-7a7d-5be6-9c51-ffab9753b5e0","slug":"/user-guides","title":"User Guides"},"frontmatter":{"index":3000,"targetURL":null,"skipToChild":true,"metaTitle":"User Guides","metaDescription":"User Guides"}}},{"node":{"fields":{"id":"cba43102-b32f-5b1a-9c69-f46222a36403","slug":"/user-guides/deepsparse-engine","title":"DeepSparse"},"frontmatter":{"index":4000,"targetURL":null,"skipToChild":null,"metaTitle":"User Guides for DeepSparse Engine","metaDescription":"User Guides for DeepSparse Engine"}}},{"node":{"fields":{"id":"d098532a-4bc3-5224-91ca-b51b42b779e7","slug":"/user-guides/sparsification","title":"Sparsification"},"frontmatter":{"index":1000,"targetURL":null,"skipToChild":null,"metaTitle":"What is Sparsification?","metaDescription":"Description of model sparsification enabling smaller and more performant neural networks in deep learning"}}},{"node":{"fields":{"id":"ceb703c1-4adc-510d-95bd-fb316521b486","slug":"/user-guides/deploying-deepsparse","title":"Deploying DeepSparse"},"frontmatter":{"index":5000,"targetURL":null,"skipToChild":null,"metaTitle":"Deploying DeepSparse","metaDescription":"Deploying Deepsparse"}}},{"node":{"fields":{"id":"36031f98-c9cf-5658-b606-b28762ed208f","slug":"/user-guides/onnx-export","title":"ONNX Export"},"frontmatter":{"index":3000,"targetURL":null,"skipToChild":null,"metaTitle":"Exporting to the ONNX Format","metaDescription":"Exporting to the ONNX Format"}}},{"node":{"fields":{"id":"2b874d9c-9c67-549d-8c79-b9b261359734","slug":"/user-guides/recipes/creating","title":"Creating"},"frontmatter":{"index":1000,"targetURL":null,"skipToChild":null,"metaTitle":"Creating Sparsification Recipes","metaDescription":"Creating Sparsification Recipes"}}},{"node":{"fields":{"id":"49f60901-1870-5d76-9fcc-12408f802b71","slug":"/user-guides/deploying-deepsparse/amazon-sagemaker","title":"Amazon SageMaker"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":null,"metaTitle":"Deploying with DeepSparse on Amazon SageMaker","metaDescription":"Deploying with DeepSparse on Amazon SageMaker for faster and cheaper model deployments behind an HTTP API"}}},{"node":{"fields":{"id":"2b513d53-228c-5cf7-9d36-42d82e22cc0b","slug":"/user-guides/deploying-deepsparse/deepsparse-server","title":"DeepSparse Server"},"frontmatter":{"index":1000,"targetURL":null,"skipToChild":null,"metaTitle":"Deploying with DeepSparse Server","metaDescription":"Deploying with DeepSparse Server for faster and cheaper model deployments behind an HTTP API"}}},{"node":{"fields":{"id":"e0110db2-2460-5fd1-8cf7-16533e4ce767","slug":"/user-guides/recipes","title":"Recipes"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":null,"metaTitle":"What are Sparsification Recipes?","metaDescription":"Description of sparsification recipes enabling smaller and more performant neural networks in deep learning"}}},{"node":{"fields":{"id":"5c89e3b2-04e2-59ed-9b42-1c5df17a2df4","slug":"/user-guides/deploying-deepsparse/google-cloud-run","title":"Google Cloud Run"},"frontmatter":{"index":4000,"targetURL":null,"skipToChild":null,"metaTitle":"Using DeepSparse on Google Cloud Run","metaDescription":"Deploy DeepSparse in a Serverless framework with Google Cloud Run"}}},{"node":{"fields":{"id":"6085e38d-6a1d-58ac-a6c2-052f8208cf6e","slug":"/user-guides/deepsparse-engine/diagnostics-debugging","title":"Diagnostics/Debugging"},"frontmatter":{"index":4000,"targetURL":null,"skipToChild":null,"metaTitle":"Logging Guidance for Diagnostics and Debugging","metaDescription":"Logging Guidance for Diagnostics and Debugging"}}},{"node":{"fields":{"id":"b16b5557-b4f4-5f6a-8c4d-ee3673781d7f","slug":"/user-guides/recipes/enabling","title":"Enabling Pipelines"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":null,"metaTitle":"Enabling Pipelines to work with SparseML Recipes","metaDescription":"Enabling Pipelines to work with SparseML Recipess"}}},{"node":{"fields":{"id":"b35e8125-4431-5427-bd08-6b379e810c9b","slug":"/user-guides/deploying-deepsparse/aws-lambda","title":"AWS Lambda"},"frontmatter":{"index":3000,"targetURL":null,"skipToChild":null,"metaTitle":"Using DeepSparse on AWS Lambda","metaDescription":"Deploy DeepSparse in a Serverless framework with AWS Lambda"}}},{"node":{"fields":{"id":"ddada45f-c6b9-5146-91e4-f56c28e31284","slug":"/user-guides/deepsparse-engine/scheduler","title":"Inference Types"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":null,"metaTitle":"Inference Types with DeepSparse Scheduler","metaDescription":"Inference Types with DeepSparse Scheduler"}}},{"node":{"fields":{"id":"86938249-6f57-5091-84c8-9ad393d417b1","slug":"/user-guides/deepsparse-engine/numactl-utility","title":"numactl Utility"},"frontmatter":{"index":5000,"targetURL":null,"skipToChild":null,"metaTitle":"Using the numactl Utility to Control Resource Utilization With DeepSparse","metaDescription":"Using the numactl Utility to Control Resource Utilization With DeepSparse"}}},{"node":{"fields":{"id":"8da43520-8b07-5bcc-a88f-f328137a2270","slug":"/user-guides/deepsparse-engine/logging","title":"DeepSparse Logging"},"frontmatter":{"index":6000,"targetURL":null,"skipToChild":null,"metaTitle":"DeepSparse Logging","metaDescription":"System and Data Logging with DeepSparse"}}},{"node":{"fields":{"id":"115b6c49-fc7b-5dc6-9872-5a690e2b4a25","slug":"/user-guides/deepsparse-engine/benchmarking","title":"Benchmarking"},"frontmatter":{"index":3000,"targetURL":null,"skipToChild":null,"metaTitle":"Benchmarking ONNX Models with DeepSparse","metaDescription":"Benchmarking ONNX Models with DeepSparse"}}},{"node":{"fields":{"id":"88604204-656d-5710-a23b-b7cc05eca1de","slug":"/user-guides/deepsparse-engine/hardware-support","title":"Supported Hardware"},"frontmatter":{"index":1000,"targetURL":null,"skipToChild":null,"metaTitle":"Supported Hardware for DeepSparse","metaDescription":"Supported hardware for DeepSparse including CPU types and instruction sets"}}},{"node":{"fields":{"id":"b7365467-d2b2-5dad-be10-a3aaa773d3a3","slug":"/use-cases/natural-language-processing","title":"Natural Language Processing"},"frontmatter":{"index":1000,"targetURL":null,"skipToChild":true,"metaTitle":"Natural Language Processing","metaDescription":"NLP with HuggingFace Transformers"}}},{"node":{"fields":{"id":"113c5c42-984c-53b3-8392-7058bdd946cb","slug":"/use-cases/embedding-extraction","title":"Embedding Extraction"},"frontmatter":{"index":5000,"targetURL":null,"skipToChild":null,"metaTitle":"Embedding Extraction Deployment","metaDescription":"Generalized Embedding Extraction Deployment"}}},{"node":{"fields":{"id":"d1d7a8f3-9061-539a-aff8-d3957da959c6","slug":"/use-cases/object-detection/deploying","title":"Deploying"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":null,"metaTitle":"Object Detection Deployments With DeepSparse","metaDescription":"Object Detection deployments with Ultralytics YOLOv5 and DeepSparse to create cheaper and more performant models"}}},{"node":{"fields":{"id":"1ef7c7c8-073e-5abf-b57a-af03628c0714","slug":"/use-cases/object-detection","title":"Object Detection"},"frontmatter":{"index":3000,"targetURL":null,"skipToChild":true,"metaTitle":"Object Detection","metaDescription":"Object Detection with Ultralytics YOLOv5"}}},{"node":{"fields":{"id":"d363f68d-8b46-5da1-a1ef-fc14776d0a03","slug":"/use-cases/natural-language-processing/deploying","title":"Deploying"},"frontmatter":{"index":5000,"targetURL":null,"skipToChild":null,"metaTitle":"NLP Deployments with DeepSparse","metaDescription":"NLP deployments with Hugging Face Transformers and DeepSparse to create cheaper and more performant NLP models"}}},{"node":{"fields":{"id":"3f751c96-1e87-5f4a-a0cb-d277724c2a0b","slug":"/use-cases/object-detection/sparsifying","title":"Sparsifying"},"frontmatter":{"index":1000,"targetURL":null,"skipToChild":null,"metaTitle":"Sparsifying Object Detection With Ultralytics YOLOv5 and SparseML","metaDescription":"Sparsifying Object Detection with Ultralytics YOLOv5 and SparseML to create cheaper and more performant models"}}},{"node":{"fields":{"id":"baad04ad-efd7-5e85-8645-6455fce34324","slug":"/use-cases/image-classification","title":"Image Classification"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":true,"metaTitle":"Image Classification","metaDescription":"Image Classification with PyTorch Torchvision"}}},{"node":{"fields":{"id":"bd363f12-8b17-5aac-af39-0ae0e7b0b829","slug":"/use-cases/natural-language-processing/question-answering","title":"Question Answering"},"frontmatter":{"index":1000,"targetURL":null,"skipToChild":null,"metaTitle":"NLP Question Answering","metaDescription":"Question Answering with Hugging Face Transformers and SparseML to create cheaper and more performant NLP models"}}},{"node":{"fields":{"id":"0d031520-ee95-58db-bdb3-86689d6a0941","slug":"/use-cases/image-classification/deploying","title":"Deploying"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":null,"metaTitle":"Image Classification Deployments With DeepSparse","metaDescription":"Image classification deployments with DeepSparse to create cheaper and more performant models"}}},{"node":{"fields":{"id":"c3c4bea9-f7cd-5044-9f34-8e33c8d2b36d","slug":"/use-cases/natural-language-processing/token-classification","title":"Token Classification"},"frontmatter":{"index":3000,"targetURL":null,"skipToChild":null,"metaTitle":"NLP Token Classification","metaDescription":"Token Classification with Hugging Face Transformers and SparseML to create cheaper and more performant NLP models"}}},{"node":{"fields":{"id":"3b06a681-3381-5cdc-9dad-827cdc6f60ac","slug":"/use-cases/deploying-deepsparse/docker","title":"Docker"},"frontmatter":{"index":3000,"targetURL":null,"skipToChild":null,"metaTitle":"Using/Creating a DeepSparse Docker Image","metaDescription":"Using/Creating a DeepSparse Docker Image for repeatable build processes"}}},{"node":{"fields":{"id":"ecaebb25-0fd8-572a-9d98-52302d0a0e4e","slug":"/use-cases/image-classification/sparsifying","title":"Sparsifying"},"frontmatter":{"index":1000,"targetURL":null,"skipToChild":null,"metaTitle":"Sparsifying Image Classification Models With SparseML","metaDescription":"Sparsifying Image Classification models with SparseML to create cheaper and more performant models"}}},{"node":{"fields":{"id":"ae7d3726-718a-5be3-91a4-2559a2445fc4","slug":"/use-cases/natural-language-processing/text-classification","title":"Text Classification"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":null,"metaTitle":"NLP Text Classification","metaDescription":"Text Classification with Hugging Face Transformers and SparseML to create cheaper and more performant NLP models"}}},{"node":{"fields":{"id":"76657780-4f8a-5f37-8f3c-1c6c04637503","slug":"/products/sparseml","title":"SparseML"},"frontmatter":{"index":1000,"targetURL":null,"skipToChild":null,"metaTitle":"SparseML","metaDescription":"Sparsity-aware neural network inference engine for GPU-class performance on CPUs"}}},{"node":{"fields":{"id":"4ba00f44-34e5-5677-a8c6-862b44d48e7f","slug":"/products/deepsparse","title":"DeepSparse"},"frontmatter":{"index":0,"targetURL":null,"skipToChild":null,"metaTitle":"DeepSparse","metaDescription":"An inference runtime offering GPU-class performance on CPUs and APIs to integrate ML into your application"}}},{"node":{"fields":{"id":"be1fa4d5-bae3-5c19-9da5-f56a08f2fa40","slug":"/products/sparsezoo","title":"SparseZoo"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":null,"metaTitle":"SparseZoo","metaDescription":"Neural network model repository for highly sparse and sparse-quantized models with matching sparsification recipes"}}},{"node":{"fields":{"id":"97cb8313-bc03-5a24-bf92-015086fc9071","slug":"/products/sparsezoo/models","title":"Models"},"frontmatter":{"index":1000,"targetURL":"https://sparsezoo.neuralmagic.com/","skipToChild":null,"metaTitle":"Models","metaDescription":"Models"}}},{"node":{"fields":{"id":"aafbc5b1-5291-5291-ab86-da09c479a4c1","slug":"/products/sparsezoo/python-api","title":"Python API"},"frontmatter":{"index":3000,"targetURL":null,"skipToChild":null,"metaTitle":"SparseML Python API","metaDescription":"Documentation for the Python APIs available with SparseZoo enabling use of SOTA sparsified models and recipes"}}},{"node":{"fields":{"id":"08d07abb-4c37-5f58-8bdd-277facdeaf05","slug":"/products/sparsezoo/cli","title":"CLI"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":null,"metaTitle":"SparseML CLI","metaDescription":"Documentation for the CLI commands installed with SparseZoo enabling use of SOTA sparsified models and recipes"}}},{"node":{"fields":{"id":"233b31f0-deac-5b52-9101-caf3e3474595","slug":"/products/deepsparse/community","title":"DeepSparse Community"},"frontmatter":{"index":1000,"targetURL":null,"skipToChild":null,"metaTitle":"DeepSparse Community","metaDescription":"An inference runtime offering GPU-class performance on CPUs and APIs to integrate ML into your application"}}},{"node":{"fields":{"id":"018cd1d6-6542-547d-ac3b-2743f179ac04","slug":"/products/sparseml/python-api","title":"Python API"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":null,"metaTitle":"SparseML Python API","metaDescription":"Documentation for the Python APIs available with SparseML enabling SOTA model sparsification"}}},{"node":{"fields":{"id":"b6a850d0-afc3-5418-ae82-146d2cb68706","slug":"/products/sparseml/cli","title":"CLI"},"frontmatter":{"index":1000,"targetURL":null,"skipToChild":null,"metaTitle":"SparseML CLI","metaDescription":"Documentation for the CLI commands installed with SparseML enabling SOTA model sparsification"}}},{"node":{"fields":{"id":"d79d91ee-f596-5f3a-aafd-02c85a389909","slug":"/products/deepsparse/enterprise","title":"DeepSparse Enterprise"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":null,"metaTitle":"DeepSparse Enterprise","metaDescription":"An inference runtime offering GPU-class performance on CPUs and APIs to integrate ML into your application"}}},{"node":{"fields":{"id":"5e0531ff-a237-587a-a318-72f000810bb0","slug":"/products/deepsparse/enterprise/python-api","title":"Python API"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":null,"metaTitle":"DeepSparse Python API","metaDescription":"Documentation for the Python APIs available with DeepSparse enabling GPU-class performance on CPUs"}}},{"node":{"fields":{"id":"d6bf031b-89e2-5374-9997-1676f340f25a","slug":"/products/deepsparse/enterprise/cpp-api","title":"C++ API"},"frontmatter":{"index":3000,"targetURL":null,"skipToChild":null,"metaTitle":"DeepSparse C++ API","metaDescription":"Documentation for the C++ APIs available with DeepSparse enabling GPU-class performance on CPUs"}}},{"node":{"fields":{"id":"e3c4460c-c09f-5838-8047-fea6cf8f0511","slug":"/products/deepsparse/enterprise/cli","title":"CLI"},"frontmatter":{"index":1000,"targetURL":null,"skipToChild":null,"metaTitle":"DeepSparse CLI","metaDescription":"Documentation for the CLI commands installed with DeepSparse enabling GPU-class performance on CPUs"}}},{"node":{"fields":{"id":"f92e631d-dc67-592a-b7c2-dd4bb5e7a3fe","slug":"/products/deepsparse/community/cpp-api","title":"C++ API"},"frontmatter":{"index":3000,"targetURL":null,"skipToChild":null,"metaTitle":"DeepSparse C++ API","metaDescription":"Documentation for the C++ APIs available with DeepSparse enabling GPU-class performance on CPUs"}}},{"node":{"fields":{"id":"478d6817-c021-5181-922d-2689a65470c5","slug":"/index/quick-tour","title":"Quick Tour"},"frontmatter":{"index":3000,"targetURL":null,"skipToChild":null,"metaTitle":"Quick Tour","metaDescription":"Quick tour of the available functionality"}}},{"node":{"fields":{"id":"b386abe1-47d1-5b57-aa77-a3f73f3ebe21","slug":"/products/deepsparse/community/cli","title":"CLI"},"frontmatter":{"index":1000,"targetURL":null,"skipToChild":null,"metaTitle":"DeepSparse CLI","metaDescription":"Documentation for the CLI commands installed with DeepSparse enabling GPU-class performance on CPUs"}}},{"node":{"fields":{"id":"0d2bd4a5-a7f1-508a-8652-91e3eed40ceb","slug":"/products/deepsparse/community/python-api","title":"Python API"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":null,"metaTitle":"DeepSparse Python API","metaDescription":"Documentation for the Python APIs available with DeepSparse enabling GPU-class performance on CPUs"}}},{"node":{"fields":{"id":"27a0b7a5-09e0-56ab-9ee5-68f45d8795fd","slug":"/index/optimize-workflow","title":"Optimize for Inference"},"frontmatter":{"index":1000,"targetURL":null,"skipToChild":null,"metaTitle":"Optimize for Inference","metaDescription":"Overview of deployment capabilities in the Neural Magic Platform"}}},{"node":{"fields":{"id":"4491ba6b-e373-50e3-a8b5-e8e173ecba81","slug":"/index/deploy-workflow","title":"Deploy on CPUs"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":null,"metaTitle":"Deploy on CPUs","metaDescription":"Overview of deployment capabilities in the Neural Magic Platform"}}},{"node":{"fields":{"id":"fb19b2bb-688f-5f4e-98e0-d1dbf478a015","slug":"/get-started/transfer-a-sparsified-model","title":"Transfer a Sparsified Model"},"frontmatter":{"index":3000,"targetURL":null,"skipToChild":null,"metaTitle":"Transfer a Sparsified Model","metaDescription":"Transfer a Sparsified Model to your dataset, enabling performant deep learning deployments with limited training"}}},{"node":{"fields":{"id":"43a5dd03-4ffe-5c02-ac47-7ee94de63602","slug":"/get-started/sparsify-a-model","title":"Sparsify a Model"},"frontmatter":{"index":4000,"targetURL":null,"skipToChild":null,"metaTitle":"Sparsify a Model","metaDescription":"Sparsify a model with SparseML and recipes for smaller, faster, and cheaper model inferences in deployment"}}},{"node":{"fields":{"id":"00c56759-713b-5731-92b9-027dab853257","slug":"/get-started/use-a-model/custom-use-case","title":"Custom Use Case"},"frontmatter":{"index":3000,"targetURL":null,"skipToChild":null,"metaTitle":"Use a Custom Use Case","metaDescription":"Use a Custom Use Case and Model with DeepSparse to deploy for faster and cheaper inference on CPUs"}}},{"node":{"fields":{"id":"665dac23-0ae5-5037-a151-d359bad8f8c2","slug":"/get-started/deploy-a-model","title":"Deploy a Model"},"frontmatter":{"index":5000,"targetURL":null,"skipToChild":null,"metaTitle":"Deploy a Model","metaDescription":"Deploy a model with DeepSparse Server for easy and performant ML deployments"}}},{"node":{"fields":{"id":"cc2c9b73-3a5b-5764-ad54-38c919cb3e78","slug":"/get-started/install","title":"Installation"},"frontmatter":{"index":0,"targetURL":null,"skipToChild":null,"metaTitle":"Install Neural Magic Platform","metaDescription":"Installation instructions for the Neural Magic Platform including DeepSparse, SparseML, SparseZoo"}}},{"node":{"fields":{"id":"3bd4ca0d-2d04-5d9f-9037-06f9ae7dfb73","slug":"/get-started/transfer-a-sparsified-model/cv-object-detection","title":"CV Object Detection"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":null,"metaTitle":"Transfer a Sparsified Model for Object Detection","metaDescription":"Transfer a Sparsified Object Detection Model to your dataset enabling performant deep learning deployments in a faster amount of time"}}},{"node":{"fields":{"id":"c32bcbda-4c9f-5b2a-b18d-5083b0003aef","slug":"/get-started/transfer-a-sparsified-model/nlp-text-classification","title":"NLP Text Classification"},"frontmatter":{"index":1000,"targetURL":null,"skipToChild":null,"metaTitle":"Transfer a Sparsified Model for Text Classification","metaDescription":"Transfer a Sparsified NLP Model to your sentiment analysis dataset enabling performant deep learning deployments with limited training"}}},{"node":{"fields":{"id":"4ac6dd90-ac18-5c3c-8c85-06021527df5e","slug":"/get-started/use-a-model/nlp-text-classification","title":"NLP Text Classification"},"frontmatter":{"index":1000,"targetURL":null,"skipToChild":null,"metaTitle":"Use a Text Classification Model","metaDescription":"Use a NLP Text Classification Model with DeepSparse for faster and cheaper inference on CPUs"}}},{"node":{"fields":{"id":"5689a5f7-7564-5b91-b21d-0f6aed1218a9","slug":"/get-started/use-a-model/cv-object-detection","title":"CV Object Detection"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":null,"metaTitle":"Use an Object Detection Model","metaDescription":"Use an Object Detection Model with DeepSparse to deploy for faster and cheaper inference on CPUs"}}},{"node":{"fields":{"id":"dc9f9ab1-1fb3-57b4-910a-fa3200519b0d","slug":"/get-started/install/sparseml","title":"SparseML"},"frontmatter":{"index":3000,"targetURL":null,"skipToChild":null,"metaTitle":"SparseML Installation","metaDescription":"Installation instructions for SparseML neural network optimization, training, and sparsification"}}},{"node":{"fields":{"id":"5ba330af-8819-52cd-8818-2374113da636","slug":"/get-started/use-a-model","title":"Use a Model"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":null,"metaTitle":"Use a Model","metaDescription":"Use a Model with DeepSparse to deploy for faster and cheaper inference on CPUs"}}},{"node":{"fields":{"id":"02f4ebab-32cf-58e1-a39b-db269f740d8b","slug":"/get-started/deploy-a-model/cv-object-detection","title":"CV Object Detection"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":null,"metaTitle":"Deploy an Object Detection Model","metaDescription":"Deploy an object detection model with DeepSparse Server for easier, faster, and cheaper inference on CPUs"}}},{"node":{"fields":{"id":"ac411c38-91fa-56bf-8dfd-c00cab6602ad","slug":"/get-started/install/sparsezoo","title":"SparseZoo"},"frontmatter":{"index":4000,"targetURL":null,"skipToChild":null,"metaTitle":"SparseZoo Installation","metaDescription":"Installation instructions for the SparseZoo sparse model repository"}}},{"node":{"fields":{"id":"7d12ac36-8c45-565c-9b28-6472fdeb4a99","slug":"/get-started/deploy-a-model/nlp-text-classification","title":"NLP Text Classification"},"frontmatter":{"index":1000,"targetURL":null,"skipToChild":null,"metaTitle":"Deploy a Text Classification Model","metaDescription":"Deploy a text classification model with DeepSparse Server for easier, faster, and cheaper inference on CPUs"}}},{"node":{"fields":{"id":"8323781e-a7b4-5bb5-a453-86e2c472d6cf","slug":"/get-started/install/deepsparse-ent","title":"DeepSparse Enterprise"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":null,"metaTitle":"DeepSparse Enterprise Installation","metaDescription":"Installation instructions for DeepSparse enabling performant neural network deployments"}}},{"node":{"fields":{"id":"f2d385fc-cb79-5c11-8873-f4e6f6d6da23","slug":"/details/glossary","title":"Glossary"},"frontmatter":{"index":3000,"targetURL":null,"skipToChild":null,"metaTitle":"Glossary","metaDescription":"Glossary for the Neural Magic product"}}},{"node":{"fields":{"id":"5cebfec6-69f9-59bb-9a47-58bd80ce5b29","slug":"/get-started/install/deepsparse","title":"DeepSparse Community"},"frontmatter":{"index":1000,"targetURL":null,"skipToChild":null,"metaTitle":"DeepSparse Community Installation","metaDescription":"Installation instructions for DeepSparse enabling performant neural network deployments"}}},{"node":{"fields":{"id":"a597113f-8c9b-5620-baaa-95555edb534c","slug":"/details/faqs","title":"FAQs"},"frontmatter":{"index":4000,"targetURL":null,"skipToChild":null,"metaTitle":"FAQs","metaDescription":"FAQs for the Neural Magic Platform"}}},{"node":{"fields":{"id":"6662f291-f43f-5616-8f60-dea883911f57","slug":"/get-started/sparsify-a-model/custom-integrations","title":"Custom Integrations"},"frontmatter":{"index":2000,"targetURL":null,"skipToChild":null,"metaTitle":"Creating a Custom Integration for Sparsifying Models","metaDescription":"Creating a Custom Integration for Sparsifying Models with SparseML for smaller, faster, and cheaper model inferences in deployment"}}},{"node":{"fields":{"id":"e5f9763e-9c0a-5d84-9f65-550685441793","slug":"/details/research-papers","title":"Research Papers"},"frontmatter":{"index":1000,"targetURL":"https://neuralmagic.com/resources/technical-papers/","skipToChild":null,"metaTitle":"Research Papers","metaDescription":"Research Papers"}}},{"node":{"fields":{"id":"8efaf662-8889-5bc3-bcae-9868aaa8aa53","slug":"/get-started/sparsify-a-model/supported-integrations","title":"Supported Integrations"},"frontmatter":{"index":1000,"targetURL":null,"skipToChild":null,"metaTitle":"Sparsifying a Model for SparseML Integrations","metaDescription":"Sparsify a model with SparseML and recipes for smaller, faster, and cheaper model inferences in deployment"}}}]}},"pageContext":{"id":"76657780-4f8a-5f37-8f3c-1c6c04637503","pageType":"docs"}},"staticQueryHashes":[]}