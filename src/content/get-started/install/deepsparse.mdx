---
title: "DeepSparse"
metaTitle: "DeepSparse Installation"
metaDescription: "Installation instructions for the DeepSparse Engine enabling performant neural network deployments"
githubURL: "https://github.com/neuralmagic/docs/blob/main/src/content/install/deepsparse.mdx"
index: 1000
---

# DeepSparse Installation

The [DeepSparse Engine](/products/deepsparse) enables GPU-class performance on CPUs, leveraging sparsity within models to reduce FLOPs and the unique cache hierarchy on CPUs to reduce memory movement.
The engine accepts models in the open-source [ONNX format](https://onnx.ai/), which are easily created from PyTorch and TensorFlow models.

Currently, DeepSparse is tested on Python 3.7-3.9, ONNX 1.5.0-1.10.1, ONNX opset version 11+ and is [manylinux compliant](https://peps.python.org/pep-0513/).
It is limited to Linux systems running on x86 CPU architectures.

## General Install

Use the following command to install with pip:

```bash
pip install deepsparse
```

## Server Install

The [DeepSparse Server](/use-cases/deploying-deepsparse/deepsparse-server) allows you to serve models and pipelines through an HTTP interface using the deepsparse.server CLI.
To install, use the following extra option:

```bash
pip install deepsparse[server]
```

## YOLO Install

The [Ultralytics YOLOv5](/use-cases/object-detection/deploying) models require extra dependencies for deployment.
To use YOLO models, install with the following extra option:

```bash
pip install deepsparse[yolo]         # just yolo requirements
pip install deepsparse[yolo, server] # both yolo + server requirements
```
