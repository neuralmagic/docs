---
title: "DeepSparse"
metaTitle: "DeepSparse Installation"
metaDescription: "Installation instructions for the DeepSparse Engine enabling performant neural network deployments"
index: 1000
---

# DeepSparse Community Edition Installation

The [DeepSparse Engine](/products/deepsparse) enables GPU-class performance on CPUs, leveraging sparsity within models to reduce FLOPs and the unique cache hierarchy on CPUs to reduce memory movement.
The engine accepts models in the open-source [ONNX format](https://onnx.ai/), which are easily created from PyTorch and TensorFlow models.

Currently, DeepSparse is tested on Python 3.7-3.10, ONNX 1.5.0-1.10.1, and ONNX opset version 11+. It is [manylinux compliant](https://peps.python.org/pep-0513/).
DeepSparse is limited to Linux systems running on x86 CPU architectures.

## Installing DeepSparse Community

Use the following command to install the Community Edition with pip:

```bash
pip install deepsparse
```

## Installing the Server

The [DeepSparse Server](/use-cases/deploying-deepsparse/deepsparse-server) allows you to serve models and pipelines through an HTTP interface using the deepsparse.server CLI.
To install, use the following extra option:

```bash
pip install deepsparse[server]
```

## Installing YOLO

The [Ultralytics YOLOv5](/use-cases/object-detection/deploying) models require extra dependencies for deployment.
To use YOLO models, install with the following extra option:

```bash
pip install deepsparse[yolo]         # just yolo requirements
pip install deepsparse[yolo,server] # both yolo + server requirements
```
 
