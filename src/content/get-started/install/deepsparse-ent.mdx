---
title: "DeepSparse Enterprise"
metaTitle: "DeepSparse Enterprise Installation"
metaDescription: "Installation instructions for the DeepSparse Engine enabling performant neural network deployments"
index: 2000
---

# DeepSparse Enterprise Edition Installation

The [DeepSparse Engine](/products/deepsparse-ent) enables GPU-class performance on CPUs, leveraging sparsity within models to reduce FLOPs and the unique cache hierarchy on CPUs to reduce memory movement.
The engine accepts models in the open-source [ONNX format](https://onnx.ai/), which are easily created from PyTorch and TensorFlow models.

Currently, DeepSparse is tested on Python 3.7-3.10, ONNX 1.5.0-1.10.1, ONNX opset version 11+ and is [manylinux compliant](https://peps.python.org/pep-0513/).
It is limited to Linux systems running on x86 CPU architectures.

## Installing DeepSparse Enterprise

Use the following command to install with pip:

```bash
pip install deepsparse-ent
```

## Installing the Server

The [DeepSparse Server](/use-cases/deploying-deepsparse/deepsparse-server) allows you to serve models and pipelines through an HTTP interface using the deepsparse.server CLI.
To install, use the following extra option:

```bash
pip install deepsparse-ent[server]
```

## Installing YOLO

The [Ultralytics YOLOv5](/use-cases/object-detection/deploying) models require extra dependencies for deployment.
To use YOLO models, install with the following extra option:

```bash
pip install deepsparse-ent[yolo]         # just yolo requirements
pip install deepsparse-ent[yolo,server] # both yolo + server requirements
```
 
