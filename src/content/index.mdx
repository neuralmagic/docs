---
title: "Home"
metaTitle: "Neural Magic Documentation"
metaDescription: "Documentation for the Neural Magic Deep Sparse Platform: a suite of software components to train and deploy sparsified deep learning models performantly on your data"
index: 0
---

# Neural Magic Documentation

The Neural Magic Platform provides models and tools needed to create sparse models and a CPU-based inference engine that runs sparse models at GPU speeds.

Using the Deep Sparse Platform, you are free to deploy your neural networks from edge to cloud&mdash;anywhere you have a CPU.

Three products accomplish these goals:

- [DeepSparse Engine](/products/deepsparse) offers best-in-class CPU performance for dense and sparsified models.
Specifically for sparse models, it delivers better than GPU performance in many use cases.
The performance is achieved by leveraging technology around the unique cache hierarchy of CPUs for faster memory access and sparsification techniques to reduce the number of FLOPs.

 DeepSparse is available in two editions:
  - [DeepSparse Community](/products/deepsparse) is open-source and free for evaluation, research, and non-production use with our [DeepSparse Community License](https://neuralmagic.com/legal/engine-license-agreement/).
  - [DeepSparse Enterprise](/products/deepsparse-ent) requires a Trial License or [can be fully licensed](https://neuralmagic.com/legal/master-software-license-and-service-agreement/) for production, commercial applications.

- [SparseML](/products/sparseml) provides the tools to easily create sparse models via [sparse transfer-learning](/get-started/transfer-a-sparsified-model) from pre-sparsified models or state-of-the-art [sparsification algorithms](/user-guide/sparsification) that prune dense models from scratch.
The algorithms are built on recipes that encode configurations and hyperparamers, enabling easy integration with common frameworks with only a few lines of code.

- [SparseZoo](/products/sparsezoo) stores dense and pre-sparsified models/recipes ready for deployment, sparsification, and fine-tuning onto your data.
SparseZoo stubs enable you to reference any model on the SparseZoo in a convenient and identifiable way.
They are found throughout the documentation and the model pages on the [SparseZoo website](https://sparsezoo.neuralmagic.com).

## Starting Points

<LinkCards>
  <LinkCard href="/get-started/try-a-model" heading="Get Started">
    A step-by-step introduction into basic Deep Sparse Platform features.
  </LinkCard>

  <LinkCard href="/use-cases/natural-language-processing/question-answering" heading="Use Cases">
    A non-exhaustive list of scenarios the Deep Sparse Platform can help with.
  </LinkCard>

  <LinkCard href="/user-guide/sparsification" heading="User Guide">
    Study the detailed inner workings of the Deep Sparse Platform in its user guide.
  </LinkCard>

  <LinkCard href="/products/deepsparse" heading="Products">
    See all of the Deep Sparse Platform's products and available commands and APIs.
  </LinkCard>
</LinkCards>


## External Resources

✅ Join our [community](https://join.slack.com/t/discuss-neuralmagic/shared_invite/zt-q1a1cnvo-YBoICSIw3L1dmQpjBeDurQ) if you need any help
or [subscribe](https://neuralmagic.com/deep-sparse-community/#subscribe) for regular Neural Magic email updates.

✅ Check out our [GitHub repositories](https://github.com/neuralmagic) and give us a ⭐ as we appreciate the community support!

✅ Contribute to our various repos [on GitHub](https://github.com/neuralmagic) or help us improve this [documentation](https://github.com/neuralmagic/docs).
