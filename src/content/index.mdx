---
title: "Home"
metaTitle: "Neural Magic Documentation"
metaDescription: "Documentation for Neural Magic"
index: 0
---

# Neural Magic Documentation

Welcome to software-delivered AI...Welcome to Neural Magic! We enable you to deploy deep learning models on commodity CPUs with GPU-class performance.

Through our guided experiences and documentation, you can discover how to unlock the full potential of your ML environment and accommodate the continuous growth of neural networks without adding complexity or cost.

[infographic]

You can integrate ML into your application quickly using DeepSparse, which is an inference runtime offering GPU class performance on CPUs and APIs for the fastest AI performance. Alternatively, you can select a model to deploy, which  can be your own model or one from Neural Magic’s SparseZoo—an open-source model repository for sparse and sparse-quantized models. Or, you can work from your dataset.

Next, you would either export a dense ONNX model or sparsify your model. You can use Neural Magic’s Sparsify—an ML optimization product, to accelerate inference at scale. Or, use SparseML—an open-source sparsification research framework. And then you can deploy with DeepSparse. Because DeepSparse reaches GPU-class performance with commodity CPUs, you do not need to tether deployments to accelerators in order to reach the performance needed for production.

This was a quick look at Neural Magic’s suite of products. Now, we invite you to explore our products through guided experiences and documentation.

## External Resources

✅ Join our [community](https://join.slack.com/t/discuss-neuralmagic/shared_invite/zt-q1a1cnvo-YBoICSIw3L1dmQpjBeDurQ) if you need any help
or [subscribe](https://neuralmagic.com/deep-sparse-community/#subscribe) for regular email updates.

✅ Check out our [GitHub repositories](https://github.com/neuralmagic) and give us a ⭐.

✅ Help us improve this [documentation](https://github.com/neuralmagic/docs).
