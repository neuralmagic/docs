---
title: "Sparsifying"
metaTitle: "Sparsifying Image Classification Models with SparseML"
metaDescription: "Sparsifying Image Classification models with SparseML to create cheaper and more performant models"
githubURL: "https://github.com/neuralmagic/docs/blob/main/src/content/use-cases/image-classification/sparsifying.mdx"
index: 1000
---

# Sparsifying Image Classification Models with SparseML

This page explains how to create a sparse image classification model.

SparseML Image Classification pipeline integrates with torch and torchvision libraries to enable the sparsification of popular image classification model.
Sparsification is a powerful technique that results in faster, smaller, and cheaper deployable models.
After training, the model can be deployed with Neural Magic's DeepSparse Engine. The engine enables inference with GPU-class performance directly on your CPU.

This integration enables you to create a sparse model in two ways:
- **Sparsification of Popular Torchvision Models** - easily sparsify popular torchvision image classification models.
- **Sparse Transfer Learning** - fine-tune a sparse backbone model (or use one of our [sparse pre-trained models](https://sparsezoo.neuralmagic.com/?domain=cv&sub_domain=classification&page=1)) on your own private dataset.

Each option is useful in different situations:
- **Sparsification from Scratch** enables you to create a sparse version of any model (even those not in the SparseZoo), but requires hand-tuning the hyperparameters of the Sparsification algorithm.
- **Sparse Transfer Learning** is the easiest path to creating a sparse model trained on your data. Simply pull a pre-sparsified model and transfer learning recipe from the SparseZoo and fine-tune on your data with a single command.

## Installation

We recommend using a virtualenv to install dependencies.
```bash
pip install sparseml[torchvision]
```

## Tutorials

- [Sparsifying PyTorch Models Using Recipes](https://github.com/neuralmagic/sparseml/blob/main/integrations/pytorch/tutorials/sparsifying_pytorch_models_using_recipes.md)
- [Sparse Transfer Learning for Image Classification](https://github.com/neuralmagic/sparseml/blob/main/integrations/pytorch/tutorials/classification_sparse_transfer_learning_tutorial.md)

## Getting Started
### Sparsifying Image Classification Models

In the example below, a dense ResNet model is sparsified and fine-tuned on the Imagenette dataset.

```bash
sparseml.image_classification.train \
    --recipe-path "zoo:cv/classification/resnet_v1-50/pytorch/sparseml/imagenette/pruned-conservative?recipe_type=original" \
    --dataset-path ./data \
    --pretrained True \
    --arch-key resnet50 \
    --dataset imagenette \
    --train-batch-size 128 \
    --test-batch-size 256 \
    --loader-num-workers 8 \
    --save-dir sparsification_example \
    --logs-dir sparsification_example \
    --model-tag resnet50-imagenette-pruned \
    --save-best-after 8
```

The most important arguments are `--dataset_path` and `--recipe_path`:
- `--dataset_path` argument indicates which model to start the pruning process from. It can be a SparseZoo stub or a path to a local model.
- `--recipe_path` argument instructs SparseML to run the sparsification process during the training loop. It can either be the stub of a recipe in the SparseZoo or a path to a local custom recipe. For more on creating a recipe see [here](/user-guide/recipes/creating).

### Sparse Transfer Learning

SparseML also enables you to fine-tune a pre-sparsified model onto your own dataset.
While you are free to use your backbone, we encourage you to leverage one of our [sparse pre-trained models](https://sparsezoo.neuralmagic.com) to boost your productivity!

The command below fetches a pruned ResNet model, pre-trained on ImageNet dataset from the SparseZoo and then fine-tunes the model on the Imagenette dataset while preserving sparsity.
```bash
sparseml.image_classification.train \
    --recipe-path zoo:cv/classification/resnet_v1-50/pytorch/sparseml/imagenet/pruned95-none?recipe_type=transfer-classification \
    --checkpoint-path zoo \
    --arch-key resnet50 \
    --model-kwargs '{"ignore_error_tensors": ["classifier.fc.weight", "classifier.fc.bias"]}' \
    --dataset imagenette \
    --dataset-path /PATH/TO/IMAGENETTE  \
    --train-batch-size 32 \
    --test-batch-size 64 \
    --loader-num-workers 0 \
    --optim Adam \
    --optim-args '{}' \
    --model-tag resnet50-imagenette-transfer-learned
```

## SparseML CLI

SparseML installation provides a CLI for sparsifying your models for a specific task;
appending the `--help` argument displays a full list of options for training in SparseML:
```bash
sparseml.image_classification.train --help

> Usage: sparseml.image_classification.train [OPTIONS]
>
>   PyTorch training integration with SparseML for image classification models
>
> Options:
>   --train-batch-size, --train_batch_size INTEGER
>                                   Train batch size  [required]
>   --test-batch-size, --test_batch_size INTEGER
>                                   Test/Validation batch size  [required]
>   --dataset TEXT                  The dataset to use for training, ex:
>                                   `imagenet`, `imagenette`, `cifar10`, etc.
>                                   Set to `imagefolder` for a generic dataset
>                                   setup with imagefolder type structure like
>                                   imagenet or loadable by a dataset in
>                                   `sparseml.pytorch.datasets`  [required]
>   --dataset-path, --dataset_path DIRECTORY
>                                   The root dir path where the dataset is
>                                   stored or should be downloaded to if
>                                   available  [required]
>   --arch_key, --arch-key TEXT     The architecture key for image
>                                   classification model; example: `resnet50`,
>                                   `mobilenet`. Note: Will be read from the
>                                   checkpoint if not specified
>   --checkpoint-path, --checkpoint_path TEXT
>                                   A path to a previous checkpoint to load the
>                                   state from and resume the state for. If
>                                   provided, pretrained will be ignored . If
>                                   using a SparseZoo recipe, can also provide
>                                   'zoo' to load the base weights associated
>                                   with that recipe. Additionally, can also
>                                   provide a SparseZoo model stub to load model
>                                   weights from SparseZoo
>   ...
```

## Exporting to ONNX

The artifacts of the training process are saved to `--save-dir` under `--model-tag`.
Once the script terminates, you should find everything required to deploy or further modify the model,
including the recipe (with the full description of the sparsification attributes),
checkpoint files (saved in the appropriate framework format), etc.

### Exporting the Sparse Model to ONNX

The DeepSparse Engine uses the ONNX format to load neural networks and then
deliver breakthrough performance for CPUs by leveraging the sparsity and quantization within a network.

The SparseML installation provides a `sparseml.image_classification.export_onnx`
command that you can use to load the checkpoint and create a new `model.onnx` file in the same directory the
framework directory is stored.
Be sure the `--model_path` argument points to your trained `model.pth` or `checkpoint-best.pth` file.
Both are included in `<save-dir>/<model-tag>/framework/` from the sparsification run.

```bash
sparseml.image_classification.export_onnx \
    --arch-key resnet50 \
    --dataset imagenet \
    --dataset-path ./data/imagenette-160 \
    --checkpoint-path sparsification_example/resnet50-imagenette-pruned/framework/model.pth
```
