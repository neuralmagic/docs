---
sidebar_position: 0
---

# nm-vllm

## GitHub

<DocCardList>
    <a href="https://github.com/neuralmagic/nm-vllm">
        <h3>nm-vllm</h3>
        <p>nm-vllm is a high-throughput and memory-efficient inference and serving engine for LLMs.</p>
    </a>
</DocCardList>