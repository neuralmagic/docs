

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Models &mdash; SparseZoo 0.1.0 documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/copybutton.css" type="text/css" />

  
  
    <link rel="shortcut icon" href="_static/favicon.ico"/>
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/clipboard.min.js"></script>
        <script src="_static/copybutton.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Recipes" href="recipes.html" />
    <link rel="prev" title="Installation" href="installation.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> SparseZoo
          

          
            
            <img src="_static/icon-sparsezoo.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                0.1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">General</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="quicktour.html">Quick Tour</a></li>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#image-classification">Image Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="#object-detection">Object Detection</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="recipes.html">Recipes</a></li>
</ul>
<p class="caption"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="api/sparsezoo.html">sparsezoo package</a></li>
</ul>
<p class="caption"><span class="caption-text">Help</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://github.com/neuralmagic/sparsezoo/issues">Bugs, Feature Requests</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/neuralmagic/sparsezoo/discussions">Support, General Q&amp;A</a></li>
<li class="toctree-l1"><a class="reference external" href="https://docs.neuralmagic.com">Neural Magic Docs</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">SparseZoo</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Models</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/models.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <!--
Copyright (c) 2021 - present / Neuralmagic, Inc. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing,
software distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
--><div class="section" id="models">
<h1>Models<a class="headerlink" href="#models" title="Permalink to this headline">¶</a></h1>
<p>Each model in the SparseZoo has a specific stub that identifies it. The stubs are made up of the following structure:</p>
<p><code class="docutils literal notranslate"><span class="pre">DOMAIN/SUB_DOMAIN/ARCHITECTURE{-SUB_ARCHITECTURE}/FRAMEWORK/REPO/DATASET{-TRAINING_SCHEME}/SPARSE_NAME-SPARSE_CATEGORY-{SPARSE_TARGET}</span></code></p>
<p>The properties within each model stub are defined as the following:</p>
<table border="1" class="docutils">
<thead>
<tr>
<th align="center">Model Property</th>
<th align="center">Definition</th>
<th align="center">Examples</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">DOMAIN</td>
<td align="center">The type of solution the model is architected and trained for</td>
<td align="center">cv, nlp</td>
</tr>
<tr>
<td align="center">SUB_DOMAIN</td>
<td align="center">The sub type of solution the model is architected and trained for</td>
<td align="center">classification, segmentation</td>
</tr>
<tr>
<td align="center">ARCHITECTURE</td>
<td align="center">The name of the guiding setup for the network's graph</td>
<td align="center">resnet_v1, mobilenet_v1</td>
</tr>
<tr>
<td align="center">SUB_ARCHITECTURE</td>
<td align="center">(optional) The scaled version of the architecture such as width or depth</td>
<td align="center">50, 101, 152</td>
</tr>
<tr>
<td align="center">FRAMEWORK</td>
<td align="center">The machine learning framework the model was defined and trained in</td>
<td align="center">pytorch, tensorflow_v1</td>
</tr>
<tr>
<td align="center">REPO</td>
<td align="center">The model repository the model and baseline weights originated from</td>
<td align="center">sparseml, torchvision</td>
</tr>
<tr>
<td align="center">DATASET</td>
<td align="center">The dataset the model was trained on</td>
<td align="center">imagenet, cifar10</td>
</tr>
<tr>
<td align="center">TRAINING_SCHEME</td>
<td align="center">(optional) A description on how the model was trained</td>
<td align="center">augmented, lower_lr</td>
</tr>
<tr>
<td align="center">SPARSE_NAME</td>
<td align="center">An overview of what was done to sparsify the model</td>
<td align="center">base, pruned, quant (quantized), pruned_quant, arch (architecture modified)</td>
</tr>
<tr>
<td align="center">SPARSE_CATEGORY</td>
<td align="center">Descriptor on the degree to which the model is sparsified as compared with the baseline metric</td>
<td align="center">none, conservative (100% baseline), moderate (&gt;= 99% baseline), aggressive (&lt; 99%)</td>
</tr>
<tr>
<td align="center">SPARSE_TARGET</td>
<td align="center">(optional) Descriptor for the target environment the model was sparsified for</td>
<td align="center">disk, edge, deepsparse, gpu</td>
</tr>
</tbody>
</table><p>The contents of each model are made up of the following:</p>
<ul class="simple">
<li><p>model.md: The model card containing metadata, descriptions, and information for the model.</p></li>
<li><p>model.onnx: The <a class="reference external" href="https://onnx.ai/">ONNX</a> representation of the model’s graph.</p></li>
<li><p>model.onnx.tar.gz: A compressed format for the ONNX file.
Currently ONNX does not support sparse tensors and quantized sparse tensors well for compression.</p></li>
<li><p>[FRAMEWORK]/model.[EXTENSION]: The native ML framework file(s) for the model in which it was originally trained.
Such as PyTorch, Keras, TensorFlow V1</p></li>
<li><p>recipes/original.[md|yaml]: The original sparsification recipe used to create the model.</p></li>
<li><p>recipes/[NAME].[md|yaml]: Additional sparsification recipes that can be used with the model such as transfer learning.</p></li>
<li><p>sample-originals: The original sample data without any preprocessing for use with the model.</p></li>
<li><p>sample-inputs: The sample data after pre processing for use with the model.</p></li>
<li><p>sample-outputs: The outputs after running the sample inputs through the model.</p></li>
<li><p>sample-labels: The labels that classify the sample inputs.</p></li>
</ul>
<div class="section" id="image-classification">
<h2>Image Classification<a class="headerlink" href="#image-classification" title="Permalink to this headline">¶</a></h2>
<table border="1" class="docutils">
<thead>
<tr>
<th>Model Tag</th>
<th>Validation Baseline Metric</th>
</tr>
</thead>
<tbody>
<tr>
<td>cv/classification/efficientnet-b0/pytorch/sparseml/imagenet/base-none</td>
<td>77.3% top1 accuracy</td>
</tr>
<tr>
<td>cv/classification/efficientnet-b0/pytorch/sparseml/imagenet/arch-moderate</td>
<td>76.5% top1 accuracy</td>
</tr>
<tr>
<td>cv/classification/efficientnet-b4/pytorch/sparseml/imagenet/base-none</td>
<td>83.0% top1 accuracy</td>
</tr>
<tr>
<td>cv/classification/efficientnet-b4/pytorch/sparseml/imagenet/arch-moderate</td>
<td>82.1% top1 accuracy</td>
</tr>
<tr>
<td>cv/classification/inception_v3/pytorch/sparseml/imagenet/base-none</td>
<td>77.4% top1 accuracy</td>
</tr>
<tr>
<td>cv/classification/inception_v3/pytorch/sparseml/imagenet/pruned-conservative</td>
<td>77.4% top1 accuracy</td>
</tr>
<tr>
<td>cv/classification/inception_v3/pytorch/sparseml/imagenet/pruned-moderate</td>
<td>76.6% top1 accuracy</td>
</tr>
<tr>
<td>cv/classification/mnistnet/pytorch/sparseml/mnist/base-none</td>
<td>99.4% top1 accuracy</td>
</tr>
<tr>
<td>cv/classification/mobilenet_v1-1.0/pytorch/sparseml/imagenet/base-none</td>
<td>70.9% top1 accuracy</td>
</tr>
<tr>
<td>cv/classification/mobilenet_v1-1.0/pytorch/sparseml/imagenet/pruned-conservative</td>
<td>70.9% top1 accuracy</td>
</tr>
<tr>
<td>cv/classification/mobilenet_v1-1.0/pytorch/sparseml/imagenet/pruned-moderate</td>
<td>70.1% top1 accuracy</td>
</tr>
<tr>
<td>cv/classification/mobilenet_v1-1.0/pytorch/sparseml/imagenet/pruned_quant-moderate</td>
<td>70.1% top1 accuracy</td>
</tr>
<tr>
<td>cv/classification/mobilenet_v2-1.0/pytorch/sparseml/imagenet/base-none</td>
<td>71.9% top1 accuracy</td>
</tr>
<tr>
<td>cv/classification/resnet_v1-101/pytorch/sparseml/imagenet/base-none</td>
<td>77.4% top1 accuracy</td>
</tr>
<tr>
<td>cv/classification/resnet_v1-101/pytorch/sparseml/imagenet/pruned-moderate</td>
<td>76.6% top1 accuracy</td>
</tr>
<tr>
<td>cv/classification/resnet_v1-101/pytorch/torchvision/imagenet/base-none</td>
<td>76.6% top1 accuracy</td>
</tr>
<tr>
<td>cv/classification/resnet_v1-101_2x/pytorch/sparseml/imagenet/base-none</td>
<td>78.8% top1 accuracy</td>
</tr>
<tr>
<td>cv/classification/resnet_v1-101_2x/pytorch/torchvision/imagenet/base-none</td>
<td>78.8% top1 accuracy</td>
</tr>
<tr>
<td>cv/classification/resnet_v1-152/pytorch/sparseml/imagenet/base-none</td>
<td>78.3% top1 accuracy</td>
</tr>
<tr>
<td>cv/classification/resnet_v1-152/pytorch/sparseml/imagenet/pruned-moderate</td>
<td>77.5% top1 accuracy</td>
</tr>
<tr>
<td>cv/classification/resnet_v1-152/pytorch/torchvision/imagenet/base-none</td>
<td>77.5% top1 accuracy</td>
</tr>
<tr>
<td>cv/classification/resnet_v1-18/pytorch/sparseml/imagenet/base-none</td>
<td>69.8% top1 accuracy</td>
</tr>
<tr>
<td>cv/classification/resnet_v1-18/pytorch/sparseml/imagenet/pruned-conservative</td>
<td>69.8% top1 accuracy</td>
</tr>
<tr>
<td>cv/classification/resnet_v1-18/pytorch/torchvision/imagenet/base-none</td>
<td>69.8% top1 accuracy</td>
</tr>
<tr>
<td>cv/classification/resnet_v1-34/pytorch/sparseml/imagenet/base-none</td>
<td>73.3% top1 accuracy</td>
</tr>
<tr>
<td>cv/classification/resnet_v1-34/pytorch/sparseml/imagenet/pruned-conservative</td>
<td>73.3% top1 accuracy</td>
</tr>
<tr>
<td>cv/classification/resnet_v1-34/pytorch/torchvision/imagenet/base-none</td>
<td>73.3% top1 accuracy</td>
</tr>
<tr>
<td>cv/classification/resnet_v1-50/pytorch/sparseml/imagenet/base-none</td>
<td>76.1% top1 accuracy</td>
</tr>
<tr>
<td>cv/classification/resnet_v1-50/pytorch/sparseml/imagenet/pruned-conservative</td>
<td>76.1% top1 accuracy</td>
</tr>
<tr>
<td>cv/classification/resnet_v1-50/pytorch/sparseml/imagenet/pruned-moderate</td>
<td>75.3% top1 accuracy</td>
</tr>
<tr>
<td>cv/classification/resnet_v1-50/pytorch/sparseml/imagenet/pruned_quant-moderate</td>
<td>75.4% top1 accuracy</td>
</tr>
<tr>
<td>cv/classification/resnet_v1-50/pytorch/sparseml/imagenet-augmented/pruned_quant-aggressive</td>
<td>76.1% top1 accuracy</td>
</tr>
<tr>
<td>cv/classification/resnet_v1-50/pytorch/sparseml/imagenette/base-none</td>
<td>99.9% top1 accuracy</td>
</tr>
<tr>
<td>cv/classification/resnet_v1-50/pytorch/sparseml/imagenette/pruned-conservative</td>
<td>99.9% top1 accuracy</td>
</tr>
<tr>
<td>cv/classification/resnet_v1-50/pytorch/torchvision/imagenet/base-none</td>
<td>99.9% top1 accuracy</td>
</tr>
<tr>
<td>cv/classification/resnet_v1-50/pytorch/torchvision/imagenette/pruned-conservative</td>
<td>99.9% top1 accuracy</td>
</tr>
<tr>
<td>cv/classification/resnet_v1-50_2x/pytorch/sparseml/imagenet/base-none</td>
<td>78.1% top1 accuracy</td>
</tr>
<tr>
<td>cv/classification/resnet_v1-50_2x/pytorch/torchvision/imagenet/base-none</td>
<td>78.1% top1 accuracy</td>
</tr>
<tr>
<td>cv/classification/vgg-11/pytorch/sparseml/imagenet/base-none</td>
<td>69.0% top1 accuracy</td>
</tr>
<tr>
<td>cv/classification/vgg-11/pytorch/sparseml/imagenet/pruned-moderate</td>
<td>68.3% top1 accuracy</td>
</tr>
<tr>
<td>cv/classification/vgg-11/pytorch/torchvision/imagenet/base-none</td>
<td>68.3% top1 accuracy</td>
</tr>
<tr>
<td>cv/classification/vgg-11_bn/pytorch/sparseml/imagenet/base-none</td>
<td>70.4% top1 accuracy</td>
</tr>
<tr>
<td>cv/classification/vgg-11_bn/pytorch/torchvision/imagenet/base-none</td>
<td>70.4% top1 accuracy</td>
</tr>
<tr>
<td>cv/classification/vgg-13/pytorch/sparseml/imagenet/base-none</td>
<td>69.9% top1 accuracy</td>
</tr>
<tr>
<td>cv/classification/vgg-13/pytorch/torchvision/imagenet/base-none</td>
<td>69.9% top1 accuracy</td>
</tr>
<tr>
<td>cv/classification/vgg-13_bn/pytorch/sparseml/imagenet/base-none</td>
<td>71.5% top1 accuracy</td>
</tr>
<tr>
<td>cv/classification/vgg-13_bn/pytorch/torchvision/imagenet/base-none</td>
<td>71.5% top1 accuracy</td>
</tr>
<tr>
<td>cv/classification/vgg-16/pytorch/sparseml/imagenet/base-none</td>
<td>71.6% top1 accuracy</td>
</tr>
<tr>
<td>cv/classification/vgg-16/pytorch/sparseml/imagenet/pruned-conservative</td>
<td>71.6% top1 accuracy</td>
</tr>
<tr>
<td>cv/classification/vgg-16/pytorch/sparseml/imagenet/pruned-moderate</td>
<td>70.8% top1 accuracy</td>
</tr>
<tr>
<td>cv/classification/vgg-16/pytorch/torchvision/imagenet/base-none</td>
<td>70.8% top1 accuracy</td>
</tr>
<tr>
<td>cv/classification/vgg-16_bn/pytorch/sparseml/imagenet/base-none</td>
<td>71.6% top1 accuracy</td>
</tr>
<tr>
<td>cv/classification/vgg-16_bn/pytorch/torchvision/imagenet/base-none</td>
<td>71.6% top1 accuracy</td>
</tr>
<tr>
<td>cv/classification/vgg-19/pytorch/sparseml/imagenet/base-none</td>
<td>72.4% top1 accuracy</td>
</tr>
<tr>
<td>cv/classification/vgg-19/pytorch/sparseml/imagenet/pruned-moderate</td>
<td>71.7% top1 accuracy</td>
</tr>
<tr>
<td>cv/classification/vgg-19/pytorch/torchvision/imagenet/base-none</td>
<td>71.7% top1 accuracy</td>
</tr>
<tr>
<td>cv/classification/vgg-19_bn/pytorch/sparseml/imagenet/base-none</td>
<td>74.2% top1 accuracy</td>
</tr>
<tr>
<td>cv/classification/vgg-19_bn/pytorch/torchvision/imagenet/base-none</td>
<td>74.2% top1 accuracy</td>
</tr>
</tbody>
</table></div>
<div class="section" id="object-detection">
<h2>Object Detection<a class="headerlink" href="#object-detection" title="Permalink to this headline">¶</a></h2>
<table border="1" class="docutils">
<thead>
<tr>
<th>Model Tag</th>
<th>Validation Baseline Metric</th>
</tr>
</thead>
<tbody>
<tr>
<td>cv/detection/ssd-resnet50_300/pytorch/sparseml/coco/base-none</td>
<td>42.7 mAP@0.5</td>
</tr>
<tr>
<td>cv/detection/ssd-resnet50_300/pytorch/sparseml/coco/pruned-moderate</td>
<td>41.8 mAP@0.5</td>
</tr>
<tr>
<td>cv/detection/ssd-resnet50_300/pytorch/sparseml/voc/base-none</td>
<td>52.2 mAP@0.5</td>
</tr>
<tr>
<td>cv/detection/ssd-resnet50_300/pytorch/sparseml/voc/pruned-moderate</td>
<td>51.5 mAP@0.5</td>
</tr>
<tr>
<td>cv/detection/yolo_v3-spp/pytorch/ultralytics/coco/base-none</td>
<td>63.5 mAP@0.5</td>
</tr>
<tr>
<td>cv/detection/yolo_v3-spp/pytorch/ultralytics/coco/pruned-aggressive</td>
<td>62.1 mAP@0.5</td>
</tr>
</tbody>
</table></div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="recipes.html" class="btn btn-neutral float-right" title="Recipes" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="installation.html" class="btn btn-neutral float-left" title="Installation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021 - present / Neuralmagic, Inc. All Rights Reserved. Licensed under the Apache License, Version 2.0 (the &#34;License&#34;).

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-128364174-1', 'auto');
    
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>