"use strict";(self.webpackChunkdocs_neuralmagic_com=self.webpackChunkdocs_neuralmagic_com||[]).push([[8682],{5615:e=>{e.exports=JSON.parse('{"label":"neural magic","permalink":"/docs-v2/next/tags/neural-magic","allTagsPath":"/docs-v2/next/tags","count":4,"items":[{"id":"get-started/optimize","title":"Optimizing LLMs","description":"Optimize large language models (LLMs) for efficient inference using one-shot pruning and quantization. Learn how to improve model performance and reduce costs without sacrificing accuracy.","permalink":"/docs-v2/next/get-started/optimize"},{"id":"get-started/finetune","title":"Sparse Fine-Tuning With LLMs","description":"Improve the performance of your large language models (LLMs) through fine-tuning with Neural Magic\'s SparseML. Optimize LLMs for specific tasks while maintaining accuracy.","permalink":"/docs-v2/next/get-started/finetune"},{"id":"get-started/transfer","title":"Sparse Transferring LLMs","description":"Adapt large language models (LLMs) to new domains and tasks using sparse transfer learning with Neural Magic\'s SparseML. Maintain accuracy while optimizing for efficiency.","permalink":"/docs-v2/next/get-started/transfer"},{"id":"home","title":"What is Neural Magic?","description":"Neural Magic empowers you to optimize and deploy deep learning models on CPUs with GPU-class performance. Unlock efficiency, accessibility, and cost savings with our software solutions.","permalink":"/docs-v2/next/"}],"unlisted":false}')}}]);