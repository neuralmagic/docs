"use strict";(self.webpackChunkdocs_neuralmagic_com=self.webpackChunkdocs_neuralmagic_com||[]).push([[5485],{4730:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>d,contentTitle:()=>t,default:()=>h,frontMatter:()=>o,metadata:()=>r,toc:()=>l});var i=a(4848),s=a(8453);const o={tags:["to-do"],keywords:["to-do"],description:"Get sparse-CPU acceleration and automatic scaling on SageMaker.",sidebar_label:"Amazon SageMaker",sidebar_position:2},t="Deploying With DeepSparse on Amazon SageMaker",r={id:"guides/deploying-deepsparse/amazon-sagemaker",title:"Deploying With DeepSparse on Amazon SageMaker",description:"Get sparse-CPU acceleration and automatic scaling on SageMaker.",source:"@site/versioned_docs/version-1.7.0/guides/deploying-deepsparse/amazon-sagemaker.mdx",sourceDirName:"guides/deploying-deepsparse",slug:"/guides/deploying-deepsparse/amazon-sagemaker",permalink:"/guides/deploying-deepsparse/amazon-sagemaker",draft:!1,unlisted:!1,editUrl:"https://github.com/neuralmagic/docs/tree/main/docs/guides/deploying-deepsparse/amazon-sagemaker.mdx",tags:[{label:"to-do",permalink:"/tags/to-do"}],version:"1.7.0",sidebarPosition:2,frontMatter:{tags:["to-do"],keywords:["to-do"],description:"Get sparse-CPU acceleration and automatic scaling on SageMaker.",sidebar_label:"Amazon SageMaker",sidebar_position:2},sidebar:"tutorialSidebar",previous:{title:"DeepSparse Server",permalink:"/guides/deploying-deepsparse/deepsparse-server"},next:{title:"AWS Lambda",permalink:"/guides/deploying-deepsparse/aws-lambda"}},d={},l=[{value:"Installation Requirements",id:"installation-requirements",level:2},{value:"Quick Start",id:"quick-start",level:3},{value:"Contents",id:"contents",level:2},{value:"Dockerfile",id:"dockerfile",level:3},{value:"config.yaml",id:"configyaml",level:3},{value:"push_image.sh",id:"push_imagesh",level:3},{value:"endpoint.py",id:"endpointpy",level:3},{value:"qa_client.py",id:"qa_clientpy",level:3},{value:"Deploying to SageMaker",id:"deploying-to-sagemaker",level:2},{value:"Building the DeepSparse-SageMaker Image Locally",id:"building-the-deepsparse-sagemaker-image-locally",level:3},{value:"Creating an ECR Repository",id:"creating-an-ecr-repository",level:3},{value:"Pushing the Local Image to the ECR Repository",id:"pushing-the-local-image-to-the-ecr-repository",level:3},{value:"Creating a SageMaker Model",id:"creating-a-sagemaker-model",level:3},{value:"Building a SageMaker EndpointConfig",id:"building-a-sagemaker-endpointconfig",level:3},{value:"Launching a SageMaker Endpoint",id:"launching-a-sagemaker-endpoint",level:3},{value:"Making a Request to the Endpoint",id:"making-a-request-to-the-endpoint",level:2},{value:"Cleanup",id:"cleanup",level:3},{value:"Next Steps",id:"next-steps",level:2}];function c(e){const n={a:"a",br:"br",code:"code",h1:"h1",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.h1,{id:"deploying-with-deepsparse-on-amazon-sagemaker",children:"Deploying With DeepSparse on Amazon SageMaker"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.a,{href:"https://docs.aws.amazon.com/sagemaker/index.html",children:"Amazon SageMaker"}),"\noffers an easy-to-use infrastructure for deploying deep learning models at scale.\nThis directory provides a guided example for deploying a\n",(0,i.jsx)(n.a,{href:"https://github.com/neuralmagic/deepsparse",children:"DeepSparse"})," inference server on SageMaker for the question answering NLP task.\nDeployments benefit from both sparse-CPU acceleration with\nDeepSparse and automatic scaling from SageMaker."]}),"\n",(0,i.jsx)(n.h2,{id:"installation-requirements",children:"Installation Requirements"}),"\n",(0,i.jsxs)(n.p,{children:["The listed steps can be easily completed using ",(0,i.jsx)(n.code,{children:"python"})," and ",(0,i.jsx)(n.code,{children:"bash"}),". The following\ncredentials, tools, and libraries are also required:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.a,{href:"https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html",children:"AWS CLI"})," version 2.X that is ",(0,i.jsx)(n.a,{href:"https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-quickstart.html",children:"configured"}),". Double-check if the ",(0,i.jsx)(n.code,{children:"region"})," that is configured in your AWS CLI matches the region in the SparseMaker class found in the ",(0,i.jsx)(n.code,{children:"endpoint.py"})," file. Currently, the default region being used is ",(0,i.jsx)(n.code,{children:"us-east-1"}),"."]}),"\n",(0,i.jsxs)(n.li,{children:["The ",(0,i.jsx)(n.a,{href:"https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html",children:"ARN"})," of your AWS role requires access to full SageMaker permissions.","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.code,{children:"AmazonSageMakerFullAccess"})}),"\n",(0,i.jsxs)(n.li,{children:["In the following steps, we will refer to this as ",(0,i.jsx)(n.code,{children:"ROLE_ARN"}),". It should take the form ",(0,i.jsx)(n.code,{children:'"arn:aws:iam::XXX:role/service-role/XXX"'}),". In addition to role permissions, make sure the AWS user who configured the AWS CLI configuration has ECR/SageMaker permissions."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsxs)(n.a,{href:"https://docs.docker.com/get-docker/",children:["Docker and the ",(0,i.jsx)(n.code,{children:"docker"})," CLI"]}),"."]}),"\n",(0,i.jsxs)(n.li,{children:["The ",(0,i.jsx)(n.code,{children:"boto3"})," Python AWS SDK (",(0,i.jsx)(n.code,{children:"pip install boto3"}),")."]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"quick-start",children:"Quick Start"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"git clone https://github.com/neuralmagic/deepsparse.git\ncd deepsparse/examples/aws-sagemaker\npip install -r requirements.txt\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsxs)(n.strong,{children:["Before starting, replace the ",(0,i.jsx)(n.code,{children:"role_arn"})," PLACEHOLDER string with your AWS ",(0,i.jsx)(n.a,{href:"https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html",children:"ARN"})," at the bottom of SparseMaker class on the ",(0,i.jsx)(n.code,{children:"endpoint.py"})," file. Your ARN should look something like this:"]})," ",(0,i.jsx)(n.code,{children:'"arn:aws:iam::XXX:role/service-role/XXX"'})]}),"\n",(0,i.jsx)(n.p,{children:"Run the following command to build your SageMaker endpoint."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"python endpoint.py create\n"})}),"\n",(0,i.jsxs)(n.p,{children:["After the endpoint has been staged (~1 minute), you can start making requests by passing your endpoint ",(0,i.jsx)(n.code,{children:"region name"})," and your ",(0,i.jsx)(n.code,{children:"endpoint name"}),". Afterward, you can run inference by passing in your question and context:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from qa_client import Endpoint\n\n\nqa = Endpoint("us-east-1", "question-answering-example-endpoint")\nanswer = qa.predict(question="who is batman?", context="Mark is batman.")\n\nprint(answer)\n'})}),"\n",(0,i.jsxs)(n.p,{children:["The answer is: ",(0,i.jsx)(n.code,{children:'b\'{"score":0.6484262943267822,"answer":"Mark","start":0,"end":4}\''})]}),"\n",(0,i.jsx)(n.p,{children:"If you want to delete your endpoint, use:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"python endpoint.py destroy\n"})}),"\n",(0,i.jsx)(n.p,{children:"Continue reading to learn more about the files in this directory, the build requirements, and a descriptive step-by-step guide for launching a SageMaker endpoint."}),"\n",(0,i.jsx)(n.h2,{id:"contents",children:"Contents"}),"\n",(0,i.jsx)(n.p,{children:"In addition to the step-by-step instructions below, the directory contains\nfiles to aid in the deployment."}),"\n",(0,i.jsx)(n.h3,{id:"dockerfile",children:"Dockerfile"}),"\n",(0,i.jsxs)(n.p,{children:["The included ",(0,i.jsx)(n.code,{children:"Dockerfile"})," builds an image on top of the standard ",(0,i.jsx)(n.code,{children:"python:3.8"})," image\nwith ",(0,i.jsx)(n.code,{children:"deepsparse"})," installed, and creates an executable command ",(0,i.jsx)(n.code,{children:"serve"})," that runs\n",(0,i.jsx)(n.code,{children:"deepsparse.server"})," on port 8080. SageMaker will execute this image by running\n",(0,i.jsx)(n.code,{children:"docker run serve"})," and expects the image to serve inference requests at the\n",(0,i.jsx)(n.code,{children:"invocations/"})," endpoint."]}),"\n",(0,i.jsxs)(n.p,{children:["For general customization of the server, changes should not need to be made\nto the Dockerfile but, instead, to the ",(0,i.jsx)(n.code,{children:"config.yaml"})," file from which the Dockerfile reads."]}),"\n",(0,i.jsx)(n.h3,{id:"configyaml",children:"config.yaml"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.code,{children:"config.yaml"})," is used to configure DeepSparse Server running in the Dockerfile.\nThe configuration must contain the line ",(0,i.jsx)(n.code,{children:"integration: sagemaker"})," so\nendpoints may be provisioned correctly to match SageMaker specifications."]}),"\n",(0,i.jsxs)(n.p,{children:["Notice that the ",(0,i.jsx)(n.code,{children:"model_path"})," and ",(0,i.jsx)(n.code,{children:"task"})," are set to run a sparse-quantized\nquestion answering model from ",(0,i.jsx)(n.a,{href:"https://sparsezoo.neuralmagic.com/",children:"SparseZoo"}),".\nTo use a model directory stored in ",(0,i.jsx)(n.code,{children:"s3"}),", set ",(0,i.jsx)(n.code,{children:"model_path"})," to ",(0,i.jsx)(n.code,{children:"/opt/ml/model"})," in\nthe configuration and add ",(0,i.jsx)(n.code,{children:"ModelDataUrl=<MODEL-S3-PATH>"})," to the ",(0,i.jsx)(n.code,{children:"CreateModel"})," arguments.\nSageMaker will automatically copy the files from the s3 path into ",(0,i.jsx)(n.code,{children:"/opt/ml/model"}),"\nfrom which the server then can read."]}),"\n",(0,i.jsx)(n.h3,{id:"push_imagesh",children:"push_image.sh"}),"\n",(0,i.jsxs)(n.p,{children:["This is a ",(0,i.jsx)(n.code,{children:"Bash"})," script for pushing your local Docker image to the AWS ECR repository."]}),"\n",(0,i.jsx)(n.h3,{id:"endpointpy",children:"endpoint.py"}),"\n",(0,i.jsx)(n.p,{children:"This file contains the SparseMaker object for automating the build of a SageMaker endpoint from a Docker image. You have the option to customize the parameters of the class in order to match the preferred state of your deployment."}),"\n",(0,i.jsx)(n.h3,{id:"qa_clientpy",children:"qa_client.py"}),"\n",(0,i.jsx)(n.p,{children:"This file contains a client object for making requests to the SageMaker inference endpoint for the question answering task."}),"\n",(0,i.jsxs)(n.p,{children:["Review ",(0,i.jsx)(n.a,{href:"https://github.com/neuralmagic/deepsparse/tree/main/src/deepsparse/server#readme",children:"DeepSparse Server"})," for more information about the server and its configuration."]}),"\n",(0,i.jsx)(n.h2,{id:"deploying-to-sagemaker",children:"Deploying to SageMaker"}),"\n",(0,i.jsx)(n.p,{children:"The following steps are required to provision and deploy DeepSparse to SageMaker\nfor inference:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Build the DeepSparse-SageMaker ",(0,i.jsx)(n.code,{children:"Dockerfile"})," into a local docker image."]}),"\n",(0,i.jsxs)(n.li,{children:["Create an ",(0,i.jsx)(n.a,{href:"https://aws.amazon.com/ecr/",children:"Amazon ECR"})," repository to host the image."]}),"\n",(0,i.jsx)(n.li,{children:"Push the image to the ECR repository."}),"\n",(0,i.jsxs)(n.li,{children:["Create a SageMaker ",(0,i.jsx)(n.code,{children:"Model"})," that reads from the hosted ECR image."]}),"\n",(0,i.jsxs)(n.li,{children:["Build a SageMaker ",(0,i.jsx)(n.code,{children:"EndpointConfig"})," that defines how to provision the model deployment."]}),"\n",(0,i.jsxs)(n.li,{children:["Launch the SageMaker ",(0,i.jsx)(n.code,{children:"Endpoint"})," defined by the ",(0,i.jsx)(n.code,{children:"Model"})," and ",(0,i.jsx)(n.code,{children:"EndpointConfig"}),"."]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"building-the-deepsparse-sagemaker-image-locally",children:"Building the DeepSparse-SageMaker Image Locally"}),"\n",(0,i.jsxs)(n.p,{children:["Build the ",(0,i.jsx)(n.code,{children:"Dockerfile"})," from this directory from a bash shell using the following command.\nThe image will be tagged locally as ",(0,i.jsx)(n.code,{children:"deepsparse-sagemaker-example"}),"."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"docker build -t deepsparse-sagemaker-example .\n"})}),"\n",(0,i.jsx)(n.h3,{id:"creating-an-ecr-repository",children:"Creating an ECR Repository"}),"\n",(0,i.jsxs)(n.p,{children:["Use the following code snippet in Python to create an ECR repository.\nThe ",(0,i.jsx)(n.code,{children:"region_name"})," can be swapped to a preferred region. The repository will be named\n",(0,i.jsx)(n.code,{children:"deepsparse-sagemaker"}),".  If the repository is already created, you may skip this step."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import boto3\n\necr = boto3.client("ecr", region_name=\'us-east-1\')\ncreate_repository_res = ecr.create_repository(repositoryName="deepsparse-sagemaker")\n'})}),"\n",(0,i.jsx)(n.h3,{id:"pushing-the-local-image-to-the-ecr-repository",children:"Pushing the Local Image to the ECR Repository"}),"\n",(0,i.jsx)(n.p,{children:"Once the image is built and the ECR repository is created, you can push the image using the following\nbash commands."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"account=$(aws sts get-caller-identity --query Account | sed -e 's/^\"//' -e 's/\"$//')\nregion=$(aws configure get region)\necr_account=${account}.dkr.ecr.${region}.amazonaws.com\n\naws ecr get-login-password --region $region | docker login --username AWS --password-stdin $ecr_account\nfullname=$ecr_account/deepsparse-sagemaker:latest\n\ndocker tag deepsparse-sagemaker-example:latest $fullname\ndocker push $fullname\n"})}),"\n",(0,i.jsx)(n.p,{children:"An abbreviated successful output will look like:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"Login Succeeded\nThe push refers to repository [XXX.dkr.ecr.us-east-1.amazonaws.com/deepsparse-example]\n3c2284f66840: Preparing\n08fa02ce37eb: Preparing\na037458de4e0: Preparing\nbafdbe68e4ae: Preparing\na13c519c6361: Preparing\n6817758dd480: Waiting\n6d95196cbe50: Waiting\ne9872b0f234f: Waiting\nc18b71656bcf: Waiting\n2174eedecc00: Waiting\n03ea99cd5cd8: Pushed\n585a375d16ff: Pushed\n5bdcc8e2060c: Pushed\nlatest: digest: sha256:XXX size: 3884\n"})}),"\n",(0,i.jsx)(n.h3,{id:"creating-a-sagemaker-model",children:"Creating a SageMaker Model"}),"\n",(0,i.jsxs)(n.p,{children:["Create a SageMaker ",(0,i.jsx)(n.code,{children:"Model"})," referencing the pushed image.\nThe example model will be named ",(0,i.jsx)(n.code,{children:"question-answering-example"}),".\nAs mentioned in the requirements, ",(0,i.jsx)(n.code,{children:"ROLE_ARN"})," should be a string arn of an AWS\nrole with full access to SageMaker."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import boto3\n\nsm_boto3 = boto3.client("sagemaker", region_name="us-east-1")\n\nregion = boto3.Session().region_name\naccount_id = boto3.client("sts").get_caller_identity()["Account"]\n\nimage_uri = "{}.dkr.ecr.{}.amazonaws.com/deepsparse-sagemaker:latest".format(account_id, region)\n\ncreate_model_res = sm_boto3.create_model(\n    ModelName="question-answering-example",\n    Containers=[\n        {\n            "Image": image_uri,\n        },\n    ],\n    ExecutionRoleArn=ROLE_ARN,\n    EnableNetworkIsolation=False,\n)\n'})}),"\n",(0,i.jsxs)(n.p,{children:["Refer to ",(0,i.jsx)(n.a,{href:"https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateModel.html",children:"AWS documentation"})," for more information about options for configuring SageMaker ",(0,i.jsx)(n.code,{children:"Model"})," instances."]}),"\n",(0,i.jsx)(n.h3,{id:"building-a-sagemaker-endpointconfig",children:"Building a SageMaker EndpointConfig"}),"\n",(0,i.jsxs)(n.p,{children:["The ",(0,i.jsx)(n.code,{children:"EndpointConfig"})," is used to set the instance type to provision, how many, scaling\nrules, and other deployment settings.  The following code snippet defines an endpoint\nwith a single machine using an ",(0,i.jsx)(n.code,{children:"ml.c5.large"})," CPU."]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.a,{href:"https://docs.aws.amazon.com/sagemaker/latest/dg/notebooks-available-instance-types.html",children:"Full list of available instances"})," (See Compute optimized (no GPUs) section)"]}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateEndpointConfig.html",children:"EndpointConfig documentation and options"})}),"\n"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'model_name = "question-answering-example"  # model defined above\ninitial_instance_count = 1\ninstance_type = "ml.c5.2xlarge" # 8 vcpus\n\nvariant_name = "QuestionAnsweringDeepSparseDemo"  # ^[a-zA-Z0-9](-*[a-zA-Z0-9]){0,62}\n\nproduction_variants = [\n    {\n        "VariantName": variant_name,\n        "ModelName": model_name,\n        "InitialInstanceCount": initial_instance_count,\n        "InstanceType": instance_type,\n    }\n]\n\nendpoint_config_name = "QuestionAnsweringExampleConfig"  # ^[a-zA-Z0-9](-*[a-zA-Z0-9]){0,62}\n\nendpoint_config = {\n    "EndpointConfigName": endpoint_config_name,\n    "ProductionVariants": production_variants,\n}\n\nendpoint_config_res = sm_boto3.create_endpoint_config(**endpoint_config)\n'})}),"\n",(0,i.jsx)(n.h3,{id:"launching-a-sagemaker-endpoint",children:"Launching a SageMaker Endpoint"}),"\n",(0,i.jsxs)(n.p,{children:["Once the ",(0,i.jsx)(n.code,{children:"EndpointConfig"})," is defined, launch the endpoint using\nthe ",(0,i.jsx)(n.code,{children:"create_endpoint"})," command:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'endpoint_name = "question-answering-example-endpoint"\nendpoint_res = sm_boto3.create_endpoint(\n    EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name\n)\n'})}),"\n",(0,i.jsxs)(n.p,{children:["After creating the endpoint, you can check its status by running the following.\nInitially, the ",(0,i.jsx)(n.code,{children:"EndpointStatus"})," will be ",(0,i.jsx)(n.code,{children:"Creating"}),". Checking after the image is\nsuccessfully launched, it will be ",(0,i.jsx)(n.code,{children:"InService"}),". If there are any errors, it will\nbe ",(0,i.jsx)(n.code,{children:"Failed"}),"."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"from pprint import pprint\npprint(sm_boto3.describe_endpoint(EndpointName=endpoint_name))\n"})}),"\n",(0,i.jsx)(n.h2,{id:"making-a-request-to-the-endpoint",children:"Making a Request to the Endpoint"}),"\n",(0,i.jsxs)(n.p,{children:["After the endpoint is in service, you can make requests to it through the\n",(0,i.jsx)(n.code,{children:"invoke_endpoint"})," API. Inputs will be passed as a JSON payload."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import json\n\nsm_runtime = boto3.client("sagemaker-runtime", region_name="us-east-1")\n\nbody = json.dumps(\n    dict(\n        question="Where do I live?",\n        context="I am a student and I live in Cambridge",\n    )\n)\n\ncontent_type = "application/json"\naccept = "text/plain"\n\nres = sm_runtime.invoke_endpoint(\n    EndpointName=endpoint_name,\n    Body=body,\n    ContentType=content_type,\n    Accept=accept,\n)\n\nprint(res["Body"].readlines())\n'})}),"\n",(0,i.jsx)(n.h3,{id:"cleanup",children:"Cleanup"}),"\n",(0,i.jsx)(n.p,{children:"You can delete the model and endpoint with the following commands:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"sm_boto3.delete_endpoint(EndpointName=endpoint_name)\nsm_boto3.delete_endpoint_config(EndpointConfigName=endpoint_config_name)\nsm_boto3.delete_model(ModelName=model_name)\n"})}),"\n",(0,i.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,i.jsxs)(n.p,{children:["These steps create an invokable SageMaker inference endpoint powered by DeepSparse.",(0,i.jsx)(n.br,{}),"\n","The ",(0,i.jsx)(n.code,{children:"EndpointConfig"})," settings may be adjusted to set instance scaling rules based\non deployment needs."]}),"\n",(0,i.jsxs)(n.p,{children:["Refer to ",(0,i.jsx)(n.a,{href:"https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-inference-code.html",children:"AWS documentation"})," for more information on deploying custom models with SageMaker."]})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}},8453:(e,n,a)=>{a.d(n,{R:()=>t,x:()=>r});var i=a(6540);const s={},o=i.createContext(s);function t(e){const n=i.useContext(o);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:t(e.components),i.createElement(o.Provider,{value:n},e.children)}}}]);