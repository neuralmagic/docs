

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Overview &mdash; DeepSparse 0.4.0.20210526 documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/nm-theme-adjustment.css" type="text/css" />

  
  
    <link rel="shortcut icon" href="_static/favicon.ico"/>
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/clipboard.min.js"></script>
        <script src="_static/copybutton.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Hardware Support" href="source/hardware.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="#" class="icon icon-home"> DeepSparse
          

          
            
            <img src="_static/icon-deepsparse.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                0.4
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">General</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="source/hardware.html">Hardware Support</a></li>
</ul>
<p class="caption"><span class="caption-text">Performance</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="debugging-optimizing/index.html">Debugging and Optimizing</a></li>
<li class="toctree-l1"><a class="reference internal" href="source/scheduler.html">Serial or Concurrent Inferences</a></li>
</ul>
<p class="caption"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="api/deepsparse.html">deepsparse package</a></li>
</ul>
<p class="caption"><span class="caption-text">Connect Online</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://github.com/neuralmagic/deepsparse/issues">Bugs, Feature Requests</a></li>
<li class="toctree-l1"><a class="reference external" href="https://discuss.neuralmagic.com/">Support, General Q&amp;A Forums</a></li>
<li class="toctree-l1"><a class="reference external" href="https://join.slack.com/t/discuss-neuralmagic/shared_invite/zt-q1a1cnvo-YBoICSIw3L1dmQpjBeDurQ">Deep Sparse Community Slack</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/neuralmagic">Neural Magic GitHub</a></li>
<li class="toctree-l1"><a class="reference external" href="https://docs.neuralmagic.com">Neural Magic Docs</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="#">DeepSparse</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="#" class="icon icon-home"></a> &raquo;</li>
        
      <li>Overview</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/index.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <!--
Copyright (c) 2021 - present / Neuralmagic, Inc. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing,
software distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
--><h1><img alt="tool icon" src="https://raw.githubusercontent.com/neuralmagic/deepsparse/main/docs/source/icon-deepsparse.png" />&nbsp;&nbsp;DeepSparse</h1><h3>Neural network inference engine that delivers GPU-class performance for sparsified models on CPUs</h3><p>
    <a href="https://docs.neuralmagic.com/deepsparse/">
        <img alt="Documentation" src="https://img.shields.io/badge/documentation-darkred?&style=for-the-badge&logo=read-the-docs" height=25>
    </a>
    <a href="https://join.slack.com/t/discuss-neuralmagic/shared_invite/zt-q1a1cnvo-YBoICSIw3L1dmQpjBeDurQ/">
        <img src="https://img.shields.io/badge/slack-purple?style=for-the-badge&logo=slack" height=25>
    </a>
    <a href="https://discuss.neuralmagic.com/">
        <img src="https://img.shields.io/badge/support%20forums-navy?style=for-the-badge&logo=discourse" height=25>
    </a>
    <a href="https://github.com/neuralmagic/deepsparse/actions/workflows/quality-check.yaml">
        <img alt="Main" src="https://img.shields.io/github/workflow/status/neuralmagic/deepsparse/Quality%20Checks/main?label=build&style=for-the-badge" height=25>
    </a>
    <a href="https://github.com/neuralmagic/deepsparse/releases">
        <img alt="GitHub release" src="https://img.shields.io/github/release/neuralmagic/deepsparse.svg?style=for-the-badge" height=25>
    </a>
    <a href="https://github.com/neuralmagic/deepsparse/blob/main/CODE_OF_CONDUCT.md">
        <img alt="Contributor Covenant" src="https://img.shields.io/badge/Contributor%20Covenant-v2.0%20adopted-ff69b4.svg?color=yellow&style=for-the-badge" height=25>
    </a>
    <a href="https://www.youtube.com/channel/UCo8dO_WMGYbWCRnj_Dxr4EA">
        <img src="https://img.shields.io/badge/-YouTube-red?&style=for-the-badge&logo=youtube&logoColor=white" height=25>
    </a>
     <a href="https://medium.com/limitlessai">
        <img src="https://img.shields.io/badge/medium-%2312100E.svg?&style=for-the-badge&logo=medium&logoColor=white" height=25>
    </a>
    <a href="https://twitter.com/neuralmagic">
        <img src="https://img.shields.io/twitter/follow/neuralmagic?color=darkgreen&label=Follow&style=social" height=25>
    </a>
</p><div class="section" id="overview">
<h1>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">¶</a></h1>
<p>The DeepSparse Engine is a CPU runtime that delivers GPU-class performance by taking advantage of sparsity (read more about sparsification <a class="reference external" href="https://docs.neuralmagic.com/main/source/getstarted.html#sparsification">here</a>) within neural networks to reduce compute required as well as accelerate memory bound workloads.
It is focused on model deployment and scaling machine learning pipelines, fitting seamlessly into your existing deployments as an inference backend.</p>
<p>The <a class="reference external" href="https://github.com/neuralmagic/deepsparse">GitHub repository</a> includes package APIs along with examples to quickly get started benchmarking and inferencing sparse models.</p>
<p><span class="raw-html-m2r"><img src="https://docs.neuralmagic.com/docs/source/infographics/deepsparse.png" width="960px" /></span></p>
</div>
<div class="section" id="highlights">
<h1>Highlights<a class="headerlink" href="#highlights" title="Permalink to this headline">¶</a></h1>
<p>
    <a href="https://neuralmagic.com/blog/benchmark-resnet50-with-deepsparse/">
        <img alt="ResNet-50, b64 - ORT: 296 images/sec vs DeepSparse: 2305 images/sec on 24 cores" src="https://docs.neuralmagic.com/docs/source/highlights/deepsparse/resnet-50.png" width="256px" />
    </a>
    <a href="https://neuralmagic.com/blog/benchmark-yolov3-on-cpus-with-deepsparse/">
        <img alt="YOLOv3, b64 - PyTorch: 6.9 images/sec vs. DeepSparse: 46.5 images/sec" src="https://docs.neuralmagic.com/docs/source/highlights/deepsparse/yolov3.png" width="256px" />
    </a>
</p></div>
<div class="section" id="tutorials">
<h1>Tutorials<a class="headerlink" href="#tutorials" title="Permalink to this headline">¶</a></h1>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/neuralmagic/deepsparse/tree/main/examples/benchmark">Benchmarking</a></p></li>
<li><p><a class="reference external" href="https://github.com/neuralmagic/deepsparse/tree/main/examples/classification">Image Classification</a></p></li>
<li><p><a class="reference external" href="https://github.com/neuralmagic/deepsparse/tree/main/examples/detection">Object Detection</a></p></li>
<li><p><a class="reference external" href="https://github.com/neuralmagic/deepsparse/tree/main/examples/flask">Flask Serving</a></p></li>
<li><p><a class="reference external" href="https://github.com/neuralmagic/deepsparse/tree/main/examples/ultralytics-yolov3">YOLOv3</a></p></li>
</ul>
</div>
<div class="section" id="installation">
<h1>Installation<a class="headerlink" href="#installation" title="Permalink to this headline">¶</a></h1>
<p>This repository is tested on Python 3.6+, and ONNX 1.5.0+. It is recommended to install in a <a class="reference external" href="https://docs.python.org/3/library/venv.html">virtual environment</a> to keep your system in order.</p>
<p>Install with pip using:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip install deepsparse
</pre></div>
</div>
<div class="section" id="hardware-support">
<h2>Hardware Support<a class="headerlink" href="#hardware-support" title="Permalink to this headline">¶</a></h2>
<p>The DeepSparse Engine is validated to work on x86 Intel and AMD CPUs running Linux operating systems. Mac and Windows require running Linux in a Docker or virtual machine.</p>
<p>It is highly recommended to run on a CPU with AVX-512 instructions available for optimal algorithms to be enabled.</p>
<p>Here is a table detailing specific support for some algorithms over different microarchitectures:</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 20%" />
<col style="width: 20%" />
<col style="width: 20%" />
<col style="width: 20%" />
<col style="width: 20%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>x86 Extension</p></th>
<th class="head"><p>Microarchitectures</p></th>
<th class="head"><p>Activation Sparsity</p></th>
<th class="head"><p>Kernel Sparsity</p></th>
<th class="head"><p>Sparse Quantization</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><a class="reference external" href="https://en.wikipedia.org/wiki/Advanced_Vector_Extensions#CPUs_with_AVX2">AMD AVX2</a></p></td>
<td><p><a class="reference external" href="https://en.wikipedia.org/wiki/Zen_2">Zen 2</a>, <a class="reference external" href="https://en.wikipedia.org/wiki/Zen_3">Zen 3</a></p></td>
<td><p>not supported</p></td>
<td><p>optimized</p></td>
<td><p>not supported</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://en.wikipedia.org/wiki/Advanced_Vector_Extensions#CPUs_with_AVX2">Intel AVX2</a></p></td>
<td><p><a class="reference external" href="https://en.wikipedia.org/wiki/Haswell_(microarchitecture">Haswell</a>), <a class="reference external" href="https://en.wikipedia.org/wiki/Broadwell_(microarchitecture">Broadwell</a>), and newer</p></td>
<td><p>not supported</p></td>
<td><p>optimized</p></td>
<td><p>not supported</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference external" href="https://en.wikipedia.org/wiki/AVX-512#CPUs_with_AVX-512">Intel AVX-512</a></p></td>
<td><p><a class="reference external" href="https://en.wikipedia.org/wiki/Skylake_(microarchitecture">Skylake</a>), <a class="reference external" href="https://en.wikipedia.org/wiki/Cannon_Lake_(microarchitecture">Cannon Lake</a>), and newer</p></td>
<td><p>optimized</p></td>
<td><p>optimized</p></td>
<td><p>emulated</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://en.wikipedia.org/wiki/AVX-512#CPUs_with_AVX-512">Intel AVX-512</a> VNNI (DL Boost)</p></td>
<td><p><a class="reference external" href="https://en.wikipedia.org/wiki/Cascade_Lake_(microarchitecture">Cascade Lake</a>), <a class="reference external" href="https://en.wikipedia.org/wiki/Ice_Lake_(microprocessor">Ice Lake</a>), <a class="reference external" href="https://en.wikipedia.org/wiki/Cooper_Lake_(microarchitecture">Cooper Lake</a>), <a class="reference external" href="https://en.wikipedia.org/wiki/Tiger_Lake_(microprocessor">Tiger Lake</a>)</p></td>
<td><p>optimized</p></td>
<td><p>optimized</p></td>
<td><p>optimized</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="compatibility">
<h2>Compatibility<a class="headerlink" href="#compatibility" title="Permalink to this headline">¶</a></h2>
<p>The DeepSparse Engine ingests models in the <a class="reference external" href="https://onnx.ai/">ONNX</a> format, allowing for compatibility with <a class="reference external" href="https://pytorch.org/docs/stable/onnx.html">PyTorch</a>, <a class="reference external" href="https://github.com/onnx/tensorflow-onnx">TensorFlow</a>, <a class="reference external" href="https://github.com/onnx/keras-onnx">Keras</a>, and <a class="reference external" href="https://github.com/onnx/onnxmltools">many other frameworks</a> that support it. This reduces the extra work of preparing your trained model for inference to just one step of exporting.</p>
</div>
</div>
<div class="section" id="quick-tour">
<h1>Quick Tour<a class="headerlink" href="#quick-tour" title="Permalink to this headline">¶</a></h1>
<p>To expedite inference and benchmarking on real models, we include the <code class="docutils literal notranslate"><span class="pre">sparsezoo</span></code> package.
<a class="reference external" href="https://github.com/neuralmagic/sparsezoo">SparseZoo</a> hosts inference-optimized models, trained on repeatable sparsification recipes using state-of-the-art techniques from <a class="reference external" href="https://github.com/neuralmagic/sparseml">SparseML</a>.</p>
<div class="section" id="quickstart-with-sparsezoo-onnx-models">
<h2>Quickstart with SparseZoo ONNX Models<a class="headerlink" href="#quickstart-with-sparsezoo-onnx-models" title="Permalink to this headline">¶</a></h2>
<p><strong>ResNet-50 Dense</strong></p>
<p>Here is how to quickly perform inference with DeepSparse Engine on a pre-trained dense ResNet-50 from SparseZoo.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">deepsparse</span> <span class="kn">import</span> <span class="n">compile_model</span>
<span class="kn">from</span> <span class="nn">sparsezoo.models</span> <span class="kn">import</span> <span class="n">classification</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span>

<span class="c1"># Download model and compile as optimized executable for your machine</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">classification</span><span class="o">.</span><span class="n">resnet_50</span><span class="p">()</span>
<span class="n">engine</span> <span class="o">=</span> <span class="n">compile_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>

<span class="c1"># Fetch sample input and predict output using engine</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">data_inputs</span><span class="o">.</span><span class="n">sample_batch</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
<span class="n">outputs</span><span class="p">,</span> <span class="n">inference_time</span> <span class="o">=</span> <span class="n">engine</span><span class="o">.</span><span class="n">timed_run</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>ResNet-50 Sparsified</strong></p>
<p>When exploring available optimized models, you can use the <code class="docutils literal notranslate"><span class="pre">Zoo.search_optimized_models</span></code> utility to find models that share a base.</p>
<p>Try this on the dense ResNet-50 to see what is available:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sparsezoo</span> <span class="kn">import</span> <span class="n">Zoo</span>
<span class="kn">from</span> <span class="nn">sparsezoo.models</span> <span class="kn">import</span> <span class="n">classification</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">classification</span><span class="o">.</span><span class="n">resnet_50</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">Zoo</span><span class="o">.</span><span class="n">search_sparse_models</span><span class="p">(</span><span class="n">model</span><span class="p">))</span>
</pre></div>
</div>
<p>Output:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="o">[</span>
    Model<span class="o">(</span><span class="nv">stub</span><span class="o">=</span>cv/classification/resnet_v1-50/pytorch/sparseml/imagenet/pruned-conservative<span class="o">)</span>,
    Model<span class="o">(</span><span class="nv">stub</span><span class="o">=</span>cv/classification/resnet_v1-50/pytorch/sparseml/imagenet/pruned-moderate<span class="o">)</span>,
    Model<span class="o">(</span><span class="nv">stub</span><span class="o">=</span>cv/classification/resnet_v1-50/pytorch/sparseml/imagenet/pruned_quant-moderate<span class="o">)</span>,
    Model<span class="o">(</span><span class="nv">stub</span><span class="o">=</span>cv/classification/resnet_v1-50/pytorch/sparseml/imagenet-augmented/pruned_quant-aggressive<span class="o">)</span>
<span class="o">]</span>
</pre></div>
</div>
<p>We can see there are two pruned versions targeting FP32 and two pruned, quantized versions targeting INT8.
The <code class="docutils literal notranslate"><span class="pre">conservative</span></code>, <code class="docutils literal notranslate"><span class="pre">moderate</span></code>, and <code class="docutils literal notranslate"><span class="pre">aggressive</span></code> tags recover to 100%, &gt;=99%, and &lt;99% of baseline accuracy respectively.</p>
<p>For a version of ResNet-50 that recovers close to the baseline and is very performant, choose the pruned_quant-moderate model.
This model will run <a class="reference external" href="https://neuralmagic.com/blog/benchmark-resnet50-with-deepsparse">nearly 7x faster</a> than the baseline model on a compatible CPU (with the VNNI instruction set enabled).
For hardware compatibility, see the Hardware Support section.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">deepsparse</span> <span class="kn">import</span> <span class="n">compile_model</span>
<span class="kn">import</span> <span class="nn">numpy</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">sample_inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">)]</span>

<span class="c1"># run baseline benchmarking</span>
<span class="n">engine_base</span> <span class="o">=</span> <span class="n">compile_model</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="s2">&quot;zoo:cv/classification/resnet_v1-50/pytorch/sparseml/imagenet/base-none&quot;</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">benchmarks_base</span> <span class="o">=</span> <span class="n">engine_base</span><span class="o">.</span><span class="n">benchmark</span><span class="p">(</span><span class="n">sample_inputs</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">benchmarks_base</span><span class="p">)</span>

<span class="c1"># run sparse benchmarking</span>
<span class="n">engine_sparse</span> <span class="o">=</span> <span class="n">compile_model</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="s2">&quot;zoo:cv/classification/resnet_v1-50/pytorch/sparseml/imagenet/pruned_quant-moderate&quot;</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
<span class="p">)</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">engine_sparse</span><span class="o">.</span><span class="n">cpu_vnni</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;WARNING: VNNI instructions not detected, quantization speedup not well supported&quot;</span><span class="p">)</span>
<span class="n">benchmarks_sparse</span> <span class="o">=</span> <span class="n">engine_sparse</span><span class="o">.</span><span class="n">benchmark</span><span class="p">(</span><span class="n">sample_inputs</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">benchmarks_sparse</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Speedup: </span><span class="si">{</span><span class="n">benchmarks_sparse</span><span class="o">.</span><span class="n">items_per_second</span> <span class="o">/</span> <span class="n">benchmarks_base</span><span class="o">.</span><span class="n">items_per_second</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">x&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="quickstart-with-custom-onnx-models">
<h2>Quickstart with Custom ONNX Models<a class="headerlink" href="#quickstart-with-custom-onnx-models" title="Permalink to this headline">¶</a></h2>
<p>We accept ONNX files for custom models, too. Simply plug in your model to compare performance with other solutions.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>&gt; wget https://github.com/onnx/models/raw/master/vision/classification/mobilenet/model/mobilenetv2-7.onnx
Saving to: ‘mobilenetv2-7.onnx’
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">deepsparse</span> <span class="kn">import</span> <span class="n">compile_model</span>
<span class="kn">from</span> <span class="nn">deepsparse.utils</span> <span class="kn">import</span> <span class="n">generate_random_inputs</span>
<span class="n">onnx_filepath</span> <span class="o">=</span> <span class="s2">&quot;mobilenetv2-7.onnx&quot;</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">16</span>

<span class="c1"># Generate random sample input</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">generate_random_inputs</span><span class="p">(</span><span class="n">onnx_filepath</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>

<span class="c1"># Compile and run</span>
<span class="n">engine</span> <span class="o">=</span> <span class="n">compile_model</span><span class="p">(</span><span class="n">onnx_filepath</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">engine</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</pre></div>
</div>
<p>For a more in-depth read on available APIs and workflows, check out the <a class="reference external" href="https://github.com/neuralmagic/deepsparse/blob/main/examples/">examples</a> and <a class="reference external" href="https://docs.neuralmagic.com/deepsparse">DeepSparse Engine documentation</a>.</p>
</div>
</div>
<div class="section" id="resources">
<h1>Resources<a class="headerlink" href="#resources" title="Permalink to this headline">¶</a></h1>
<div class="section" id="learning-more">
<h2>Learning More<a class="headerlink" href="#learning-more" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Documentation: <a class="reference external" href="https://docs.neuralmagic.com/sparseml/">SparseML</a>, <a class="reference external" href="https://docs.neuralmagic.com/sparsezoo/">SparseZoo</a>, <a class="reference external" href="https://docs.neuralmagic.com/sparsify/">Sparsify</a>, <a class="reference external" href="https://docs.neuralmagic.com/deepsparse/">DeepSparse</a></p></li>
<li><p>Neural Magic: <a class="reference external" href="https://www.neuralmagic.com/blog/">Blog</a>, <a class="reference external" href="https://www.neuralmagic.com/resources/">Resources</a></p></li>
</ul>
</div>
<div class="section" id="release-history">
<h2>Release History<a class="headerlink" href="#release-history" title="Permalink to this headline">¶</a></h2>
<p>Official builds are hosted on PyPI</p>
<ul class="simple">
<li><p>stable: <a class="reference external" href="https://pypi.org/project/deepsparse">deepsparse</a></p></li>
<li><p>nightly (dev): <a class="reference external" href="https://pypi.org/project/deepsparse-nightly/">deepsparse-nightly</a></p></li>
</ul>
<p>Additionally, more information can be found via <a class="reference external" href="https://github.com/neuralmagic/deepsparse/releases">GitHub Releases.</a></p>
</div>
<div class="section" id="license">
<h2>License<a class="headerlink" href="#license" title="Permalink to this headline">¶</a></h2>
<p>The project’s binary containing the DeepSparse Engine is licensed under the <a class="reference external" href="https://github.com/neuralmagic/deepsparse/blob/main/LICENSE-NEURALMAGIC">Neural Magic Engine License</a>.</p>
<p>Example files and scripts included in this repository are licensed under the <a class="reference external" href="https://github.com/neuralmagic/deepsparse/blob/main/LICENSE">Apache License Version 2.0</a> as noted.</p>
</div>
</div>
<div class="section" id="community">
<h1>Community<a class="headerlink" href="#community" title="Permalink to this headline">¶</a></h1>
<div class="section" id="contribute">
<h2>Contribute<a class="headerlink" href="#contribute" title="Permalink to this headline">¶</a></h2>
<p>We appreciate contributions to the code, examples, integrations, and documentation as well as bug reports and feature requests! <a class="reference external" href="https://github.com/neuralmagic/deepsparse/blob/main/CONTRIBUTING.md">Learn how here</a>.</p>
</div>
<div class="section" id="join">
<h2>Join<a class="headerlink" href="#join" title="Permalink to this headline">¶</a></h2>
<p>For user help or questions about the DeepSparse Engine, sign up or log in: <strong>Deep Sparse Community</strong> <a class="reference external" href="https://discuss.neuralmagic.com/">Discourse Forum</a> and/or <a class="reference external" href="https://join.slack.com/t/discuss-neuralmagic/shared_invite/zt-q1a1cnvo-YBoICSIw3L1dmQpjBeDurQ">Slack</a>. We are growing the community member by member and happy to see you there.</p>
<p>You can get the latest news, webinar and event invites, research papers, and other ML Performance tidbits by <a class="reference external" href="https://neuralmagic.com/subscribe/">subscribing</a> to the Neural Magic community.</p>
<p>For more general questions about Neural Magic, please fill out this <a class="reference external" href="http://neuralmagic.com/contact/">form</a>.</p>
</div>
<div class="section" id="cite">
<h2>Cite<a class="headerlink" href="#cite" title="Permalink to this headline">¶</a></h2>
<p>Find this project useful in your research or other communications? Please consider citing:</p>
<div class="highlight-bibtex notranslate"><div class="highlight"><pre><span></span><span class="nc">@InProceedings</span><span class="p">{</span>
    <span class="nl">pmlr-v119-kurtz20a</span><span class="p">,</span>
    <span class="na">title</span> <span class="p">=</span> <span class="s">{Inducing and Exploiting Activation Sparsity for Fast Inference on Deep Neural Networks}</span><span class="p">,</span>
    <span class="na">author</span> <span class="p">=</span> <span class="s">{Kurtz, Mark and Kopinsky, Justin and Gelashvili, Rati and Matveev, Alexander and Carr, John and Goin, Michael and Leiserson, William and Moore, Sage and Nell, Bill and Shavit, Nir and Alistarh, Dan}</span><span class="p">,</span>
    <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 37th International Conference on Machine Learning}</span><span class="p">,</span>
    <span class="na">pages</span> <span class="p">=</span> <span class="s">{5533--5543}</span><span class="p">,</span>
    <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
    <span class="na">editor</span> <span class="p">=</span> <span class="s">{Hal Daumé III and Aarti Singh}</span><span class="p">,</span>
    <span class="na">volume</span> <span class="p">=</span> <span class="s">{119}</span><span class="p">,</span>
    <span class="na">series</span> <span class="p">=</span> <span class="s">{Proceedings of Machine Learning Research}</span><span class="p">,</span>
    <span class="na">address</span> <span class="p">=</span> <span class="s">{Virtual}</span><span class="p">,</span>
    <span class="na">month</span> <span class="p">=</span> <span class="s">{13--18 Jul}</span><span class="p">,</span>
    <span class="na">publisher</span> <span class="p">=</span> <span class="s">{PMLR}</span><span class="p">,</span>
    <span class="na">pdf</span> <span class="p">=</span> <span class="s">{http://proceedings.mlr.press/v119/kurtz20a/kurtz20a.pdf}</span><span class="p">,</span>
    <span class="na">url</span> <span class="p">=</span> <span class="s">{http://proceedings.mlr.press/v119/kurtz20a.html}</span><span class="p">,</span>
    <span class="na">abstract</span> <span class="p">=</span> <span class="s">{Optimizing convolutional neural networks for fast inference has recently become an extremely active area of research. One of the go-to solutions in this context is weight pruning, which aims to reduce computational and memory footprint by removing large subsets of the connections in a neural network. Surprisingly, much less attention has been given to exploiting sparsity in the activation maps, which tend to be naturally sparse in many settings thanks to the structure of rectified linear (ReLU) activation functions. In this paper, we present an in-depth analysis of methods for maximizing the sparsity of the activations in a trained neural network, and show that, when coupled with an efficient sparse-input convolution algorithm, we can leverage this sparsity for significant performance gains. To induce highly sparse activation maps without accuracy loss, we introduce a new regularization technique, coupled with a new threshold-based sparsification method based on a parameterized activation function called Forced-Activation-Threshold Rectified Linear Unit (FATReLU). We examine the impact of our methods on popular image classification models, showing that most architectures can adapt to significantly sparser activation maps without any accuracy loss. Our second contribution is showing that these these compression gains can be translated into inference speedups: we provide a new algorithm to enable fast convolution operations over networks with sparse activations, and show that it can enable significant speedups for end-to-end inference on a range of popular models on the large-scale ImageNet image classification task on modern Intel CPUs, with little or no retraining cost.}</span>
<span class="p">}</span>
</pre></div>
</div>
<div class="toctree-wrapper compound">
<p class="caption"><span class="caption-text">General</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="source/hardware.html">Hardware Support</a></li>
</ul>
</div>
<div class="toctree-wrapper compound">
<p class="caption"><span class="caption-text">Performance</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="debugging-optimizing/index.html">Debugging and Optimizing</a><ul>
<li class="toctree-l2"><a class="reference internal" href="debugging-optimizing/numactl-utility.html">Using the numactl Utility to Control Resource Utilization with the DeepSparse Engine</a><ul>
<li class="toctree-l3"><a class="reference internal" href="debugging-optimizing/numactl-utility.html#deepsparse-engine-and-thread-pinning">DeepSparse Engine and Thread Pinning</a></li>
<li class="toctree-l3"><a class="reference internal" href="debugging-optimizing/numactl-utility.html#additional-notes">Additional Notes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="debugging-optimizing/diagnostics-debugging.html">Logging Guidance for Diagnostics and Debugging</a><ul>
<li class="toctree-l3"><a class="reference internal" href="debugging-optimizing/diagnostics-debugging.html#performance-tuning">Performance Tuning</a></li>
<li class="toctree-l3"><a class="reference internal" href="debugging-optimizing/diagnostics-debugging.html#enabling-logs-and-controlling-the-amount-of-logs-produced-by-the-deepsparse-engine">Enabling Logs and Controlling the Amount of Logs Produced by the DeepSparse Engine</a></li>
<li class="toctree-l3"><a class="reference internal" href="debugging-optimizing/diagnostics-debugging.html#parsing-an-example-log">Parsing an Example Log</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="debugging-optimizing/example-log.html">Example Log, Verbose Level = diagnose</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="source/scheduler.html">Serial or Concurrent Inferences</a></li>
</ul>
</div>
<div class="toctree-wrapper compound">
<p class="caption"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="api/deepsparse.html">deepsparse package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="api/deepsparse.html#subpackages">Subpackages</a></li>
<li class="toctree-l2"><a class="reference internal" href="api/deepsparse.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="api/deepsparse.html#module-deepsparse.benchmark">deepsparse.benchmark module</a></li>
<li class="toctree-l2"><a class="reference internal" href="api/deepsparse.html#module-deepsparse.cpu">deepsparse.cpu module</a></li>
<li class="toctree-l2"><a class="reference internal" href="api/deepsparse.html#module-deepsparse.engine">deepsparse.engine module</a></li>
<li class="toctree-l2"><a class="reference internal" href="api/deepsparse.html#deepsparse-generated-version-module">deepsparse.generated-version module</a></li>
<li class="toctree-l2"><a class="reference internal" href="api/deepsparse.html#module-deepsparse.generated_version">deepsparse.generated_version module</a></li>
<li class="toctree-l2"><a class="reference internal" href="api/deepsparse.html#module-deepsparse.lib">deepsparse.lib module</a></li>
<li class="toctree-l2"><a class="reference internal" href="api/deepsparse.html#module-deepsparse.version">deepsparse.version module</a></li>
<li class="toctree-l2"><a class="reference internal" href="api/deepsparse.html#module-deepsparse">Module contents</a></li>
</ul>
</li>
</ul>
</div>
<div class="toctree-wrapper compound">
<p class="caption"><span class="caption-text">Connect Online</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://github.com/neuralmagic/deepsparse/issues">Bugs, Feature Requests</a></li>
<li class="toctree-l1"><a class="reference external" href="https://discuss.neuralmagic.com/">Support, General Q&amp;A Forums</a></li>
<li class="toctree-l1"><a class="reference external" href="https://join.slack.com/t/discuss-neuralmagic/shared_invite/zt-q1a1cnvo-YBoICSIw3L1dmQpjBeDurQ">Deep Sparse Community Slack</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/neuralmagic">Neural Magic GitHub</a></li>
<li class="toctree-l1"><a class="reference external" href="https://docs.neuralmagic.com">Neural Magic Docs</a></li>
</ul>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="source/hardware.html" class="btn btn-neutral float-right" title="Hardware Support" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021 - present / Neuralmagic, Inc. All Rights Reserved. Licensed under the Neural Magic Engine License and Apache License, Version 2.0 as noted..

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  
<div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    <span class="fa fa-book"> Other Versions</span>
    v: main
    <span class="fa fa-caret-down"></span>
  </span>
  <div class="rst-other-versions">
    <dl>
      <dt>Tags</dt>
      <dd><a href="../v0.3.0/index.html">v0.3.0</a></dd>
      <dd><a href="../v0.3.1/index.html">v0.3.1</a></dd>
    </dl>
    <dl>
      <dt>Branches</dt>
      <dd><a href="index.html">main</a></dd>
    </dl>
  </div>
</div>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-128364174-1', 'auto');
    
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>